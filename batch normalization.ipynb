{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/1000, train loss: 285.3080, test loss: 285.1842\n",
      "epoch: 2/1000, train loss: 276.3896, test loss: 276.2621\n",
      "epoch: 3/1000, train loss: 270.3400, test loss: 270.2122\n",
      "epoch: 4/1000, train loss: 265.1137, test loss: 264.9868\n",
      "epoch: 5/1000, train loss: 260.3383, test loss: 260.2125\n",
      "epoch: 6/1000, train loss: 255.8705, test loss: 255.7457\n",
      "epoch: 7/1000, train loss: 251.6582, test loss: 251.5344\n",
      "epoch: 8/1000, train loss: 247.6800, test loss: 247.5572\n",
      "epoch: 9/1000, train loss: 243.9246, test loss: 243.8028\n",
      "epoch: 10/1000, train loss: 240.3807, test loss: 240.2599\n",
      "epoch: 11/1000, train loss: 237.0335, test loss: 236.9136\n",
      "epoch: 12/1000, train loss: 233.8665, test loss: 233.7474\n",
      "epoch: 13/1000, train loss: 230.8630, test loss: 230.7447\n",
      "epoch: 14/1000, train loss: 228.0079, test loss: 227.8904\n",
      "epoch: 15/1000, train loss: 225.2878, test loss: 225.1711\n",
      "epoch: 16/1000, train loss: 222.6909, test loss: 222.5749\n",
      "epoch: 17/1000, train loss: 220.2057, test loss: 220.0904\n",
      "epoch: 18/1000, train loss: 217.8218, test loss: 217.7072\n",
      "epoch: 19/1000, train loss: 215.5296, test loss: 215.4156\n",
      "epoch: 20/1000, train loss: 213.3199, test loss: 213.2065\n",
      "epoch: 21/1000, train loss: 211.1838, test loss: 211.0710\n",
      "epoch: 22/1000, train loss: 209.1133, test loss: 209.0011\n",
      "epoch: 23/1000, train loss: 207.1013, test loss: 206.9898\n",
      "epoch: 24/1000, train loss: 205.1424, test loss: 205.0314\n",
      "epoch: 25/1000, train loss: 203.2316, test loss: 203.1211\n",
      "epoch: 26/1000, train loss: 201.3646, test loss: 201.2547\n",
      "epoch: 27/1000, train loss: 199.5374, test loss: 199.4281\n",
      "epoch: 28/1000, train loss: 197.7466, test loss: 197.6378\n",
      "epoch: 29/1000, train loss: 195.9886, test loss: 195.8803\n",
      "epoch: 30/1000, train loss: 194.2607, test loss: 194.1529\n",
      "epoch: 31/1000, train loss: 192.5600, test loss: 192.4527\n",
      "epoch: 32/1000, train loss: 190.8843, test loss: 190.7775\n",
      "epoch: 33/1000, train loss: 189.2314, test loss: 189.1251\n",
      "epoch: 34/1000, train loss: 187.5993, test loss: 187.4935\n",
      "epoch: 35/1000, train loss: 185.9864, test loss: 185.8811\n",
      "epoch: 36/1000, train loss: 184.3911, test loss: 184.2863\n",
      "epoch: 37/1000, train loss: 182.8121, test loss: 182.7077\n",
      "epoch: 38/1000, train loss: 181.2482, test loss: 181.1443\n",
      "epoch: 39/1000, train loss: 179.6983, test loss: 179.5949\n",
      "epoch: 40/1000, train loss: 178.1615, test loss: 178.0586\n",
      "epoch: 41/1000, train loss: 176.6371, test loss: 176.5347\n",
      "epoch: 42/1000, train loss: 175.1241, test loss: 175.0222\n",
      "epoch: 43/1000, train loss: 173.6221, test loss: 173.5206\n",
      "epoch: 44/1000, train loss: 172.1306, test loss: 172.0296\n",
      "epoch: 45/1000, train loss: 170.6489, test loss: 170.5484\n",
      "epoch: 46/1000, train loss: 169.1766, test loss: 169.0766\n",
      "epoch: 47/1000, train loss: 167.7133, test loss: 167.6138\n",
      "epoch: 48/1000, train loss: 166.2587, test loss: 166.1596\n",
      "epoch: 49/1000, train loss: 164.8125, test loss: 164.7138\n",
      "epoch: 50/1000, train loss: 163.3743, test loss: 163.2762\n",
      "epoch: 51/1000, train loss: 161.9441, test loss: 161.8464\n",
      "epoch: 52/1000, train loss: 160.5215, test loss: 160.4243\n",
      "epoch: 53/1000, train loss: 159.1064, test loss: 159.0096\n",
      "epoch: 54/1000, train loss: 157.6987, test loss: 157.6024\n",
      "epoch: 55/1000, train loss: 156.2982, test loss: 156.2024\n",
      "epoch: 56/1000, train loss: 154.9049, test loss: 154.8095\n",
      "epoch: 57/1000, train loss: 153.5186, test loss: 153.4237\n",
      "epoch: 58/1000, train loss: 152.1393, test loss: 152.0449\n",
      "epoch: 59/1000, train loss: 150.7669, test loss: 150.6730\n",
      "epoch: 60/1000, train loss: 149.4013, test loss: 149.3078\n",
      "epoch: 61/1000, train loss: 148.0425, test loss: 147.9495\n",
      "epoch: 62/1000, train loss: 146.6904, test loss: 146.5978\n",
      "epoch: 63/1000, train loss: 145.3450, test loss: 145.2529\n",
      "epoch: 64/1000, train loss: 144.0063, test loss: 143.9146\n",
      "epoch: 65/1000, train loss: 142.6742, test loss: 142.5830\n",
      "epoch: 66/1000, train loss: 141.3487, test loss: 141.2580\n",
      "epoch: 67/1000, train loss: 140.0299, test loss: 139.9396\n",
      "epoch: 68/1000, train loss: 138.7176, test loss: 138.6278\n",
      "epoch: 69/1000, train loss: 137.4118, test loss: 137.3225\n",
      "epoch: 70/1000, train loss: 136.1126, test loss: 136.0238\n",
      "epoch: 71/1000, train loss: 134.8201, test loss: 134.7317\n",
      "epoch: 72/1000, train loss: 133.5341, test loss: 133.4462\n",
      "epoch: 73/1000, train loss: 132.2547, test loss: 132.1673\n",
      "epoch: 74/1000, train loss: 130.9818, test loss: 130.8948\n",
      "epoch: 75/1000, train loss: 129.7154, test loss: 129.6289\n",
      "epoch: 76/1000, train loss: 128.4554, test loss: 128.3694\n",
      "epoch: 77/1000, train loss: 127.2020, test loss: 127.1164\n",
      "epoch: 78/1000, train loss: 125.9549, test loss: 125.8698\n",
      "epoch: 79/1000, train loss: 124.7144, test loss: 124.6297\n",
      "epoch: 80/1000, train loss: 123.4803, test loss: 123.3961\n",
      "epoch: 81/1000, train loss: 122.2526, test loss: 122.1689\n",
      "epoch: 82/1000, train loss: 121.0314, test loss: 120.9481\n",
      "epoch: 83/1000, train loss: 119.8166, test loss: 119.7338\n",
      "epoch: 84/1000, train loss: 118.6082, test loss: 118.5259\n",
      "epoch: 85/1000, train loss: 117.4063, test loss: 117.3245\n",
      "epoch: 86/1000, train loss: 116.2108, test loss: 116.1294\n",
      "epoch: 87/1000, train loss: 115.0218, test loss: 114.9408\n",
      "epoch: 88/1000, train loss: 113.8391, test loss: 113.7586\n",
      "epoch: 89/1000, train loss: 112.6629, test loss: 112.5829\n",
      "epoch: 90/1000, train loss: 111.4931, test loss: 111.4136\n",
      "epoch: 91/1000, train loss: 110.3298, test loss: 110.2507\n",
      "epoch: 92/1000, train loss: 109.1729, test loss: 109.0943\n",
      "epoch: 93/1000, train loss: 108.0224, test loss: 107.9443\n",
      "epoch: 94/1000, train loss: 106.8785, test loss: 106.8008\n",
      "epoch: 95/1000, train loss: 105.7412, test loss: 105.6640\n",
      "epoch: 96/1000, train loss: 104.6103, test loss: 104.5336\n",
      "epoch: 97/1000, train loss: 103.4859, test loss: 103.4096\n",
      "epoch: 98/1000, train loss: 102.3679, test loss: 102.2920\n",
      "epoch: 99/1000, train loss: 101.2562, test loss: 101.1809\n",
      "epoch: 100/1000, train loss: 100.1510, test loss: 100.0761\n",
      "epoch: 101/1000, train loss: 99.0522, test loss: 98.9778\n",
      "epoch: 102/1000, train loss: 97.9598, test loss: 97.8858\n",
      "epoch: 103/1000, train loss: 96.8737, test loss: 96.8003\n",
      "epoch: 104/1000, train loss: 95.7942, test loss: 95.7211\n",
      "epoch: 105/1000, train loss: 94.7210, test loss: 94.6484\n",
      "epoch: 106/1000, train loss: 93.6542, test loss: 93.5821\n",
      "epoch: 107/1000, train loss: 92.5939, test loss: 92.5222\n",
      "epoch: 108/1000, train loss: 91.5400, test loss: 91.4688\n",
      "epoch: 109/1000, train loss: 90.4925, test loss: 90.4218\n",
      "epoch: 110/1000, train loss: 89.4514, test loss: 89.3811\n",
      "epoch: 111/1000, train loss: 88.4168, test loss: 88.3470\n",
      "epoch: 112/1000, train loss: 87.3887, test loss: 87.3194\n",
      "epoch: 113/1000, train loss: 86.3670, test loss: 86.2981\n",
      "epoch: 114/1000, train loss: 85.3517, test loss: 85.2833\n",
      "epoch: 115/1000, train loss: 84.3428, test loss: 84.2749\n",
      "epoch: 116/1000, train loss: 83.3404, test loss: 83.2730\n",
      "epoch: 117/1000, train loss: 82.3444, test loss: 82.2774\n",
      "epoch: 118/1000, train loss: 81.3547, test loss: 81.2882\n",
      "epoch: 119/1000, train loss: 80.3715, test loss: 80.3054\n",
      "epoch: 120/1000, train loss: 79.3947, test loss: 79.3291\n",
      "epoch: 121/1000, train loss: 78.4242, test loss: 78.3591\n",
      "epoch: 122/1000, train loss: 77.4602, test loss: 77.3955\n",
      "epoch: 123/1000, train loss: 76.5026, test loss: 76.4384\n",
      "epoch: 124/1000, train loss: 75.5514, test loss: 75.4877\n",
      "epoch: 125/1000, train loss: 74.6066, test loss: 74.5433\n",
      "epoch: 126/1000, train loss: 73.6682, test loss: 73.6054\n",
      "epoch: 127/1000, train loss: 72.7363, test loss: 72.6739\n",
      "epoch: 128/1000, train loss: 71.8107, test loss: 71.7488\n",
      "epoch: 129/1000, train loss: 70.8916, test loss: 70.8301\n",
      "epoch: 130/1000, train loss: 69.9788, test loss: 69.9179\n",
      "epoch: 131/1000, train loss: 69.0725, test loss: 69.0120\n",
      "epoch: 132/1000, train loss: 68.1727, test loss: 68.1126\n",
      "epoch: 133/1000, train loss: 67.2792, test loss: 67.2197\n",
      "epoch: 134/1000, train loss: 66.3922, test loss: 66.3331\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-585e4f52681a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    188\u001b[0m         \u001b[0mx_train_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[0my_train_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_train_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0my_train_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[0mloss_value_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mis_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow4\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 956\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    957\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow4\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1180\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1181\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow4\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1357\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1359\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1360\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow4\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1363\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1365\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1366\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow4\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1350\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow4\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1443\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1445\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn import utils\n",
    "from functools import partial\n",
    "tf.set_random_seed(777)\n",
    "import sys\n",
    "\n",
    "def norm(Data):\n",
    "    \n",
    "    return ((Data - Data.mean())/Data.std())\n",
    "\n",
    "def preprocess(Data,max_norm=50,min_norm=10):\n",
    "    #normalization\n",
    "    Data = (Data - Data.min())/(Data.max() - Data.min())*(max_norm - min_norm) + min_norm\n",
    "    # for i in range(len(Data.columns)):\n",
    "    #     Data[Data.columns[i]] = (Data[Data.columns[i]] - Data[Data.columns[i]].mean())/Data[Data.columns[i]].std()\n",
    "    #     print('standardized')\n",
    "    #standardization\n",
    "    #for i in range(len(Data.columns)):\n",
    "    #    if Data[Data.columns[i]].std()*3 > (Data[Data.columns[i]].max()-Data[Data.columns[i]].min()):\n",
    "    #        Data[Data.columns[i]] = (Data[Data.columns[i]] - Data[Data.columns[i]].mean())/Data[Data.columns[i]].std()\n",
    "    #        print('standardized %d'%i)\n",
    "    #    else:\n",
    "    #        Data = (Data - Data.min())/(Data.max() - Data.min())*(max_norm - min_norm) + min_norm\n",
    "    return Data\n",
    "\n",
    "# mod = sys.modules[__name__]\n",
    "# num_Data_case = 9\n",
    "# for i in range(num_Data_case):\n",
    "#     setattr(mod,'Data{}'.format(i+1),)\n",
    "    \n",
    "    \n",
    "    \n",
    "Data1 = pd.read_csv(r'D:\\Desktop\\190925\\Python_scripts\\Data\\case1_RANS_wedge_trim.csv')\n",
    "Data2 = pd.read_csv(r'D:\\Desktop\\190925\\Python_scripts\\Data\\case2_RANS_wedge_trim.csv')\n",
    "Data3 = pd.read_csv(r'D:\\Desktop\\190925\\Python_scripts\\Data\\case3_RANS_wedge_trim.csv')\n",
    "# Data4 = pd.read_csv(r'D:\\Desktop\\190925\\wedge_pr_t\\csv_file\\RANS_wedge_Re400_Pr02.csv')\n",
    "# Data5 = pd.read_csv(r'D:\\Desktop\\190925\\wedge_pr_t\\csv_file\\RANS_wedge_Re400_Pr07.csv')\n",
    "# Data6 = pd.read_csv(r'D:\\Desktop\\190925\\wedge_pr_t\\csv_file\\RANS_wedge_Re400_Pr20.csv')\n",
    "# Data7 = pd.read_csv(r'D:\\Desktop\\190925\\wedge_pr_t\\csv_file\\RANS_wedge_Re590_Pr02.csv')\n",
    "# Data8 = pd.read_csv(r'D:\\Desktop\\190925\\wedge_pr_t\\csv_file\\RANS_wedge_Re590_Pr07.csv')\n",
    "# Data9 = pd.read_csv(r'D:\\Desktop\\190925\\wedge_pr_t\\csv_file\\RANS_wedge_Re590_Pr20.csv')\n",
    "# Data10 = pd.read_csv(r'D:\\Desktop\\190925\\wedge_pr_t\\csv_file\\RANS_flat_.csv')\n",
    "# Data10['Re_tau'] = Data10['Re_tau']/1000\n",
    "Data = pd.concat([Data1,Data2,Data3])\n",
    "\n",
    "after_data = pd.DataFrame()\n",
    "after_data['X'] = Data.pop('X')\n",
    "after_data['Y'] = Data.pop('Y')\n",
    "after_data['Re_tau'] = Data.pop('Re_tau')\n",
    "after_data['Pr'] = Data['Pr']\n",
    "after_data['Alpha_t_lsq'] = Data.pop('Alpha_t_lsq')\n",
    "# del Data['Re_tau']\n",
    "# del Data['X']\n",
    "# del Data['Y']\n",
    "# del Data['y_plus']\n",
    "# del Data['wedge_height']\n",
    "# del Data['Alpha_t_lsq']\n",
    "# del Data['Pr']\n",
    "# del Data['Re']\n",
    "\n",
    "# Data = pd.DataFrame()\n",
    "# Data['dk_dx_i_abs'] = data['dk_dx_i_abs']\n",
    "# Data['dT/dx'] = data['dT/dx']\n",
    "# Data['dT/dy'] = data['dT/dy']\n",
    "# # Data['Nu_t_lsq_n'] = data['Nu_t_lsq_n']\n",
    "# Data['PHI-Alpha_t_lsq_n'] = data['PHI-Alpha_t_lsq_n']\n",
    "# # Data['PHI-Pr_t_new'] = data['PHI-Pr_t_new']\n",
    "\n",
    "denorm_min = Data['Pr_t'].min()\n",
    "denorm_max = Data['Pr_t'].max()\n",
    "\n",
    "norm_Data = norm(Data)\n",
    "pre_Data = preprocess(norm_Data)\n",
    "\n",
    "X_Data = pre_Data[pre_Data.columns[:-1]]\n",
    "X_length = len(X_Data.columns)\n",
    "Y_Data = pre_Data[pre_Data.columns[-1:]]\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_Data,Y_Data, test_size=0.33, random_state=42)\n",
    "\n",
    "train_index = y_train.index.values\n",
    "test_index = y_test.index.values\n",
    "\n",
    "# nu_t = x_test['Nu_t_lsq_n']\n",
    "# train_index = x_train['Y']\n",
    "# test_index = x_test['Y']\n",
    "\n",
    "# del x_train['Y']\n",
    "# del x_test['Y']\n",
    "\n",
    "# x_train = norm(x_train)\n",
    "# x_test = norm(x_test)\n",
    "# y_train = norm(y_train)\n",
    "# y_test = norm(y_test)\n",
    "\n",
    "# x_train = preprocess(x_train)\n",
    "# x_test = preprocess(x_test)\n",
    "# y_train = preprocess(y_train)\n",
    "# y_test = preprocess(y_test)\n",
    "\n",
    "# train_index = \n",
    "\n",
    "x_train = x_train.values.tolist()\n",
    "x_test = x_test.values.tolist()\n",
    "y_train = y_train.values.tolist()\n",
    "y_test = y_test.values.tolist()\n",
    "\n",
    "learning_rate = 0.00001\n",
    "l2_reg = 0.0001\n",
    "training = tf.placeholder_with_default(False, shape=[], name=\"training\")\n",
    "batch_norm_momentum = 0.9\n",
    "# n_epochs = 10000\n",
    "# batch_size = 128\n",
    "\n",
    "he_init = tf.keras.initializers.he_normal()\n",
    "l2_regularizer = tf.contrib.layers.l2_regularizer(scale=l2_reg)\n",
    "dense_layer = partial(tf.layers.dense, activation=None,kernel_initializer=he_init,use_bias=True, kernel_regularizer=l2_regularizer)\n",
    "batch_norm_layer = partial(tf.layers.batch_normalization, training=training, momentum=batch_norm_momentum)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, X_length])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "hidden1 = dense_layer(X,40)\n",
    "bn1 = batch_norm_layer(hidden1)\n",
    "bn1_act = tf.nn.tanh(bn1)\n",
    "# hidden1 = tf.layers.dropout(hidden1, 0.8, is_training)\n",
    "hidden2 = dense_layer(bn1_act,40)\n",
    "bn2 = batch_norm_layer(hidden2)\n",
    "bn2_act = tf.nn.tanh(bn2)\n",
    "hidden3 = dense_layer(bn2_act,40)\n",
    "bn3 = batch_norm_layer(hidden3)\n",
    "bn3_act = tf.nn.tanh(bn3)\n",
    "hidden4 = dense_layer(bn3_act,40)\n",
    "bn4 = batch_norm_layer(hidden4)\n",
    "bn4_act = tf.nn.tanh(bn4)\n",
    "hidden5 = dense_layer(bn4_act,32)\n",
    "bn5 = batch_norm_layer(hidden5)\n",
    "bn5_act = tf.nn.tanh(bn5)\n",
    "hidden6 = dense_layer(bn5_act,16)\n",
    "bn6 = batch_norm_layer(hidden6)\n",
    "bn6_act = tf.nn.tanh(bn6)\n",
    "hidden7 = dense_layer(bn6_act,16)\n",
    "bn7 = batch_norm_layer(hidden7)\n",
    "bn7_act = tf.nn.tanh(bn7)\n",
    "hidden8 = dense_layer(bn7_act,8)\n",
    "bn8 = batch_norm_layer(hidden8)\n",
    "bn8_act = tf.nn.tanh(bn8)\n",
    "hidden9 = dense_layer(bn8_act,8)\n",
    "bn9 = batch_norm_layer(hidden9)\n",
    "bn9_act = tf.nn.tanh(bn9)\n",
    "hidden10 = dense_layer(bn9_act,8)\n",
    "bn10 = batch_norm_layer(hidden10)\n",
    "bn10_act = tf.nn.tanh(bn10)\n",
    "hidden11 = dense_layer(bn10_act,1,use_bias=False)\n",
    "\n",
    "reconstruction_loss = tf.reduce_mean(tf.square(hidden11 - Y))\n",
    "reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "loss = tf.add_n([reconstruction_loss] + reg_losses)\n",
    "\n",
    "train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.local_variables_initializer())\n",
    "\n",
    "# while math.isnan(sess.run(reconstruction_loss),feed_dict={X: x_test, Y: y_test, is_training: False}) == True:\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "#     sess.run(tf.local_variables_initializer())\n",
    "    \n",
    "num_over = 0\n",
    "epochs = 1000\n",
    "batch_size = 256\n",
    "shuffle = True\n",
    "\n",
    "for epoch_index in range(epochs):\n",
    "    if shuffle:\n",
    "        utils.shuffle(x_train, y_train)\n",
    "    total_batch = int(np.ceil(len(x_train) / batch_size))\n",
    "    for batch_index in range(total_batch):\n",
    "        start = batch_index*batch_size\n",
    "        end = start + batch_size\n",
    "        x_train_batch = x_train[start:end]\n",
    "        y_train_batch = y_train[start:end]\n",
    "        sess.run(train_op, feed_dict={X: x_train_batch, Y:y_train_batch,is_training:True})\n",
    "    \n",
    "    loss_value_train = sess.run(loss, feed_dict={X: x_train, Y: y_train,is_training:False})\n",
    "    loss_value_test = sess.run(loss, feed_dict={X: x_test, Y: y_test,is_training:False})\n",
    "    print('epoch: {}/{}, train loss: {:.4f}, test loss: {:.4f}'.format(epoch_index+1,epochs,loss_value_train,loss_value_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 2/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 3/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 4/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 5/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 6/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 7/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 8/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 9/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 10/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 11/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 12/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 13/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 14/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 15/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 16/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 17/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 18/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 19/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 20/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 21/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 22/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 23/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 24/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 25/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 26/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 27/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 28/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 29/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 30/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 31/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 32/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 33/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 34/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 35/1000, train loss: 0.0098, test loss: 0.0100\n",
      "epoch: 36/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 37/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 38/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 39/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 40/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 41/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 42/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 43/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 44/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 45/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 46/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 47/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 48/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 49/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 50/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 51/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 52/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 53/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 54/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 55/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 56/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 57/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 58/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 59/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 60/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 61/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 62/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 63/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 64/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 65/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 66/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 67/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 68/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 69/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 70/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 71/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 72/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 73/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 74/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 75/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 76/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 77/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 78/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 79/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 80/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 81/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 82/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 83/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 84/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 85/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 86/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 87/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 88/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 89/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 90/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 91/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 92/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 93/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 94/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 95/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 96/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 97/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 98/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 99/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 100/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 101/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 102/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 103/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 104/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 105/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 106/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 107/1000, train loss: 0.0097, test loss: 0.0100\n",
      "epoch: 108/1000, train loss: 0.0097, test loss: 0.0099\n",
      "epoch: 109/1000, train loss: 0.0097, test loss: 0.0099\n",
      "epoch: 110/1000, train loss: 0.0097, test loss: 0.0099\n",
      "epoch: 111/1000, train loss: 0.0097, test loss: 0.0099\n",
      "epoch: 112/1000, train loss: 0.0097, test loss: 0.0099\n",
      "epoch: 113/1000, train loss: 0.0097, test loss: 0.0099\n"
     ]
    }
   ],
   "source": [
    "for epoch_index in range(epochs):\n",
    "    if shuffle:\n",
    "        utils.shuffle(x_train, y_train)\n",
    "    total_batch = int(np.ceil(len(x_train) / batch_size))\n",
    "    for batch_index in range(total_batch):\n",
    "        start = batch_index*batch_size\n",
    "        end = start + batch_size\n",
    "        x_train_batch = x_train[start:end]\n",
    "        y_train_batch = y_train[start:end]\n",
    "        sess.run(train_op, feed_dict={X: x_train_batch, Y:y_train_batch,is_training:True})\n",
    "    \n",
    "    loss_value_train = sess.run(loss, feed_dict={X: x_train, Y: y_train,is_training:False})\n",
    "    loss_value_test = sess.run(loss, feed_dict={X: x_test, Y: y_test,is_training:False})\n",
    "    print('epoch: {}/{}, train loss: {:.4f}, test loss: {:.4f}'.format(epoch_index+1,epochs,loss_value_train,loss_value_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1bb1ae0b940>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.scatter(sess.run(hidden11,feed_dict={X: x_train, is_training:False}),y_train,s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19.908384,\n",
       " 19.549536,\n",
       " 19.287622,\n",
       " 19.1533,\n",
       " 19.152231,\n",
       " 19.279861,\n",
       " 19.5287,\n",
       " 19.883911,\n",
       " 20.31128,\n",
       " 20.750057,\n",
       " 21.136719,\n",
       " 21.44853,\n",
       " 21.67739,\n",
       " 21.782804,\n",
       " 21.803646,\n",
       " 21.821043,\n",
       " 21.823824,\n",
       " 21.869534,\n",
       " 21.965271,\n",
       " 22.15502,\n",
       " 22.334757,\n",
       " 22.492622,\n",
       " 22.614525,\n",
       " 22.704483,\n",
       " 22.777018,\n",
       " 22.849422,\n",
       " 22.945005,\n",
       " 23.045094,\n",
       " 23.140882,\n",
       " 23.230694,\n",
       " 23.313286,\n",
       " 23.387629,\n",
       " 23.453194,\n",
       " 23.509327,\n",
       " 23.553946,\n",
       " 23.583023,\n",
       " 23.592209,\n",
       " 23.579927,\n",
       " 23.549706,\n",
       " 23.509193,\n",
       " 23.466484,\n",
       " 23.425686,\n",
       " 23.383753,\n",
       " 23.330622,\n",
       " 23.254728,\n",
       " 23.151346,\n",
       " 23.0232,\n",
       " 22.876467,\n",
       " 22.71888,\n",
       " 22.557884,\n",
       " 22.398348,\n",
       " 22.241083,\n",
       " 22.083384,\n",
       " 21.92089,\n",
       " 21.750324,\n",
       " 21.572506,\n",
       " 21.392754,\n",
       " 21.218468,\n",
       " 21.065527,\n",
       " 20.880457,\n",
       " 20.756107,\n",
       " 20.63118,\n",
       " 20.495495,\n",
       " 20.358543,\n",
       " 20.222754,\n",
       " 20.090736,\n",
       " 19.962475,\n",
       " 19.834991,\n",
       " 19.705254,\n",
       " 19.573776,\n",
       " 19.443556,\n",
       " 19.316732,\n",
       " 19.193272,\n",
       " 19.072433,\n",
       " 18.953842,\n",
       " 18.837723,\n",
       " 18.724829,\n",
       " 18.617115,\n",
       " 18.517351,\n",
       " 18.427511,\n",
       " 18.347164,\n",
       " 18.273615,\n",
       " 18.204462,\n",
       " 18.138645,\n",
       " 18.074987,\n",
       " 18.011488,\n",
       " 17.946556,\n",
       " 17.878777,\n",
       " 17.806047,\n",
       " 17.727587,\n",
       " 17.644964,\n",
       " 17.561445,\n",
       " 17.479183,\n",
       " 17.397268,\n",
       " 17.312391,\n",
       " 17.224304,\n",
       " 17.138084,\n",
       " 17.059738,\n",
       " 16.991404,\n",
       " 16.932579,\n",
       " 16.880043,\n",
       " 16.827034,\n",
       " 16.7664,\n",
       " 16.697346,\n",
       " 16.625637,\n",
       " 16.557684,\n",
       " 16.495539,\n",
       " 16.436632,\n",
       " 20.846777,\n",
       " 20.729094,\n",
       " 20.627775,\n",
       " 20.540276,\n",
       " 20.461252,\n",
       " 20.388773,\n",
       " 20.326628,\n",
       " 20.281124,\n",
       " 20.255123,\n",
       " 20.247362,\n",
       " 20.257318,\n",
       " 20.287498,\n",
       " 20.339415,\n",
       " 20.409254,\n",
       " 20.487417,\n",
       " 20.56219,\n",
       " 20.624874,\n",
       " 20.672617,\n",
       " 20.708887,\n",
       " 20.741346,\n",
       " 20.776848,\n",
       " 20.817032,\n",
       " 20.859337,\n",
       " 20.900513,\n",
       " 20.938246,\n",
       " 20.971354,\n",
       " 21.000343,\n",
       " 21.027826,\n",
       " 21.056671,\n",
       " 21.088514,\n",
       " 21.124876,\n",
       " 21.170292,\n",
       " 21.227755,\n",
       " 21.289558,\n",
       " 21.373009,\n",
       " 21.462803,\n",
       " 21.556494,\n",
       " 21.650486,\n",
       " 21.743523,\n",
       " 21.83644,\n",
       " 21.930523,\n",
       " 22.025816,\n",
       " 22.120913,\n",
       " 22.213577,\n",
       " 22.302225,\n",
       " 22.386086,\n",
       " 22.466537,\n",
       " 22.545568,\n",
       " 22.620045,\n",
       " 22.67832,\n",
       " 22.708746,\n",
       " 22.709965,\n",
       " 22.690563,\n",
       " 22.661142,\n",
       " 22.629042,\n",
       " 22.597824,\n",
       " 22.56829,\n",
       " 22.53942,\n",
       " 22.508879,\n",
       " 22.473856,\n",
       " 22.430796,\n",
       " 22.375946,\n",
       " 22.30643,\n",
       " 22.221262,\n",
       " 22.1214,\n",
       " 22.009523,\n",
       " 21.889223,\n",
       " 21.764214,\n",
       " 21.637486,\n",
       " 21.510944,\n",
       " 21.385653,\n",
       " 21.262314,\n",
       " 21.141846,\n",
       " 21.024979,\n",
       " 20.915283,\n",
       " 20.782848,\n",
       " 20.693165,\n",
       " 20.60386,\n",
       " 20.490719,\n",
       " 20.330856,\n",
       " 20.184177,\n",
       " 20.056614,\n",
       " 19.952856,\n",
       " 19.876417,\n",
       " 19.829264,\n",
       " 19.811256,\n",
       " 19.814266,\n",
       " 19.813807,\n",
       " 19.782639,\n",
       " 19.741879,\n",
       " 19.741224,\n",
       " 19.743538,\n",
       " 19.6799,\n",
       " 19.596415,\n",
       " 19.60831,\n",
       " 19.624136,\n",
       " 19.587893,\n",
       " 19.55386,\n",
       " 19.581732,\n",
       " 19.61312,\n",
       " 19.573217,\n",
       " 19.45304,\n",
       " 19.261686,\n",
       " 14.745681,\n",
       " 14.6406765,\n",
       " 14.741553,\n",
       " 15.010865,\n",
       " 15.415426,\n",
       " 15.932095,\n",
       " 16.54425,\n",
       " 17.229067,\n",
       " 17.941679,\n",
       " 18.61537,\n",
       " 19.206554,\n",
       " 19.72033,\n",
       " 20.139103,\n",
       " 20.420723,\n",
       " 20.610931,\n",
       " 20.779207,\n",
       " 20.952127,\n",
       " 21.109108,\n",
       " 21.371511,\n",
       " 21.565485,\n",
       " 21.732733,\n",
       " 21.86435,\n",
       " 21.964914,\n",
       " 22.048721,\n",
       " 22.132881,\n",
       " 22.232666,\n",
       " 22.377914,\n",
       " 22.521275,\n",
       " 22.65814,\n",
       " 22.78592,\n",
       " 22.902401,\n",
       " 23.006023,\n",
       " 23.096268,\n",
       " 23.173332,\n",
       " 23.236378,\n",
       " 23.28196,\n",
       " 23.305075,\n",
       " 23.302536,\n",
       " 23.276966,\n",
       " 23.237324,\n",
       " 23.194504,\n",
       " 23.155338,\n",
       " 23.118227,\n",
       " 23.073372,\n",
       " 23.00893,\n",
       " 22.919277,\n",
       " 22.805754,\n",
       " 22.672874,\n",
       " 22.52687,\n",
       " 22.374702,\n",
       " 22.22129,\n",
       " 22.06803,\n",
       " 21.912611,\n",
       " 21.750834,\n",
       " 21.579538,\n",
       " 21.39992,\n",
       " 21.217714,\n",
       " 21.040855,\n",
       " 20.876335,\n",
       " 20.7036,\n",
       " 20.592577,\n",
       " 20.463974,\n",
       " 20.336016,\n",
       " 20.206501,\n",
       " 20.07743,\n",
       " 19.951342,\n",
       " 19.828266,\n",
       " 19.70554,\n",
       " 19.580446,\n",
       " 19.4534,\n",
       " 19.32751,\n",
       " 19.205063,\n",
       " 19.085411,\n",
       " 18.967243,\n",
       " 18.850235,\n",
       " 18.734774,\n",
       " 18.622,\n",
       " 18.514345,\n",
       " 18.414951,\n",
       " 18.325956,\n",
       " 18.24655,\n",
       " 18.17383,\n",
       " 18.105051,\n",
       " 18.03925,\n",
       " 17.97572,\n",
       " 17.912947,\n",
       " 17.84924,\n",
       " 17.783045,\n",
       " 17.71208,\n",
       " 17.635273,\n",
       " 17.554321,\n",
       " 17.472258,\n",
       " 17.391457,\n",
       " 17.31103,\n",
       " 17.227772,\n",
       " 17.141161,\n",
       " 17.056038,\n",
       " 16.978577,\n",
       " 16.91091,\n",
       " 16.852283,\n",
       " 16.799526,\n",
       " 16.745926,\n",
       " 16.684649,\n",
       " 16.615171,\n",
       " 16.543507,\n",
       " 16.475819,\n",
       " 16.413805,\n",
       " 16.355078,\n",
       " 20.795479,\n",
       " 20.680798,\n",
       " 20.581795,\n",
       " 20.495722,\n",
       " 20.41757,\n",
       " 20.345573,\n",
       " 20.28399,\n",
       " 20.239191,\n",
       " 20.214071,\n",
       " 20.207464,\n",
       " 20.219496,\n",
       " 20.252794,\n",
       " 20.308199,\n",
       " 20.38049,\n",
       " 20.459192,\n",
       " 20.53294,\n",
       " 20.594028,\n",
       " 20.6405,\n",
       " 20.676386,\n",
       " 20.709032,\n",
       " 20.744345,\n",
       " 20.78338,\n",
       " 20.823717,\n",
       " 20.862707,\n",
       " 20.898361,\n",
       " 20.929554,\n",
       " 20.956997,\n",
       " 20.983385,\n",
       " 21.01187,\n",
       " 21.043976,\n",
       " 21.081072,\n",
       " 21.125923,\n",
       " 21.186907,\n",
       " 21.252316,\n",
       " 21.335083,\n",
       " 21.426252,\n",
       " 21.520895,\n",
       " 21.615294,\n",
       " 21.708302,\n",
       " 21.800844,\n",
       " 21.89453,\n",
       " 21.989536,\n",
       " 22.084448,\n",
       " 22.177092,\n",
       " 22.265686,\n",
       " 22.349648,\n",
       " 22.430653,\n",
       " 22.510944,\n",
       " 22.586998,\n",
       " 22.646505,\n",
       " 22.677708,\n",
       " 22.679674,\n",
       " 22.661129,\n",
       " 22.63258,\n",
       " 22.60119,\n",
       " 22.570484,\n",
       " 22.541256,\n",
       " 22.512527,\n",
       " 22.482176,\n",
       " 22.447456,\n",
       " 22.404987,\n",
       " 22.351023,\n",
       " 22.282497,\n",
       " 22.198275,\n",
       " 22.099173,\n",
       " 21.987667,\n",
       " 21.8675,\n",
       " 21.742405,\n",
       " 21.61532,\n",
       " 21.48821,\n",
       " 21.362202,\n",
       " 21.23807,\n",
       " 21.116762,\n",
       " 20.99935,\n",
       " 20.886047,\n",
       " 20.758823,\n",
       " 20.675997,\n",
       " 20.575705,\n",
       " 20.466637,\n",
       " 20.307884,\n",
       " 20.161734,\n",
       " 20.034513,\n",
       " 19.93085,\n",
       " 19.85406,\n",
       " 19.80621,\n",
       " 19.787296,\n",
       " 19.789867,\n",
       " 19.789825,\n",
       " 19.75944,\n",
       " 19.718197,\n",
       " 19.716839,\n",
       " 19.719418,\n",
       " 19.655396,\n",
       " 19.574867,\n",
       " 19.594288,\n",
       " 19.61486,\n",
       " 19.581568,\n",
       " 19.552233,\n",
       " 19.581924,\n",
       " 19.606691,\n",
       " 19.558886,\n",
       " 19.43558,\n",
       " 19.248274,\n",
       " 12.456037,\n",
       " 12.478802,\n",
       " 12.6733675,\n",
       " 13.029449,\n",
       " 13.510589,\n",
       " 14.075924,\n",
       " 14.702332,\n",
       " 15.380049,\n",
       " 16.101032,\n",
       " 16.839008,\n",
       " 17.556225,\n",
       " 18.247253,\n",
       " 18.873425,\n",
       " 19.336662,\n",
       " 19.668531,\n",
       " 19.953232,\n",
       " 20.21052,\n",
       " 20.473606,\n",
       " 20.708904,\n",
       " 20.914335,\n",
       " 21.082218,\n",
       " 21.216234,\n",
       " 21.329918,\n",
       " 21.439451,\n",
       " 21.558804,\n",
       " 21.702976,\n",
       " 21.879217,\n",
       " 22.053806,\n",
       " 22.22168,\n",
       " 22.378742,\n",
       " 22.521511,\n",
       " 22.647547,\n",
       " 22.756357,\n",
       " 22.849215,\n",
       " 22.926325,\n",
       " 22.98502,\n",
       " 23.020288,\n",
       " 23.028053,\n",
       " 23.009922,\n",
       " 22.974981,\n",
       " 22.935274,\n",
       " 22.899118,\n",
       " 22.865946,\n",
       " 22.826733,\n",
       " 22.770325,\n",
       " 22.691565,\n",
       " 22.590963,\n",
       " 22.471403,\n",
       " 22.3377,\n",
       " 22.195728,\n",
       " 22.050291,\n",
       " 21.902864,\n",
       " 21.751467,\n",
       " 21.591995,\n",
       " 21.42169,\n",
       " 21.242308,\n",
       " 21.05981,\n",
       " 20.88223,\n",
       " 20.716902,\n",
       " 20.54489,\n",
       " 20.434862,\n",
       " 20.310556,\n",
       " 20.188976,\n",
       " 20.06667,\n",
       " 19.944187,\n",
       " 19.823158,\n",
       " 19.703808,\n",
       " 19.584396,\n",
       " 19.463148,\n",
       " 19.340475,\n",
       " 19.21899,\n",
       " 19.100483,\n",
       " 18.984324,\n",
       " 18.869024,\n",
       " 18.754047,\n",
       " 18.639635,\n",
       " 18.527214,\n",
       " 18.419716,\n",
       " 18.320787,\n",
       " 18.23263,\n",
       " 18.15441,\n",
       " 18.082672,\n",
       " 18.01434,\n",
       " 17.94856,\n",
       " 17.885033,\n",
       " 17.822767,\n",
       " 17.760105,\n",
       " 17.6953,\n",
       " 17.626043,\n",
       " 17.550896,\n",
       " 17.471352,\n",
       " 17.390423,\n",
       " 17.310865,\n",
       " 17.231844,\n",
       " 17.15016,\n",
       " 17.06505,\n",
       " 16.981314,\n",
       " 16.904833,\n",
       " 16.837831,\n",
       " 16.779205,\n",
       " 16.725925,\n",
       " 16.671673,\n",
       " 16.610075,\n",
       " 16.540876,\n",
       " 16.469849,\n",
       " 16.40303,\n",
       " 16.341902,\n",
       " 16.283472,\n",
       " 20.734566,\n",
       " 20.623781,\n",
       " 20.52772,\n",
       " 20.443708,\n",
       " 20.366928,\n",
       " 20.296041,\n",
       " 20.235552,\n",
       " 20.19212,\n",
       " 20.16851,\n",
       " 20.163694,\n",
       " 20.178347,\n",
       " 20.215239,\n",
       " 20.27412,\n",
       " 20.348509,\n",
       " 20.427382,\n",
       " 20.499956,\n",
       " 20.559515,\n",
       " 20.605103,\n",
       " 20.640997,\n",
       " 20.67399,\n",
       " 20.709047,\n",
       " 20.746912,\n",
       " 20.78548,\n",
       " 20.822521,\n",
       " 20.856264,\n",
       " 20.885668,\n",
       " 20.91165,\n",
       " 20.937344,\n",
       " 20.9657,\n",
       " 20.998468,\n",
       " 21.036634,\n",
       " 21.083044,\n",
       " 21.143736,\n",
       " 21.213284,\n",
       " 21.29767,\n",
       " 21.390085,\n",
       " 21.485643,\n",
       " 21.5804,\n",
       " 21.673254,\n",
       " 21.765617,\n",
       " 21.859037,\n",
       " 21.953842,\n",
       " 22.048662,\n",
       " 22.141203,\n",
       " 22.229553,\n",
       " 22.313375,\n",
       " 22.394772,\n",
       " 22.476236,\n",
       " 22.553642,\n",
       " 22.61401,\n",
       " 22.645632,\n",
       " 22.648073,\n",
       " 22.630318,\n",
       " 22.602772,\n",
       " 22.572332,\n",
       " 22.54225,\n",
       " 22.51334,\n",
       " 22.48475,\n",
       " 22.454609,\n",
       " 22.420332,\n",
       " 22.378435,\n",
       " 22.325184,\n",
       " 22.257528,\n",
       " 22.174147,\n",
       " 22.075787,\n",
       " 21.964909,\n",
       " 21.845114,\n",
       " 21.720112,\n",
       " 21.592873,\n",
       " 21.465357,\n",
       " 21.338734,\n",
       " 21.213932,\n",
       " 21.091995,\n",
       " 20.973978,\n",
       " 20.860132,\n",
       " 20.732475,\n",
       " 20.649437,\n",
       " 20.549118,\n",
       " 20.440279,\n",
       " 20.282116,\n",
       " 20.136616,\n",
       " 20.010109,\n",
       " 19.907057,\n",
       " 19.830692,\n",
       " 19.78292,\n",
       " 19.76385,\n",
       " 19.766155,\n",
       " 19.765806,\n",
       " 19.735226,\n",
       " 19.693464,\n",
       " 19.69144,\n",
       " 19.693165,\n",
       " 19.626831,\n",
       " 19.544836,\n",
       " 19.564009,\n",
       " 19.583918,\n",
       " 19.549177,\n",
       " 19.519453,\n",
       " 19.549448,\n",
       " 19.572943,\n",
       " 19.523287,\n",
       " 19.398653,\n",
       " 19.211143,\n",
       " 11.801357,\n",
       " 11.56914,\n",
       " 11.578182,\n",
       " 11.816323,\n",
       " 12.217493,\n",
       " 12.746585,\n",
       " 13.350637,\n",
       " 13.993921,\n",
       " 14.664184,\n",
       " 15.338486,\n",
       " 15.9816885,\n",
       " 16.603378,\n",
       " 17.252018,\n",
       " 17.896215,\n",
       " 18.4207,\n",
       " 18.80835,\n",
       " 19.13338,\n",
       " 19.331272,\n",
       " 19.752703,\n",
       " 20.019026,\n",
       " 20.247446,\n",
       " 20.437553,\n",
       " 20.600237,\n",
       " 20.750982,\n",
       " 20.903599,\n",
       " 21.06799,\n",
       " 21.248861,\n",
       " 21.440266,\n",
       " 21.633512,\n",
       " 21.821756,\n",
       " 21.999147,\n",
       " 22.160654,\n",
       " 22.302687,\n",
       " 22.424938,\n",
       " 22.529629,\n",
       " 22.61796,\n",
       " 22.687883,\n",
       " 22.73473,\n",
       " 22.753912,\n",
       " 22.745735,\n",
       " 22.718178,\n",
       " 22.683388,\n",
       " 22.650423,\n",
       " 22.619848,\n",
       " 22.583838,\n",
       " 22.532965,\n",
       " 22.4632,\n",
       " 22.374699,\n",
       " 22.268866,\n",
       " 22.14879,\n",
       " 22.019232,\n",
       " 21.884167,\n",
       " 21.7451,\n",
       " 21.600277,\n",
       " 21.445704,\n",
       " 21.279001,\n",
       " 21.102156,\n",
       " 20.921146,\n",
       " 20.743818,\n",
       " 20.577654,\n",
       " 20.40534,\n",
       " 20.294075,\n",
       " 20.171589,\n",
       " 20.054136,\n",
       " 19.937263,\n",
       " 19.820063,\n",
       " 19.70306,\n",
       " 19.586426,\n",
       " 19.46956,\n",
       " 19.351608,\n",
       " 19.233072,\n",
       " 19.115826,\n",
       " 19.001215,\n",
       " 18.888552,\n",
       " 18.776247,\n",
       " 18.663383,\n",
       " 18.55018,\n",
       " 18.438246,\n",
       " 18.330957,\n",
       " 18.23241,\n",
       " 18.145096,\n",
       " 18.067966,\n",
       " 17.99723,\n",
       " 17.9294,\n",
       " 17.863544,\n",
       " 17.799913,\n",
       " 17.737974,\n",
       " 17.67618,\n",
       " 17.612644,\n",
       " 17.544897,\n",
       " 17.471432,\n",
       " 17.393118,\n",
       " 17.313238,\n",
       " 17.234535,\n",
       " 17.15665,\n",
       " 17.076347,\n",
       " 16.992641,\n",
       " 16.910097,\n",
       " 16.834476,\n",
       " 16.767752,\n",
       " 16.708872,\n",
       " 16.654905,\n",
       " 16.599916,\n",
       " 16.537914,\n",
       " 16.468779,\n",
       " 16.398249,\n",
       " 16.332216,\n",
       " 16.27178,\n",
       " 16.21368,\n",
       " 20.67167,\n",
       " 20.564878,\n",
       " 20.471928,\n",
       " 20.39009,\n",
       " 20.314718,\n",
       " 20.244928,\n",
       " 20.18564,\n",
       " 20.143671,\n",
       " 20.121662,\n",
       " 20.118858,\n",
       " 20.136421,\n",
       " 20.176973,\n",
       " 20.239138,\n",
       " 20.315298,\n",
       " 20.394028,\n",
       " 20.465254,\n",
       " 20.523365,\n",
       " 20.568264,\n",
       " 20.604336,\n",
       " 20.63763,\n",
       " 20.672304,\n",
       " 20.708908,\n",
       " 20.74575,\n",
       " 20.78099,\n",
       " 20.812916,\n",
       " 20.84064,\n",
       " 20.86547,\n",
       " 20.890644,\n",
       " 20.9192,\n",
       " 20.952702,\n",
       " 20.992159,\n",
       " 21.040274,\n",
       " 21.100586,\n",
       " 21.178165,\n",
       " 21.260382,\n",
       " 21.353994,\n",
       " 21.450275,\n",
       " 21.545279,\n",
       " 21.638117,\n",
       " 21.730268,\n",
       " 21.8235,\n",
       " 21.918137,\n",
       " 22.012833,\n",
       " 22.105156,\n",
       " 22.193132,\n",
       " 22.276579,\n",
       " 22.358294,\n",
       " 22.440958,\n",
       " 22.519634,\n",
       " 22.580732,\n",
       " 22.612757,\n",
       " 22.615694,\n",
       " 22.598833,\n",
       " 22.572418,\n",
       " 22.542984,\n",
       " 22.513512,\n",
       " 22.48486,\n",
       " 22.456387,\n",
       " 22.426428,\n",
       " 22.392506,\n",
       " 22.351181,\n",
       " 22.29862,\n",
       " 22.231739,\n",
       " 22.14918,\n",
       " 22.051537,\n",
       " 21.941223,\n",
       " 21.821774,\n",
       " 21.696821,\n",
       " 21.569382,\n",
       " 21.441328,\n",
       " 21.314018,\n",
       " 21.188467,\n",
       " 21.06587,\n",
       " 20.947369,\n",
       " 20.833124,\n",
       " 20.705383,\n",
       " 20.62198,\n",
       " 20.521605,\n",
       " 20.41295,\n",
       " 20.25536,\n",
       " 20.110548,\n",
       " 19.984688,\n",
       " 19.882254,\n",
       " 19.806242,\n",
       " 19.75861,\n",
       " 19.739523,\n",
       " 19.741669,\n",
       " 19.741201,\n",
       " 19.710459,\n",
       " 19.668308,\n",
       " 19.665716,\n",
       " 19.666666,\n",
       " 19.598083,\n",
       " 19.514843,\n",
       " 19.533875,\n",
       " 19.5532,\n",
       " 19.51714,\n",
       " 19.487223,\n",
       " 19.517548,\n",
       " 19.5398,\n",
       " 19.48822,\n",
       " 19.362316,\n",
       " 19.174582,\n",
       " 11.7241,\n",
       " 11.595916,\n",
       " 11.528584,\n",
       " 11.599912,\n",
       " 11.906076,\n",
       " 12.408885,\n",
       " 13.012988,\n",
       " 13.654474,\n",
       " 14.31215,\n",
       " 14.956565,\n",
       " 15.548187,\n",
       " 16.094637,\n",
       " 16.631565,\n",
       " 17.161097,\n",
       " 17.658709,\n",
       " 18.075216,\n",
       " 18.402338,\n",
       " 18.771063,\n",
       " 19.089794,\n",
       " 19.379763,\n",
       " 19.634712,\n",
       " 19.858538,\n",
       " 20.062927,\n",
       " 20.26044,\n",
       " 20.46055,\n",
       " 20.668913,\n",
       " 20.869354,\n",
       " 21.064716,\n",
       " 21.265709,\n",
       " 21.464794,\n",
       " 21.6544,\n",
       " 21.82748,\n",
       " 21.979599,\n",
       " 22.110952,\n",
       " 22.224575,\n",
       " 22.32216,\n",
       " 22.402071,\n",
       " 22.459917,\n",
       " 22.4908,\n",
       " 22.493578,\n",
       " 22.474443,\n",
       " 22.444855,\n",
       " 22.414328,\n",
       " 22.384455,\n",
       " 22.349094,\n",
       " 22.301146,\n",
       " 22.23815,\n",
       " 22.16022,\n",
       " 22.067621,\n",
       " 21.962004,\n",
       " 21.84662,\n",
       " 21.724476,\n",
       " 21.596529,\n",
       " 21.460928,\n",
       " 21.31396,\n",
       " 21.153393,\n",
       " 20.981262,\n",
       " 20.803411,\n",
       " 20.627396,\n",
       " 20.460579,\n",
       " 20.287407,\n",
       " 20.17273,\n",
       " 20.049463,\n",
       " 19.933426,\n",
       " 19.819714,\n",
       " 19.705976,\n",
       " 19.591595,\n",
       " 19.476625,\n",
       " 19.361403,\n",
       " 19.246237,\n",
       " 19.131458,\n",
       " 19.018284,\n",
       " 18.907537,\n",
       " 18.798363,\n",
       " 18.689077,\n",
       " 18.578514,\n",
       " 18.466692,\n",
       " 18.355307,\n",
       " 18.248257,\n",
       " 18.1501,\n",
       " 18.063562,\n",
       " 17.98748,\n",
       " 17.91775,\n",
       " 17.85048,\n",
       " 17.784561,\n",
       " 17.720833,\n",
       " 17.65909,\n",
       " 17.597977,\n",
       " 17.53557,\n",
       " 17.4693,\n",
       " 17.397154,\n",
       " 17.32006,\n",
       " 17.241093,\n",
       " 17.163105,\n",
       " 17.085957,\n",
       " 17.006645,\n",
       " 16.924248,\n",
       " 16.842741,\n",
       " 16.767801,\n",
       " 16.701185,\n",
       " 16.641829,\n",
       " 16.58693,\n",
       " 16.530972,\n",
       " 16.468452,\n",
       " 16.399277,\n",
       " 16.329197,\n",
       " 16.263714,\n",
       " 16.203909,\n",
       " 16.14595,\n",
       " 20.606487,\n",
       " 20.50392,\n",
       " 20.414175,\n",
       " 20.334557,\n",
       " 20.26074,\n",
       " 20.192028,\n",
       " 20.13402,\n",
       " 20.093666,\n",
       " 20.073477,\n",
       " 20.07288,\n",
       " 20.093594,\n",
       " 20.13781,\n",
       " 20.203009,\n",
       " 20.28059,\n",
       " 20.358961,\n",
       " 20.42876,\n",
       " 20.485548,\n",
       " 20.529957,\n",
       " 20.566294,\n",
       " 20.599808,\n",
       " 20.63399,\n",
       " 20.66932,\n",
       " 20.704521,\n",
       " 20.738062,\n",
       " 20.76827,\n",
       " 20.794493,\n",
       " 20.81836,\n",
       " 20.843277,\n",
       " 20.872303,\n",
       " 20.906734,\n",
       " 20.94772,\n",
       " 20.997711,\n",
       " 21.059977,\n",
       " 21.137657,\n",
       " 21.223154,\n",
       " 21.31785,\n",
       " 21.414791,\n",
       " 21.510145,\n",
       " 21.603022,\n",
       " 21.695099,\n",
       " 21.788185,\n",
       " 21.882746,\n",
       " 21.977331,\n",
       " 22.069387,\n",
       " 22.156797,\n",
       " 22.239895,\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data = sess.run(hidden11, feed_dict={X: X_Data, Y: Y_Data })\n",
    "model_data1 = [model_data[i][0] for i in range(len(model_data))]\n",
    "model_data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Re_tau</th>\n",
       "      <th>Alpha_t_lsq</th>\n",
       "      <th>ANN_Pr_t</th>\n",
       "      <th>DNN_Pr_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.076720</td>\n",
       "      <td>180</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>19.908384</td>\n",
       "      <td>19.012569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.074086</td>\n",
       "      <td>180</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>19.549536</td>\n",
       "      <td>19.530524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.071392</td>\n",
       "      <td>180</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>19.287622</td>\n",
       "      <td>19.954093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.068635</td>\n",
       "      <td>180</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>19.153299</td>\n",
       "      <td>20.296938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.065814</td>\n",
       "      <td>180</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>19.152231</td>\n",
       "      <td>20.572195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              X         Y  Re_tau  Alpha_t_lsq   ANN_Pr_t   DNN_Pr_t\n",
       "0 -5.000000e-09 -0.076720     180     0.000022  19.908384  19.012569\n",
       "1 -5.000000e-09 -0.074086     180     0.000029  19.549536  19.530524\n",
       "2 -5.000000e-09 -0.071392     180     0.000037  19.287622  19.954093\n",
       "3 -5.000000e-09 -0.068635     180     0.000047  19.153299  20.296938\n",
       "4 -5.000000e-09 -0.065814     180     0.000058  19.152231  20.572195"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "after_data['ANN_Pr_t'] = model_data1\n",
    "after_data['DNN_Pr_t'] = Y_Data\n",
    "after_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "after_data.to_csv(r'D:\\Desktop\\190925\\wedge_pr_t\\results\\softplus.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             count      mean       std       min       25%       50%  \\\n",
      "Nu_t_lsq  271950.0  0.002727  0.001812  0.000002  0.000744  0.003311   \n",
      "tke       271950.0  0.007270  0.003245  0.001561  0.004451  0.006803   \n",
      "tke_diss  271950.0 -0.001688  0.001240 -0.005468 -0.002992 -0.001319   \n",
      "dk/dx     271950.0 -0.000013  0.001948 -0.010422 -0.000247 -0.000034   \n",
      "dk/dy     271950.0 -0.000632  0.086369 -0.275915 -0.015030  0.000347   \n",
      "\n",
      "               75%       max  \n",
      "Nu_t_lsq  0.004284  0.005976  \n",
      "tke       0.009933  0.015415  \n",
      "tke_diss -0.000521 -0.000188  \n",
      "dk/dx     0.000195  0.008786  \n",
      "dk/dy     0.016286  0.320624  \n",
      "             count          mean  std       min       25%       50%       75%  \\\n",
      "Nu_t_lsq  271950.0  1.960069e-14  1.0 -1.503612 -1.094030  0.322309  0.859040   \n",
      "tke       271950.0 -4.067560e-16  1.0 -1.759090 -0.868530 -0.143738  0.820697   \n",
      "tke_diss  271950.0 -7.595426e-15  1.0 -3.047437 -1.051268  0.297575  0.940935   \n",
      "dk/dx     271950.0 -9.928525e-17  1.0 -5.343934 -0.120080 -0.010896  0.106665   \n",
      "dk/dy     271950.0  4.857139e-17  1.0 -3.187306 -0.166709  0.011332  0.195884   \n",
      "\n",
      "               max  \n",
      "Nu_t_lsq  1.792829  \n",
      "tke       2.509804  \n",
      "tke_diss  1.209547  \n",
      "dk/dx     4.517655  \n",
      "dk/dy     3.719590  \n"
     ]
    }
   ],
   "source": [
    "Data_stat = Data.describe()\n",
    "Data_stat = Data_stat.transpose()\n",
    "print(Data_stat.head())\n",
    "Data_stat1 = norm_Data.describe()\n",
    "Data_stat1 = Data_stat1.transpose()\n",
    "print(Data_stat1.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nu_t_lsq</th>\n",
       "      <th>tke</th>\n",
       "      <th>tke_diss</th>\n",
       "      <th>dk/dx</th>\n",
       "      <th>dk/dy</th>\n",
       "      <th>dk/dx_i</th>\n",
       "      <th>dp_dx</th>\n",
       "      <th>dp_dy</th>\n",
       "      <th>dp_dx_i</th>\n",
       "      <th>dT/dx</th>\n",
       "      <th>...</th>\n",
       "      <th>S_22</th>\n",
       "      <th>S_ij_abs</th>\n",
       "      <th>u_du/dx+v_dv/dx</th>\n",
       "      <th>MKE_diff</th>\n",
       "      <th>MKE_pre</th>\n",
       "      <th>MKE_diss</th>\n",
       "      <th>MTV_diff</th>\n",
       "      <th>MTV_diss</th>\n",
       "      <th>Pr</th>\n",
       "      <th>Pr_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.132986</td>\n",
       "      <td>14.377132</td>\n",
       "      <td>22.268086</td>\n",
       "      <td>37.114486</td>\n",
       "      <td>44.346723</td>\n",
       "      <td>39.466290</td>\n",
       "      <td>48.009760</td>\n",
       "      <td>20.425027</td>\n",
       "      <td>26.667895</td>\n",
       "      <td>25.449422</td>\n",
       "      <td>...</td>\n",
       "      <td>18.579268</td>\n",
       "      <td>27.418088</td>\n",
       "      <td>36.907974</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>21.496533</td>\n",
       "      <td>42.226601</td>\n",
       "      <td>20.145804</td>\n",
       "      <td>36.800436</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.012569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.185886</td>\n",
       "      <td>16.245140</td>\n",
       "      <td>22.510143</td>\n",
       "      <td>37.402969</td>\n",
       "      <td>45.271994</td>\n",
       "      <td>41.187298</td>\n",
       "      <td>47.862485</td>\n",
       "      <td>19.678991</td>\n",
       "      <td>26.818636</td>\n",
       "      <td>25.147700</td>\n",
       "      <td>...</td>\n",
       "      <td>18.593374</td>\n",
       "      <td>27.545938</td>\n",
       "      <td>37.314369</td>\n",
       "      <td>49.868454</td>\n",
       "      <td>21.114644</td>\n",
       "      <td>42.114543</td>\n",
       "      <td>21.000677</td>\n",
       "      <td>36.867342</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.530524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.249500</td>\n",
       "      <td>18.250517</td>\n",
       "      <td>22.825082</td>\n",
       "      <td>37.582998</td>\n",
       "      <td>45.944272</td>\n",
       "      <td>42.437739</td>\n",
       "      <td>47.711269</td>\n",
       "      <td>18.942071</td>\n",
       "      <td>27.003289</td>\n",
       "      <td>24.887386</td>\n",
       "      <td>...</td>\n",
       "      <td>18.652764</td>\n",
       "      <td>27.582043</td>\n",
       "      <td>37.693985</td>\n",
       "      <td>49.624822</td>\n",
       "      <td>20.757066</td>\n",
       "      <td>42.082673</td>\n",
       "      <td>21.784650</td>\n",
       "      <td>36.957200</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.954093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.324497</td>\n",
       "      <td>20.366414</td>\n",
       "      <td>23.175629</td>\n",
       "      <td>37.684747</td>\n",
       "      <td>46.345855</td>\n",
       "      <td>43.184686</td>\n",
       "      <td>47.554859</td>\n",
       "      <td>18.224296</td>\n",
       "      <td>27.211999</td>\n",
       "      <td>24.667237</td>\n",
       "      <td>...</td>\n",
       "      <td>18.747683</td>\n",
       "      <td>27.528010</td>\n",
       "      <td>38.045613</td>\n",
       "      <td>49.295051</td>\n",
       "      <td>20.418061</td>\n",
       "      <td>42.130238</td>\n",
       "      <td>22.499872</td>\n",
       "      <td>37.069875</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.296938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.412217</td>\n",
       "      <td>22.562516</td>\n",
       "      <td>23.524736</td>\n",
       "      <td>37.727042</td>\n",
       "      <td>46.472720</td>\n",
       "      <td>43.420656</td>\n",
       "      <td>47.392680</td>\n",
       "      <td>17.532720</td>\n",
       "      <td>27.436014</td>\n",
       "      <td>24.485448</td>\n",
       "      <td>...</td>\n",
       "      <td>18.872329</td>\n",
       "      <td>27.387712</td>\n",
       "      <td>38.368020</td>\n",
       "      <td>48.902306</td>\n",
       "      <td>20.094091</td>\n",
       "      <td>42.253057</td>\n",
       "      <td>23.150194</td>\n",
       "      <td>37.204829</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.572195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nu_t_lsq        tke   tke_diss      dk/dx      dk/dy    dk/dx_i  \\\n",
       "0  10.132986  14.377132  22.268086  37.114486  44.346723  39.466290   \n",
       "1  10.185886  16.245140  22.510143  37.402969  45.271994  41.187298   \n",
       "2  10.249500  18.250517  22.825082  37.582998  45.944272  42.437739   \n",
       "3  10.324497  20.366414  23.175629  37.684747  46.345855  43.184686   \n",
       "4  10.412217  22.562516  23.524736  37.727042  46.472720  43.420656   \n",
       "\n",
       "       dp_dx      dp_dy    dp_dx_i      dT/dx  ...       S_22   S_ij_abs  \\\n",
       "0  48.009760  20.425027  26.667895  25.449422  ...  18.579268  27.418088   \n",
       "1  47.862485  19.678991  26.818636  25.147700  ...  18.593374  27.545938   \n",
       "2  47.711269  18.942071  27.003289  24.887386  ...  18.652764  27.582043   \n",
       "3  47.554859  18.224296  27.211999  24.667237  ...  18.747683  27.528010   \n",
       "4  47.392680  17.532720  27.436014  24.485448  ...  18.872329  27.387712   \n",
       "\n",
       "   u_du/dx+v_dv/dx   MKE_diff    MKE_pre   MKE_diss   MTV_diff   MTV_diss  \\\n",
       "0        36.907974  50.000000  21.496533  42.226601  20.145804  36.800436   \n",
       "1        37.314369  49.868454  21.114644  42.114543  21.000677  36.867342   \n",
       "2        37.693985  49.624822  20.757066  42.082673  21.784650  36.957200   \n",
       "3        38.045613  49.295051  20.418061  42.130238  22.499872  37.069875   \n",
       "4        38.368020  48.902306  20.094091  42.253057  23.150194  37.204829   \n",
       "\n",
       "     Pr       Pr_t  \n",
       "0  10.0  19.012569  \n",
       "1  10.0  19.530524  \n",
       "2  10.0  19.954093  \n",
       "3  10.0  20.296938  \n",
       "4  10.0  20.572195  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(r'D:\\Desktop\\190925\\Python_scripts\\Data\\case1_RANS_wedge_trim.csv')\n",
    "data1 = pd.DataFrame()\n",
    "data1['X'] = data['X']\n",
    "data1['Y'] = data['Y']\n",
    "del data['X']\n",
    "del data['Y']\n",
    "del data['Alpha_t_lsq']\n",
    "del data['Re_tau']\n",
    "data1['DNS_Pr_t'] = data['Pr_t']\n",
    "\n",
    "data11 = (data - Data_stat['mean'])/Data_stat['std']\n",
    "data12 = (data11 - Data_stat1['min'])/(Data_stat1['max'] - Data_stat1['min'])*(50 - 10) + 10\n",
    "data12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19.783888],\n",
       "       [19.544605],\n",
       "       [17.58237 ],\n",
       "       ...,\n",
       "       [16.194212],\n",
       "       [17.635166],\n",
       "       [17.721893]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del data12['Pr_t']\n",
    "\n",
    "model = sess.run(hidden11,feed_dict={X: x_train,is_training:False})\n",
    "model\n",
    "# grad_model = sess.run(tf.squeeze(tf.gradients(hidden5,X)),feed_dict={X:data12,is_training:False})\n",
    "# for i in range(len(data12.columns)):\n",
    "#     globals()['grad_x{}'.format(i+1)] = [grad_model[j][i] for j in range(len(grad_model))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values does not match length of index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-88031a21af40>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata12\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ANN_Pr_t'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdata12\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow4\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3368\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3369\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3370\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3372\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow4\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3444\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3445\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3446\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow4\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3629\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3630\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3631\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3632\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow4\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[1;34m(data, index, copy)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Length of values does not match length of index'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    520\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCIndexClass\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values does not match length of index"
     ]
    }
   ],
   "source": [
    "model1 = [model[i][0] for i in range(len(model))]\n",
    "model1\n",
    "data12['ANN_Pr_t'] = model1\n",
    "data12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>DNS_Pr_t</th>\n",
       "      <th>Nu_t_lsq</th>\n",
       "      <th>tke</th>\n",
       "      <th>tke_diss</th>\n",
       "      <th>dk/dx</th>\n",
       "      <th>dk/dy</th>\n",
       "      <th>dk/dx_i</th>\n",
       "      <th>dp_dx</th>\n",
       "      <th>...</th>\n",
       "      <th>S_22</th>\n",
       "      <th>S_ij_abs</th>\n",
       "      <th>u_du/dx+v_dv/dx</th>\n",
       "      <th>MKE_diff</th>\n",
       "      <th>MKE_pre</th>\n",
       "      <th>MKE_diss</th>\n",
       "      <th>MTV_diff</th>\n",
       "      <th>MTV_diss</th>\n",
       "      <th>Re_tau</th>\n",
       "      <th>Pr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.076720</td>\n",
       "      <td>0.993037</td>\n",
       "      <td>2.350121</td>\n",
       "      <td>0.498286</td>\n",
       "      <td>-1.107374</td>\n",
       "      <td>-0.088408</td>\n",
       "      <td>-0.533132</td>\n",
       "      <td>-0.551654</td>\n",
       "      <td>2.545012</td>\n",
       "      <td>...</td>\n",
       "      <td>1.540576</td>\n",
       "      <td>1.221290</td>\n",
       "      <td>-0.554221</td>\n",
       "      <td>2.143875</td>\n",
       "      <td>1.980704</td>\n",
       "      <td>2.759040</td>\n",
       "      <td>1.291551</td>\n",
       "      <td>-2.366121</td>\n",
       "      <td>0.464251</td>\n",
       "      <td>-0.080646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.074086</td>\n",
       "      <td>1.025760</td>\n",
       "      <td>2.330193</td>\n",
       "      <td>0.498247</td>\n",
       "      <td>-1.070832</td>\n",
       "      <td>-0.089417</td>\n",
       "      <td>-0.540665</td>\n",
       "      <td>-0.570904</td>\n",
       "      <td>2.509068</td>\n",
       "      <td>...</td>\n",
       "      <td>1.521865</td>\n",
       "      <td>1.243789</td>\n",
       "      <td>-0.535846</td>\n",
       "      <td>2.114339</td>\n",
       "      <td>1.962674</td>\n",
       "      <td>2.756478</td>\n",
       "      <td>1.274209</td>\n",
       "      <td>-2.364124</td>\n",
       "      <td>0.460535</td>\n",
       "      <td>-0.083380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.071392</td>\n",
       "      <td>1.052520</td>\n",
       "      <td>2.316830</td>\n",
       "      <td>0.503947</td>\n",
       "      <td>-1.068320</td>\n",
       "      <td>-0.101840</td>\n",
       "      <td>-0.548055</td>\n",
       "      <td>-0.571070</td>\n",
       "      <td>2.468442</td>\n",
       "      <td>...</td>\n",
       "      <td>1.527090</td>\n",
       "      <td>1.245809</td>\n",
       "      <td>-0.547637</td>\n",
       "      <td>2.100595</td>\n",
       "      <td>1.964931</td>\n",
       "      <td>2.736974</td>\n",
       "      <td>1.263276</td>\n",
       "      <td>-2.328565</td>\n",
       "      <td>0.464069</td>\n",
       "      <td>-0.082057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.068635</td>\n",
       "      <td>1.074180</td>\n",
       "      <td>2.332357</td>\n",
       "      <td>0.539766</td>\n",
       "      <td>-1.090985</td>\n",
       "      <td>-0.122386</td>\n",
       "      <td>-0.472117</td>\n",
       "      <td>-0.594500</td>\n",
       "      <td>2.424022</td>\n",
       "      <td>...</td>\n",
       "      <td>1.505123</td>\n",
       "      <td>1.228186</td>\n",
       "      <td>-0.535763</td>\n",
       "      <td>2.045291</td>\n",
       "      <td>1.964294</td>\n",
       "      <td>2.640466</td>\n",
       "      <td>1.246901</td>\n",
       "      <td>-2.240331</td>\n",
       "      <td>0.474957</td>\n",
       "      <td>-0.081571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.065814</td>\n",
       "      <td>1.091570</td>\n",
       "      <td>2.418782</td>\n",
       "      <td>0.663382</td>\n",
       "      <td>-1.171814</td>\n",
       "      <td>-0.166174</td>\n",
       "      <td>-0.165377</td>\n",
       "      <td>-0.685028</td>\n",
       "      <td>2.351002</td>\n",
       "      <td>...</td>\n",
       "      <td>1.396686</td>\n",
       "      <td>1.157015</td>\n",
       "      <td>-0.458912</td>\n",
       "      <td>1.869473</td>\n",
       "      <td>1.955989</td>\n",
       "      <td>2.329468</td>\n",
       "      <td>1.208006</td>\n",
       "      <td>-2.000580</td>\n",
       "      <td>0.507439</td>\n",
       "      <td>-0.079922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              X         Y  DNS_Pr_t  Nu_t_lsq       tke  tke_diss     dk/dx  \\\n",
       "0 -5.000000e-09 -0.076720  0.993037  2.350121  0.498286 -1.107374 -0.088408   \n",
       "1 -5.000000e-09 -0.074086  1.025760  2.330193  0.498247 -1.070832 -0.089417   \n",
       "2 -5.000000e-09 -0.071392  1.052520  2.316830  0.503947 -1.068320 -0.101840   \n",
       "3 -5.000000e-09 -0.068635  1.074180  2.332357  0.539766 -1.090985 -0.122386   \n",
       "4 -5.000000e-09 -0.065814  1.091570  2.418782  0.663382 -1.171814 -0.166174   \n",
       "\n",
       "      dk/dy   dk/dx_i     dp_dx  ...      S_22  S_ij_abs  u_du/dx+v_dv/dx  \\\n",
       "0 -0.533132 -0.551654  2.545012  ...  1.540576  1.221290        -0.554221   \n",
       "1 -0.540665 -0.570904  2.509068  ...  1.521865  1.243789        -0.535846   \n",
       "2 -0.548055 -0.571070  2.468442  ...  1.527090  1.245809        -0.547637   \n",
       "3 -0.472117 -0.594500  2.424022  ...  1.505123  1.228186        -0.535763   \n",
       "4 -0.165377 -0.685028  2.351002  ...  1.396686  1.157015        -0.458912   \n",
       "\n",
       "   MKE_diff   MKE_pre  MKE_diss  MTV_diff  MTV_diss    Re_tau        Pr  \n",
       "0  2.143875  1.980704  2.759040  1.291551 -2.366121  0.464251 -0.080646  \n",
       "1  2.114339  1.962674  2.756478  1.274209 -2.364124  0.460535 -0.083380  \n",
       "2  2.100595  1.964931  2.736974  1.263276 -2.328565  0.464069 -0.082057  \n",
       "3  2.045291  1.964294  2.640466  1.246901 -2.240331  0.474957 -0.081571  \n",
       "4  1.869473  1.955989  2.329468  1.208006 -2.000580  0.507439 -0.079922  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "mod = sys.modules[__name__]\n",
    "for i in range(len(data12.columns)):\n",
    "    data1['{}'.format(data12.columns[i])] = getattr(mod,'grad_x{}'.format(i+1))\n",
    "    \n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1.to_csv(r'D:\\Desktop\\190925\\wedge_pr_t\\csv_file\\grad_0098_case1_RANS_wedge.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_pr_t = sess.run(hidden11, feed_dict={X: x_test, is_training:False})\n",
    "testset_pr_t = [testset_pr_t[i][0] for i in range(len(testset_pr_t))]\n",
    "testset_pr_t = [(testset_pr_t[i]-10)/40*(norm_Data['Pr_t'].max()-norm_Data['Pr_t'].min())+norm_Data['Pr_t'].min() for i in range(len(testset_pr_t))]\n",
    "testset_pr_t = [testset_pr_t[i]*Data['Pr_t'].std()+Data['Pr_t'].mean() for i in range(len(testset_pr_t))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f45c8e96ac8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testset_pr_t_real = [y_test[i][0] for i in range(len(y_test))]\n",
    "# testset_pr_t_real\n",
    "testset_pr_t_real = [((testset_pr_t_real[i]-10)/40*(norm_Data['Pr_t'].max()-norm_Data['Pr_t'].min())+norm_Data['Pr_t'].min()) for i in range(len(testset_pr_t_real))]\n",
    "testset_pr_t_real = [(testset_pr_t_real[i]*Data['Pr_t'].std()+Data['Pr_t'].mean()) for i in range(len(testset_pr_t_real))]\n",
    "\n",
    "plt.scatter(testset_pr_t,testset_pr_t_real,s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "case9_Data = pd.read_csv(r'/home/ftmlab/다운로드/HaKang/case9_total_uniform_wedge.csv')\n",
    "\n",
    "contour_data = pd.DataFrame()\n",
    "contour_data['X'] = case9_Data['X']\n",
    "contour_data['Y'] = case9_Data['Y']\n",
    "contour_data['Alpha_t'] = case9_Data['Alpha_t']\n",
    "\n",
    "del case9_Data['X']\n",
    "del case9_Data['Y']\n",
    "del case9_Data['y_plus']\n",
    "del case9_Data['wedge_height']\n",
    "del case9_Data['Alpha_t']\n",
    "\n",
    "preprocess_case9_Data = ((case9_Data - Data.mean())/Data.std())\n",
    "preprocess_case9_Data = (preprocess_case9_Data - norm_Data.min())/(norm_Data.max() - norm_Data.min())*40 + 10\n",
    "\n",
    "case9_X = preprocess_case9_Data[preprocess_case9_Data.columns[:-1]]\n",
    "case9_Y = preprocess_case9_Data[preprocess_case9_Data.columns[-1:]]\n",
    "\n",
    "plt.scatter(sess.run(hidden11,feed_dict={X: case9_X,is_training:False}),case9_Y,s=1)\n",
    "# plt.axis([-2.5,15,-2.5,15])\n",
    "\n",
    "case9_pr_t = sess.run(hidden11, feed_dict={X: case9_X, is_training:False})\n",
    "case9_pr_t = [case9_pr_t[i][0] for i in range(len(case9_pr_t))]\n",
    "case9_pr_t = [(case9_pr_t[i]-10)/40*(norm_Data['Pr_t'].max()-norm_Data['Pr_t'].min())+norm_Data['Pr_t'].min() for i in range(len(case9_pr_t))]\n",
    "case9_pr_t = [case9_pr_t[i]*Data['Pr_t'].std()+Data['Pr_t'].mean() for i in range(len(case9_pr_t))]\n",
    "\n",
    "# case2_pr_t_real = case2_Y\n",
    "case9_pr_t_real = ((case9_Y-10)/40*(norm_Data['Pr_t'].max()-norm_Data['Pr_t'].min())+norm_Data['Pr_t'].min())*Data['Pr_t'].std()+Data['Pr_t'].mean()\n",
    "# caes2_pr_t_real = case2_pr_t_real*Data['Pr_t'].std()+Data['Pr_t'].mean()\n",
    "\n",
    "plt.scatter(case9_pr_t, case9_pr_t_real, s=1)\n",
    "\n",
    "contour_data['ANN_pr_t'] = case9_pr_t\n",
    "contour_data['DNS_pr_t'] = case9_Data['Pr_t']\n",
    "contour_data['nu_t'] = case9_Data['Nu_t_lsq']\n",
    "contour_data.to_csv(r'./case9_wedge_contour.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADypJREFUeJzt3X+s1fV9x/HXS65GQCdSjswC63XoMJapsKOTslgj2jB10nSNwdRWKx1Z0vlrbA7sUk3aGJva2l+JDUWFRYZZqMau1gakdWSZJbsgCgrVsQpCUY6jsxVdlPneH/fQweWce358v+d87/nwfCSGe8853O8r5vLke7/3nIsjQgCA3ndc0QMAAPkg6ACQCIIOAIkg6ACQCIIOAIkg6ACQCIIOAIkg6ACQCIIOAIno6+bBJkyYEP39/d08JAD0vI0bN74REaVGj+tq0Pv7+zUwMNDNQwJAz7O9s5nHcckFABJB0AEgEQQdABJB0AEgEQ2DbvtB2/tsb61x3yLbYXtCZ+YBAJrVzBn6cklzh95oe4qkj0nalfMmAEAbGgY9ItZL2l/jrvsk3S6Jf/IIAEaAtq6h254naU9EPJfzHgBIyrL1O/T7S57QsvU7On6sloNue4ykOyR9scnHL7Q9YHugUqm0ejgA6FmrNuzUl3+0Xe+H9OUfbe/48dp5pehUSWdIes62JE2WtMn2hRHx2tAHR8RSSUslqVwuc3kGQPJ2VN7SXz08oG2vH/jtbX3HuePHbTnoEbFF0mmH3rf9iqRyRLyR4y4A6ElPb9+nBSv+Xf972OnrcZbuu+a8jh+7YdBtr5J0iaQJtndLujMiHuj0MADoJf+8eY9uemTzUbfPO+903Xn1dI0fe0LHNzQMekRc2+D+/tzWAEAP+txDG/TUz4+8SDHmBOvhBbM080Ondm1HV3/aIgCkZNWGnVry2FGvuZQkvf1u979lyEv/AaBFOypv6YzFT9SN+SF//U9HX4LpJM7QAaAFdz2+Rcufae4F8hef1fDfpMgVQQeAJuw/8K5mfmltU4+dNO5EXfmHp+svLzmzw6uORNABYBg7Km9pztf+peHj+seP1q5fvaNL/mCC7r1mRlee1TIUQQeAOjbt/JU+cf+/NXzcKEsPfPZCTS2d1IVV9RF0AKjh7Due0P+83/hxxx8nfe8zFxQec4mgA8ARmj0rl6S5H56ouz9xbiGXV2oh6AAg6TPfe0brd9T6SeFHu+aPJmnxFeeMmJAfQtABHPMWr948bMz//oqz9bmLp3ZxUXsIOoBjVqOnIs4vT9I9nzy/i4uyIegAjjmNXhxkSU8t+uiI+EZnKwg6gGPKbas26rHnjvqnG35r+Q0X6JKzT6t7/0hG0AEcM/74S2v0+oH3at734Ylj9cRtl3R3UM4IOoDk1ftZ5Yd8e/75+rPzJ3VxUWcQdADJqxfzFM7KD0fQARxzLp46Xv/wF7OKnpE7gg4geVM/MFo7/usdTf3AaK3720uLntMxBB1A8lKO+OH4F4sAIBEEHQAS0TDoth+0vc/21sNu+6rt7baft/2Y7XGdnQkAaKSZM/TlkuYOuW2tpOkRca6klyQtyXkXAKBFDYMeEesl7R9y25qIOFh992eSJndgGwCgBXlcQ79R0pM5fBwAQAaZgm77C5IOSlo5zGMW2h6wPVCpVLIcDgAwjLaDbvsGSVdJ+lRERL3HRcTSiChHRLlUKrV7OABAA229sMj2XEm3S/poRLyd7yQAQDuaedriKknPSJpme7ftBZK+I+lkSWttb7b93Q7vBAA00PAMPSKurXHzAx3YAgDIgFeKAkAiCDoAJIKgA0AiCDoAJIKgA0AiCDoAJIKgA0AiCDoAJIKgA0AiCDoAJIKgA0AiCDoAJIKgA0AiCDoAJIKgA0AiCDoAJIKgA0AiCDoAJIKgA0AiCDoAJIKgA0AiGgbd9oO299neetht422vtf1y9ddTOzsTANBIM2foyyXNHXLbYknrIuIsSeuq7wMACtQw6BGxXtL+ITfPk7Si+vYKSR/PeRcAoEXtXkOfGBF7q2+/JmliTnsAAG3K/E3RiAhJUe9+2wttD9geqFQqWQ8HAKij3aC/bvt0Sar+uq/eAyNiaUSUI6JcKpXaPBwAoJF2g/4DSddX375e0uP5zAEAtKuZpy2ukvSMpGm2d9teIOkeSZfbflnSZdX3AQAF6mv0gIi4ts5dc3LeAgDIgFeKAkAiCDoAJIKgA0AiCDoAJIKgA0AiCDoAJIKgA0AiCDoAJIKgA0AiCDoAJIKgA0AiCDoAJIKgA0AiCDoAJIKgA0AiCDoAJIKgA0AiCDoAJIKgA0AiCDoAJIKgA0AiMgXd9m22X7C91fYq2yfmNQwA0Jq2g257kqSbJZUjYrqkUZLm5zUMANCarJdc+iSNtt0naYykX2afBABoR9tBj4g9ku6VtEvSXklvRsSavIYBAFqT5ZLLqZLmSTpD0gcljbV9XY3HLbQ9YHugUqm0vxQAMKwsl1wuk/SLiKhExHuSHpX0kaEPioilEVGOiHKpVMpwOADAcLIEfZeki2yPsW1JcyRty2cWAKBVWa6hb5C0WtImSVuqH2tpTrsAAC3qy/KbI+JOSXfmtAUAkAGvFAWARBB0AEgEQQeARBB0AEgEQQeARBB0AEgEQQeARBB0AEgEQQeARBB0AEgEQQeARBB0AEgEQQeARBB0AEgEQQeARBB0AEgEQQeARBB0AEgEQQeARBB0AEgEQQeARGQKuu1xtlfb3m57m+1ZeQ0DALSmL+Pv/6akH0fEJ22fIGlMDpsAAG1oO+i2T5F0saQbJCki3pX0bj6zAACtynLJ5QxJFUkP2X7W9jLbY3PaBQBoUZag90maKen+iJgh6YCkxUMfZHuh7QHbA5VKJcPhAADDyRL03ZJ2R8SG6vurNRj4I0TE0ogoR0S5VCplOBwAYDhtBz0iXpP0qu1p1ZvmSHoxl1UAgJZlfZbLTZJWVp/h8p+SPpt9EgCgHZmCHhGbJZVz2gIAyIBXigJAIgg6ACSCoANAIgg6ACSCoANAIgg6ACSCoANAIgg6ACSCoANAIgg6ACSCoANAIgg6ACSCoANAIgg6ACSCoANAIgg6ACSCoANAIgg6ACSCoANAIgg6ACSCoANAIjIH3fYo28/a/mEegwAA7cnjDP0WSdty+DgAgAwyBd32ZElXSlqWzxwAQLuynqF/Q9Ltkt7PYQsAIIO2g277Kkn7ImJjg8cttD1ge6BSqbR7OABAA1nO0GdLutr2K5IekXSp7YeHPigilkZEOSLKpVIpw+EAAMNpO+gRsSQiJkdEv6T5kn4SEdfltgwA0BKehw4AiejL44NExNOSns7jYwEA2sMZOgAkgqADQCIIOgAkgqADQCIIOgAkgqADQCIIOgAkgqADQCIIOgAkgqADQCIIOgAkgqADQCIIOgAkgqADQCIIOgAkgqADQCIIOgAkgqADQCIIOgAkgqADQCIIOgAkou2g255i+6e2X7T9gu1b8hwGAGhNX4bfe1DSoojYZPtkSRttr42IF3PaBgBoQdtn6BGxNyI2Vd/+jaRtkiblNQwA0JpcrqHb7pc0Q9KGPD4eAKB1mYNu+yRJ35d0a0T8usb9C20P2B6oVCpZDwcAqCNT0G0fr8GYr4yIR2s9JiKWRkQ5IsqlUinL4QAAw8jyLBdLekDStoj4en6TAADtyHKGPlvSpyVdantz9b8rctoFAGhR209bjIh/leQctwAAMuCVogCQCIIOAIkg6ACQCIIOAIkg6ACQCIIOAInI8tMWR5ZvXSjt//ng21d+S7rg+mL3AECX9X7Q750uvfXqkbc9uYigAzjm9G7QX3pK+sc/r33fn36tu1sAYATozaDfdUr9+2bdzNk5gGNSbwX9K2dK7wzzI3hP+B3pT27t3h4AGEF6J+jDnZVL0uV3S7M/350tADAC9UbQv3Jm/fvuerN7OwBgBOuNoNe6zHLjU9LvXdD9LQAwQvVG0EeX/j/qJ02R/mZrsXsAYATqjaD/3X8UvQAARjxe+g8AiSDoAJAIgg4AiSDoAJAIgg4AiSDoAJAIgg4AiXBEdO9gdkXSzq4dMJsJkt4oekSbenU7u7uL3d3X7vYPRUSp0YO6GvReYnsgIspF72hHr25nd3exu/s6vZ1LLgCQCIIOAIkg6PUtLXpABr26nd3dxe7u6+h2rqEDQCI4QweARBD0IWxPsf1T2y/afsH2LUVvaoXtUbaftf3Dorc0y/Y426ttb7e9zfasojc1y/Zt1c+TrbZX2T6x6E212H7Q9j7bWw+7bbzttbZfrv56apEba6mz+6vVz5XnbT9me1yRG2uptfuw+xbZDtsT8j4uQT/aQUmLIuIcSRdJ+rztcwre1IpbJG0rekSLvinpxxFxtqTz1CP7bU+SdLOkckRMlzRK0vxiV9W1XNLcIbctlrQuIs6StK76/kizXEfvXitpekScK+klSUu6PaoJy3X0btmeIuljknZ14qAEfYiI2BsRm6pv/0aDcZlU7Krm2J4s6UpJy4re0izbp0i6WNIDkhQR70bEfxe7qiV9kkbb7pM0RtIvC95TU0Ssl7R/yM3zJK2ovr1C0se7OqoJtXZHxJqIOFh992eSJnd9WAN1/n9L0n2SbpfUkW9eEvRh2O6XNEPShmKXNO0bGvxkeb/oIS04Q1JF0kPVS0XLbI8telQzImKPpHs1eLa1V9KbEbGm2FUtmRgRe6tvvyZpYpFj2nSjpCeLHtEM2/Mk7YmI5zp1DIJeh+2TJH1f0q0R8eui9zRi+ypJ+yJiY9FbWtQnaaak+yNihqQDGplf+h+les15ngb/UvqgpLG2ryt2VXti8OluPfWUN9tf0OAl0pVFb2nE9hhJd0j6YiePQ9BrsH28BmO+MiIeLXpPk2ZLutr2K5IekXSp7YeLndSU3ZJ2R8Shr4JWazDwveAySb+IiEpEvCfpUUkfKXhTK163fbokVX/dV/Ceptm+QdJVkj4VvfHc66ka/Iv/ueqf0cmSNtn+3TwPQtCHsG0NXs/dFhFfL3pPsyJiSURMjoh+DX5j7icRMeLPFiPiNUmv2p5WvWmOpBcLnNSKXZIusj2m+nkzRz3yDd2qH0i6vvr29ZIeL3BL02zP1eClxasj4u2i9zQjIrZExGkR0V/9M7pb0szq539uCPrRZkv6tAbPcDdX/7ui6FGJu0nSStvPSzpf0t0F72lK9auK1ZI2SdqiwT9PI/JVjLZXSXpG0jTbu20vkHSPpMttv6zBrzbuKXJjLXV2f0fSyZLWVv98frfQkTXU2d354/bGVysAgEY4QweARBB0AEgEQQeARBB0AEgEQQeARBB0AEgEQQeARBB0AEjE/wGe15hoB7V5iAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "case10_Data = pd.read_csv(r'/home/ftmlab/다운로드/HaKang/0D_mean_orig_channel.csv')\n",
    "\n",
    "contour_data = pd.DataFrame()\n",
    "contour_data['X'] = case10_Data['X']\n",
    "contour_data['Y'] = case10_Data['Y']\n",
    "contour_data['Alpha_t'] = case10_Data['Alpha_t']\n",
    "contour_data['Re'] = case10_Data['Re']\n",
    "contour_data['Pr'] = case10_Data['Pr']\n",
    "\n",
    "del case10_Data['X']\n",
    "del case10_Data['Y']\n",
    "del case10_Data['y_plus']\n",
    "del case10_Data['wedge_height']\n",
    "del case10_Data['Alpha_t']\n",
    "\n",
    "preprocess_case10_Data = ((case10_Data - Data.mean())/Data.std())\n",
    "preprocess_case10_Data = (preprocess_case10_Data - norm_Data.min())/(norm_Data.max() - norm_Data.min())*40 + 10\n",
    "\n",
    "case10_X = preprocess_case10_Data[preprocess_case10_Data.columns[:-1]]\n",
    "case10_Y = preprocess_case10_Data[preprocess_case10_Data.columns[-1:]]\n",
    "\n",
    "plt.scatter(sess.run(hidden11,feed_dict={X: case10_X,is_training:False}),case10_Y,s=1)\n",
    "# plt.axis([-2.5,15,-2.5,15])\n",
    "\n",
    "case10_pr_t = sess.run(hidden11, feed_dict={X: case10_X, is_training:False})\n",
    "case10_pr_t = [case10_pr_t[i][0] for i in range(len(case10_pr_t))]\n",
    "case10_pr_t = [(case10_pr_t[i]-10)/40*(norm_Data['Pr_t'].max()-norm_Data['Pr_t'].min())+norm_Data['Pr_t'].min() for i in range(len(case10_pr_t))]\n",
    "case10_pr_t = [case10_pr_t[i]*Data['Pr_t'].std()+Data['Pr_t'].mean() for i in range(len(case10_pr_t))]\n",
    "\n",
    "# case2_pr_t_real = case2_Y\n",
    "case10_pr_t_real = ((case10_Y-10)/40*(norm_Data['Pr_t'].max()-norm_Data['Pr_t'].min())+norm_Data['Pr_t'].min())*Data['Pr_t'].std()+Data['Pr_t'].mean()\n",
    "# caes2_pr_t_real = case2_pr_t_real*Data['Pr_t'].std()+Data['Pr_t'].mean()\n",
    "\n",
    "plt.scatter(case10_pr_t, case10_pr_t_real, s=1)\n",
    "\n",
    "contour_data['ANN_pr_t'] = case10_pr_t\n",
    "contour_data['DNS_pr_t'] = case10_Data['Pr_t']\n",
    "contour_data['nu_t'] = case10_Data['Nu_t_lsq']\n",
    "contour_data.to_csv(r'./case10_wedge_contour.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2, 6, -2, 6]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(case2_pr_t, case2_pr_t_real, s=1)\n",
    "plt.axis([-2,6,-2,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f45cc6e7f98>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "case1_Data = pd.read_csv(r'/home/ftmlab/다운로드/HaKang/case1_total_uniform_wedge.csv')\n",
    "\n",
    "contour_data = pd.DataFrame()\n",
    "contour_data['X'] = case1_Data['X']\n",
    "contour_data['Y'] = case1_Data['Y']\n",
    "contour_data['Alpha_t'] = case1_Data['Alpha_t']\n",
    "\n",
    "del case1_Data['X']\n",
    "del case1_Data['Y']\n",
    "del case1_Data['y_plus']\n",
    "del case1_Data['wedge_height']\n",
    "del case1_Data['Alpha_t']\n",
    "\n",
    "preprocess_case1_Data = ((case1_Data - Data.mean())/Data.std())\n",
    "preprocess_case1_Data = (preprocess_case1_Data - norm_Data.min())/(norm_Data.max() - norm_Data.min())*40 + 10\n",
    "\n",
    "case1_X = preprocess_case1_Data[preprocess_case1_Data.columns[:-1]]\n",
    "case1_Y = preprocess_case1_Data[preprocess_case1_Data.columns[-1:]]\n",
    "\n",
    "plt.scatter(sess.run(hidden11,feed_dict={X: case1_X,is_training:False}),case1_Y,s=1)\n",
    "# plt.axis([-2.5,15,-2.5,15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case1_pr_t = sess.run(hidden11, feed_dict={X: case1_X, is_training:False})\n",
    "case1_pr_t = [case1_pr_t[i][0] for i in range(len(case1_pr_t))]\n",
    "case1_pr_t = [(case1_pr_t[i]-10)/40*(norm_Data['Pr_t'].max()-norm_Data['Pr_t'].min())+norm_Data['Pr_t'].min() for i in range(len(case1_pr_t))]\n",
    "case1_pr_t = [case1_pr_t[i]*Data['Pr_t'].std()+Data['Pr_t'].mean() for i in range(len(case1_pr_t))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f45cc336ac8>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# case1_pr_t_real = case1_Y\n",
    "case1_pr_t_real_norm = ((case1_Y-10)/40*(norm_Data['Pr_t'].max()-norm_Data['Pr_t'].min())+norm_Data['Pr_t'].min())*Data['Pr_t'].std()+Data['Pr_t'].mean()\n",
    "# caes1_pr_t_real = case1_pr_t_real_norm*Data['Pr_t'].std()+Data['Pr_t'].mean()\n",
    "\n",
    "plt.scatter(case1_pr_t, case1_pr_t_real_norm, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0.478256\n",
       "1         0.774759\n",
       "2         0.955058\n",
       "3         1.066099\n",
       "4         1.139431\n",
       "5         1.193767\n",
       "6         1.239245\n",
       "7         1.280743\n",
       "8         1.320299\n",
       "9         1.358528\n",
       "10        1.395432\n",
       "11        1.430771\n",
       "12        1.464737\n",
       "13        1.497472\n",
       "14        1.529448\n",
       "15        1.560950\n",
       "16        1.591979\n",
       "17        1.622345\n",
       "18        1.651432\n",
       "19        1.678529\n",
       "20        1.702167\n",
       "21        1.721211\n",
       "22        1.734902\n",
       "23        1.742813\n",
       "24        1.745039\n",
       "25        1.742150\n",
       "26        1.734665\n",
       "27        1.722632\n",
       "28        1.706099\n",
       "29        1.685019\n",
       "            ...   \n",
       "179897    1.388610\n",
       "179898    1.372030\n",
       "179899    1.352370\n",
       "179900    1.328921\n",
       "179901    1.301066\n",
       "179902    1.268284\n",
       "179903    1.230481\n",
       "179904    1.187893\n",
       "179905    1.141184\n",
       "179906    1.091112\n",
       "179907    1.038623\n",
       "179908    0.984950\n",
       "179909    0.931183\n",
       "179910    0.878362\n",
       "179911    0.827579\n",
       "179912    0.778833\n",
       "179913    0.732361\n",
       "179914    0.688399\n",
       "179915    0.647185\n",
       "179916    0.610046\n",
       "179917    0.577785\n",
       "179918    0.551872\n",
       "179919    0.533729\n",
       "179920    0.523449\n",
       "179921    0.521080\n",
       "179922    0.525249\n",
       "179923    0.532071\n",
       "179924    0.533587\n",
       "179925    0.516154\n",
       "179926    0.459828\n",
       "Name: Pr_t, Length: 179927, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case1_pr_t_real_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Alpha_t</th>\n",
       "      <th>ANN_pr_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.075792</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>1.002857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.069741</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>1.064503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.063689</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>1.103554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.057637</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>1.128479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.051585</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>1.144655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.045533</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>1.156056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.039481</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>1.165191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.033429</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>1.173371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.027377</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>1.182186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.021326</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.192481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.015274</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>1.196793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.009222</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>1.204147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.003170</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>1.211505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>1.218706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.008934</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>1.225792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.014986</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>1.232681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.021038</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>1.239258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.027089</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>1.245712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.033141</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>1.251936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.039193</td>\n",
       "      <td>0.001210</td>\n",
       "      <td>1.257756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.045245</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>1.262898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.051297</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>1.267119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.057349</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>1.270275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.063401</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>1.272276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.069452</td>\n",
       "      <td>0.001646</td>\n",
       "      <td>1.273102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.075504</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>1.272823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.081556</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>1.271523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.087608</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.269247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.093660</td>\n",
       "      <td>0.001983</td>\n",
       "      <td>1.266017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.099712</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>1.261904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179897</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.806340</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>1.203727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179898</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.812390</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>1.200152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179899</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.818440</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>1.195929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179900</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.824500</td>\n",
       "      <td>0.001841</td>\n",
       "      <td>1.190909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179901</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.830550</td>\n",
       "      <td>0.001748</td>\n",
       "      <td>1.184968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179902</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.836600</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>1.178007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179903</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.842650</td>\n",
       "      <td>0.001560</td>\n",
       "      <td>1.170016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179904</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.848700</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>1.161047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179905</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.854760</td>\n",
       "      <td>0.001370</td>\n",
       "      <td>1.151263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179906</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.860810</td>\n",
       "      <td>0.001275</td>\n",
       "      <td>1.140808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179907</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.866860</td>\n",
       "      <td>0.001181</td>\n",
       "      <td>1.129870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179908</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.872910</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>1.118719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179909</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.878960</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>1.107549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179910</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.885010</td>\n",
       "      <td>0.000905</td>\n",
       "      <td>1.096580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179911</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.891070</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>1.086035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179912</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.897120</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>1.075952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179913</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.903170</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>1.068108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179914</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.909220</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>1.060299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179915</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.915270</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>1.048128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179916</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.921330</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>1.040141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179917</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.927380</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>1.033235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179918</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.933430</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>1.027715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179919</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.939480</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>1.023921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179920</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.945530</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>1.021903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179921</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.951590</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>1.021561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179922</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.957640</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>1.022391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179923</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.963690</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>1.023462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179924</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.969740</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>1.023779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179925</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.975790</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>1.020956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179926</th>\n",
       "      <td>1.254830e+01</td>\n",
       "      <td>1.981840</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.010502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179927 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   X         Y   Alpha_t  ANN_pr_t\n",
       "0      -5.000000e-09 -0.075792  0.000024  1.002857\n",
       "1      -5.000000e-09 -0.069741  0.000042  1.064503\n",
       "2      -5.000000e-09 -0.063689  0.000066  1.103554\n",
       "3      -5.000000e-09 -0.057637  0.000096  1.128479\n",
       "4      -5.000000e-09 -0.051585  0.000132  1.144655\n",
       "5      -5.000000e-09 -0.045533  0.000174  1.156056\n",
       "6      -5.000000e-09 -0.039481  0.000223  1.165191\n",
       "7      -5.000000e-09 -0.033429  0.000276  1.173371\n",
       "8      -5.000000e-09 -0.027377  0.000336  1.182186\n",
       "9      -5.000000e-09 -0.021326  0.000400  1.192481\n",
       "10     -5.000000e-09 -0.015274  0.000469  1.196793\n",
       "11     -5.000000e-09 -0.009222  0.000542  1.204147\n",
       "12     -5.000000e-09 -0.003170  0.000618  1.211505\n",
       "13     -5.000000e-09  0.002882  0.000697  1.218706\n",
       "14     -5.000000e-09  0.008934  0.000779  1.225792\n",
       "15     -5.000000e-09  0.014986  0.000863  1.232681\n",
       "16     -5.000000e-09  0.021038  0.000948  1.239258\n",
       "17     -5.000000e-09  0.027089  0.001035  1.245712\n",
       "18     -5.000000e-09  0.033141  0.001122  1.251936\n",
       "19     -5.000000e-09  0.039193  0.001210  1.257756\n",
       "20     -5.000000e-09  0.045245  0.001298  1.262898\n",
       "21     -5.000000e-09  0.051297  0.001386  1.267119\n",
       "22     -5.000000e-09  0.057349  0.001473  1.270275\n",
       "23     -5.000000e-09  0.063401  0.001560  1.272276\n",
       "24     -5.000000e-09  0.069452  0.001646  1.273102\n",
       "25     -5.000000e-09  0.075504  0.001732  1.272823\n",
       "26     -5.000000e-09  0.081556  0.001816  1.271523\n",
       "27     -5.000000e-09  0.087608  0.001900  1.269247\n",
       "28     -5.000000e-09  0.093660  0.001983  1.266017\n",
       "29     -5.000000e-09  0.099712  0.002064  1.261904\n",
       "...              ...       ...       ...       ...\n",
       "179897  1.254830e+01  1.806340  0.002114  1.203727\n",
       "179898  1.254830e+01  1.812390  0.002024  1.200152\n",
       "179899  1.254830e+01  1.818440  0.001934  1.195929\n",
       "179900  1.254830e+01  1.824500  0.001841  1.190909\n",
       "179901  1.254830e+01  1.830550  0.001748  1.184968\n",
       "179902  1.254830e+01  1.836600  0.001654  1.178007\n",
       "179903  1.254830e+01  1.842650  0.001560  1.170016\n",
       "179904  1.254830e+01  1.848700  0.001465  1.161047\n",
       "179905  1.254830e+01  1.854760  0.001370  1.151263\n",
       "179906  1.254830e+01  1.860810  0.001275  1.140808\n",
       "179907  1.254830e+01  1.866860  0.001181  1.129870\n",
       "179908  1.254830e+01  1.872910  0.001087  1.118719\n",
       "179909  1.254830e+01  1.878960  0.000995  1.107549\n",
       "179910  1.254830e+01  1.885010  0.000905  1.096580\n",
       "179911  1.254830e+01  1.891070  0.000816  1.086035\n",
       "179912  1.254830e+01  1.897120  0.000731  1.075952\n",
       "179913  1.254830e+01  1.903170  0.000648  1.068108\n",
       "179914  1.254830e+01  1.909220  0.000568  1.060299\n",
       "179915  1.254830e+01  1.915270  0.000492  1.048128\n",
       "179916  1.254830e+01  1.921330  0.000420  1.040141\n",
       "179917  1.254830e+01  1.927380  0.000353  1.033235\n",
       "179918  1.254830e+01  1.933430  0.000291  1.027715\n",
       "179919  1.254830e+01  1.939480  0.000234  1.023921\n",
       "179920  1.254830e+01  1.945530  0.000183  1.021903\n",
       "179921  1.254830e+01  1.951590  0.000137  1.021561\n",
       "179922  1.254830e+01  1.957640  0.000098  1.022391\n",
       "179923  1.254830e+01  1.963690  0.000066  1.023462\n",
       "179924  1.254830e+01  1.969740  0.000041  1.023779\n",
       "179925  1.254830e+01  1.975790  0.000022  1.020956\n",
       "179926  1.254830e+01  1.981840  0.000010  1.010502\n",
       "\n",
       "[179927 rows x 4 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contour_data['ANN_pr_t'] = case1_pr_t\n",
    "contour_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "contour_data['DNS_pr_t'] = case1_Data['Pr_t']\n",
    "contour_data['nu_t'] = case1_Data['Nu_t_lsq']\n",
    "contour_data.to_csv(r'./case1_wedge_contour.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.7732\n",
      "0.0219149\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    globals()['Data{}'.format(i+1)] = pd.read_csv(r'/home/ftmlab/다운로드/HaKang/case%d_total_uniform_wedge.csv'%(i+1))\n",
    "Data10 = pd.read_csv(r'/home/ftmlab/다운로드/HaKang/0D_mean_orig_channel.csv')\n",
    "\n",
    "Data = pd.concat([Data1,Data2,Data3,Data4,Data5,Data6,Data7,Data8,Data9,Data10])\n",
    "\n",
    "Pr_t_max = Data['Pr_t'].max()\n",
    "Pr_t_min = Data['Pr_t'].min()\n",
    "Pr_t_mean = Data['Pr_t'].mean()\n",
    "Pr_t_std = Data['Pr_t'].std()\n",
    "\n",
    "# aa = sess.run(hidden11,feed_dict={X: x_test,is_training:False})\n",
    "# aaa = [aa[i][0]*Pr_t_std + Pr_t_mean for i in range(len(aa))]\n",
    "# aaa\n",
    "# bb = y_test\n",
    "# bbb = [bb[i][0]*Pr_t_std + Pr_t_mean for i in range(len(bb))]\n",
    "\n",
    "# plt.scatter(aaa,bbb,s=1)\n",
    "print(Pr_t_max)\n",
    "print(Pr_t_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nu_t_test = Data['Nu_t_lsq'].iloc[test_index]\n",
    "alpha_model_test = nu_t_test/aaa\n",
    "alpha_DNS_test = nu_t_test/bbb\n",
    "\n",
    "plt.scatter(alpha_model_test,alpha_DNS_test,s=1)\n",
    "plt.axis([-0.0005,0.002,-0.0005,0.002])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = abs(alpha_model_test - alpha_DNS_test)/alpha_DNS_test*100\n",
    "print('max relative error:',max(cc))\n",
    "print('min relative error:',min(cc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    globals()['Data{}'.format(i+1)] = pd.read_csv(r'/home/ftmlab/다운로드/HaKang/case%d_total_uniform_wedge.csv'%(i+1))\n",
    "Data10 = pd.read_csv(r'/home/ftmlab/다운로드/HaKang/0D_mean_orig_channel.csv')\n",
    "\n",
    "print(Data1.columns)\n",
    "print(Data10.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Data1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Data10.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./wedge_flat_model.ckpt\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey dense_5/bias not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-2-edfb9fff83d6>:11) ]]\n\t [[node save/RestoreV2 (defined at <ipython-input-2-edfb9fff83d6>:11) ]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-edfb9fff83d6>\", line 11, in <module>\n    saver = tf.train.Saver()\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n    self.build()\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 844, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 881, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 332, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 580, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1572, in restore_v2\n    name=name)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey dense_5/bias not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-2-edfb9fff83d6>:11) ]]\n\t [[node save/RestoreV2 (defined at <ipython-input-2-edfb9fff83d6>:11) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key dense_5/bias not found in checkpoint\n\t [[{{node save/RestoreV2}}]]\n\t [[{{node save/RestoreV2}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1275\u001b[0m         sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1276\u001b[0;31m                  {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1277\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key dense_5/bias not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-2-edfb9fff83d6>:11) ]]\n\t [[node save/RestoreV2 (defined at <ipython-input-2-edfb9fff83d6>:11) ]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-edfb9fff83d6>\", line 11, in <module>\n    saver = tf.train.Saver()\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n    self.build()\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 844, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 881, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 332, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 580, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1572, in restore_v2\n    name=name)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Key dense_5/bias not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-2-edfb9fff83d6>:11) ]]\n\t [[node save/RestoreV2 (defined at <ipython-input-2-edfb9fff83d6>:11) ]]\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1285\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1286\u001b[0;31m         \u001b[0mnames_to_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_graph_key_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mobject_graph_key_mapping\u001b[0;34m(checkpoint_path)\u001b[0m\n\u001b[1;32m   1590\u001b[0m   object_graph_string = reader.get_tensor(\n\u001b[0;32m-> 1591\u001b[0;31m       checkpointable.OBJECT_GRAPH_PROTO_KEY)\n\u001b[0m\u001b[1;32m   1592\u001b[0m   object_graph_proto = (\n",
      "\u001b[0;32m~/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mget_tensor\u001b[0;34m(self, tensor_str)\u001b[0m\n\u001b[1;32m    369\u001b[0m         return CheckpointReader_GetTensor(self, compat.as_bytes(tensor_str),\n\u001b[0;32m--> 370\u001b[0;31m                                           status)\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key _CHECKPOINTABLE_OBJECT_GRAPH not found in checkpoint",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-edfb9fff83d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"./wedge_flat_model.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1290\u001b[0m         \u001b[0;31m# a helpful message (b/110263146)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m         raise _wrap_restore_error_with_msg(\n\u001b[0;32m-> 1292\u001b[0;31m             err, \"a Variable name or other graph key that is missing\")\n\u001b[0m\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m       \u001b[0;31m# This is an object-based checkpoint. We'll print a warning and then do\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey dense_5/bias not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-2-edfb9fff83d6>:11) ]]\n\t [[node save/RestoreV2 (defined at <ipython-input-2-edfb9fff83d6>:11) ]]\n\nCaused by op 'save/RestoreV2', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-edfb9fff83d6>\", line 11, in <module>\n    saver = tf.train.Saver()\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 832, in __init__\n    self.build()\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 844, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 881, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 513, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 332, in _AddRestoreOps\n    restore_sequentially)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 580, in bulk_restore\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1572, in restore_v2\n    name=name)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nNotFoundError (see above for traceback): Restoring from checkpoint failed. This is most likely due to a Variable name or other graph key that is missing from the checkpoint. Please ensure that you have not altered the graph expected based on the checkpoint. Original error:\n\nKey dense_5/bias not found in checkpoint\n\t [[node save/RestoreV2 (defined at <ipython-input-2-edfb9fff83d6>:11) ]]\n\t [[node save/RestoreV2 (defined at <ipython-input-2-edfb9fff83d6>:11) ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn import utils\n",
    "from functools import partial\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "sess = tf.Session()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess,\"./wedge_flat_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X                       4.214498e+00\n",
       "Y                       9.989130e-01\n",
       "y_plus                  1.423812e+02\n",
       "wedge_height            9.989324e-02\n",
       "Nu_t_lsq                3.301367e-03\n",
       "Alpha_t                 3.715701e-03\n",
       "tke                     5.668334e-03\n",
       "dk/dx                  -2.327634e-05\n",
       "dk/dy                  -1.205200e-04\n",
       "dk/dx_i_abs             2.409174e-02\n",
       "tke_diss               -1.109727e-03\n",
       "TV_prod(al_t_1)         3.916107e-04\n",
       "tke_prod(nu_t_1_new)    1.333905e-03\n",
       "Rp                      3.497205e+00\n",
       "Rd                      3.730394e+00\n",
       "TV                      3.226160e-03\n",
       "tke_sdm                -6.182514e-06\n",
       "tke_conv_turb          -3.970063e-05\n",
       "tke_pre                -2.377277e-06\n",
       "tke_diff               -7.663247e-05\n",
       "TV_sdm                  1.602093e-07\n",
       "TV_conv_turb            1.587612e-06\n",
       "TV_diff                -8.432491e-06\n",
       "TV_diss                -3.085193e-04\n",
       "dp/dx                  -3.994744e-04\n",
       "dp/dy                  -2.746078e-04\n",
       "dp/dx_i_abs             2.153266e-02\n",
       "u_du/dx+v_dv/dx         3.203596e-04\n",
       "MKE_pre                 4.298167e-04\n",
       "MKE_diss               -6.936031e+00\n",
       "MKE_visc_diff          -2.878772e+00\n",
       "MTV_diss               -1.037123e+00\n",
       "MTV_mol_diff            2.659979e+00\n",
       "dT/dx                  -3.591182e-04\n",
       "dT/dy                   4.933484e-01\n",
       "dT/dx_i_abs             4.935473e-01\n",
       "S_ij_abs                7.457069e-01\n",
       "S_11                    7.724487e-04\n",
       "S_12(=S_21)            -4.927618e-03\n",
       "S_22                   -7.716222e-04\n",
       "Re                      3.561849e+02\n",
       "Pr                      9.842319e-01\n",
       "dTvar/dx_i_abs          8.842466e-03\n",
       "Rp/Rd                   9.142781e-01\n",
       "U-AVG-X                 8.342407e-01\n",
       "U-AVG-Y                 5.529150e-04\n",
       "U-AVG-Z                -8.922171e-05\n",
       "du/dx                   7.724487e-04\n",
       "du/dy                  -1.020985e-02\n",
       "dv/dx                   3.546072e-04\n",
       "dv/dy                  -7.716222e-04\n",
       "P_AVG                   5.238917e-04\n",
       "Pr_t                    9.139632e-01\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X                         3.039029\n",
       "Y                         0.638445\n",
       "y_plus                  112.304408\n",
       "wedge_height              0.003266\n",
       "Nu_t_lsq                  0.001458\n",
       "Alpha_t                   0.001495\n",
       "tke                       0.002721\n",
       "dk/dx                     0.002780\n",
       "dk/dy                     0.068448\n",
       "dk/dx_i_abs               0.064239\n",
       "tke_diss                  0.001356\n",
       "TV_prod(al_t_1)           0.000301\n",
       "tke_prod(nu_t_1_new)      0.002187\n",
       "Rp                        5.681268\n",
       "Rd                        4.813051\n",
       "TV                        0.001430\n",
       "tke_sdm                   0.000419\n",
       "tke_conv_turb             0.000624\n",
       "tke_pre                   0.000165\n",
       "tke_diff                  0.000521\n",
       "TV_sdm                    0.000032\n",
       "TV_conv_turb              0.000080\n",
       "TV_diff                   0.000092\n",
       "TV_diss                   0.000217\n",
       "dp/dx                     0.020746\n",
       "dp/dy                     0.017271\n",
       "dp/dx_i_abs               0.016311\n",
       "u_du/dx+v_dv/dx           0.033765\n",
       "MKE_pre                   0.016668\n",
       "MKE_diss                 41.958276\n",
       "MKE_visc_diff            34.196472\n",
       "MTV_diss                  8.752209\n",
       "MTV_mol_diff             24.899988\n",
       "dT/dx                     0.038071\n",
       "dT/dy                     0.889771\n",
       "dT/dx_i_abs               0.890476\n",
       "S_ij_abs                  1.706019\n",
       "S_11                      0.091763\n",
       "S_12(=S_21)               1.311078\n",
       "S_22                      0.091775\n",
       "Re                      162.230725\n",
       "Pr                        0.780039\n",
       "dTvar/dx_i_abs            0.020047\n",
       "Rp/Rd                     0.211408\n",
       "U-AVG-X                   0.149874\n",
       "U-AVG-Y                   0.017216\n",
       "U-AVG-Z                   0.001411\n",
       "du/dx                     0.091763\n",
       "du/dy                     2.625195\n",
       "dv/dx                     0.019657\n",
       "dv/dy                     0.091775\n",
       "P_AVG                     0.021590\n",
       "Pr_t                      0.211094\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./wedge_flat_model.ckpt'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.save(sess,\"./wedge_flat_model.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sess = tf.Session()\n",
    "saver = tf.train.import_meta_graph('wedge_flat_model.ckpt.meta')\n",
    "# saver.restore(sess, tf.train.latest_checkpoint('./'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./wedge_flat_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "# sess.run(tf.global_variables_initializer())\n",
    "# sess.run(tf.local_variables_initializer())\n",
    "\n",
    "save_file = './wedge_flat_model.ckpt'\n",
    "\n",
    "# sess = tf.Session()\n",
    "#     new_saver = tf.train.import_meta_graph('wedge_flat_model.ckpt.meta')\n",
    "saver.restore(sess, save_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value dense/kernel_2\n\t [[node dense/kernel_2/read (defined at <ipython-input-8-530169cb3fcc>:107) ]]\n\t [[node gradients_2/dense/MatMul_2_grad/MatMul (defined at <ipython-input-12-674bf1e66930>:57) ]]\n\nCaused by op 'dense/kernel_2/read', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-530169cb3fcc>\", line 107, in <module>\n    hidden1 = dense_layer(X,32)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/layers/core.py\", line 188, in dense\n    return layer.apply(inputs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1227, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/layers/base.py\", line 530, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 538, in __call__\n    self._maybe_build(inputs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1603, in _maybe_build\n    self.build(input_shapes)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/keras/layers/core.py\", line 949, in build\n    trainable=True)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/layers/base.py\", line 435, in add_weight\n    getter=vs.get_variable)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 349, in add_weight\n    aggregation=aggregation)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/checkpointable/base.py\", line 607, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 1479, in get_variable\n    aggregation=aggregation)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 1220, in get_variable\n    aggregation=aggregation)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 547, in get_variable\n    aggregation=aggregation)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 499, in _true_getter\n    aggregation=aggregation)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 911, in _get_single_variable\n    aggregation=aggregation)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 1557, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 81, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3890, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value dense/kernel_2\n\t [[node dense/kernel_2/read (defined at <ipython-input-8-530169cb3fcc>:107) ]]\n\t [[node gradients_2/dense/MatMul_2_grad/MatMul (defined at <ipython-input-12-674bf1e66930>:57) ]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value dense/kernel_2\n\t [[{{node dense/kernel_2/read}}]]\n\t [[{{node gradients_2/dense/MatMul_2_grad/MatMul}}]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-674bf1e66930>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;31m# pre_Data = preprocess(norm_Data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0maa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mpre_Data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpre_Data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value dense/kernel_2\n\t [[node dense/kernel_2/read (defined at <ipython-input-8-530169cb3fcc>:107) ]]\n\t [[node gradients_2/dense/MatMul_2_grad/MatMul (defined at <ipython-input-12-674bf1e66930>:57) ]]\n\nCaused by op 'dense/kernel_2/read', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/ftmlab/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-530169cb3fcc>\", line 107, in <module>\n    hidden1 = dense_layer(X,32)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 324, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/layers/core.py\", line 188, in dense\n    return layer.apply(inputs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1227, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/layers/base.py\", line 530, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 538, in __call__\n    self._maybe_build(inputs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1603, in _maybe_build\n    self.build(input_shapes)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/keras/layers/core.py\", line 949, in build\n    trainable=True)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/layers/base.py\", line 435, in add_weight\n    getter=vs.get_variable)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 349, in add_weight\n    aggregation=aggregation)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/checkpointable/base.py\", line 607, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 1479, in get_variable\n    aggregation=aggregation)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 1220, in get_variable\n    aggregation=aggregation)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 547, in get_variable\n    aggregation=aggregation)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 499, in _true_getter\n    aggregation=aggregation)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 911, in _get_single_variable\n    aggregation=aggregation)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 213, in __call__\n    return cls._variable_v1_call(*args, **kwargs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 176, in _variable_v1_call\n    aggregation=aggregation)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 155, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variable_scope.py\", line 2495, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 217, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 1395, in __init__\n    constraint=constraint)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/variables.py\", line 1557, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/util/dispatch.py\", line 180, in wrapper\n    return target(*args, **kwargs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py\", line 81, in identity\n    ret = gen_array_ops.identity(input, name=name)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3890, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/home/ftmlab/다운로드/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value dense/kernel_2\n\t [[node dense/kernel_2/read (defined at <ipython-input-8-530169cb3fcc>:107) ]]\n\t [[node gradients_2/dense/MatMul_2_grad/MatMul (defined at <ipython-input-12-674bf1e66930>:57) ]]\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# import tensorflow as tf\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# import math\n",
    "# import numpy as np\n",
    "# from sklearn import utils\n",
    "# from functools import partial\n",
    "# tf.set_random_seed(777)\n",
    "\n",
    "# def norm(Data):\n",
    "    \n",
    "#     return ((Data - Data.mean())/Data.std())\n",
    "\n",
    "# def preprocess(Data,max_norm=50,min_norm=10):\n",
    "#     #normalization\n",
    "#     Data = (Data - Data.min())/(Data.max() - Data.min())*(max_norm - min_norm) + min_norm\n",
    "#     # for i in range(len(Data.columns)):\n",
    "#     #     Data[Data.columns[i]] = (Data[Data.columns[i]] - Data[Data.columns[i]].mean())/Data[Data.columns[i]].std()\n",
    "#     #     print('standardized')\n",
    "#     #standardization\n",
    "#     #for i in range(len(Data.columns)):\n",
    "#     #    if Data[Data.columns[i]].std()*3 > (Data[Data.columns[i]].max()-Data[Data.columns[i]].min()):\n",
    "#     #        Data[Data.columns[i]] = (Data[Data.columns[i]] - Data[Data.columns[i]].mean())/Data[Data.columns[i]].std()\n",
    "#     #        print('standardized %d'%i)\n",
    "#     #    else:\n",
    "#     #        Data = (Data - Data.min())/(Data.max() - Data.min())*(max_norm - min_norm) + min_norm\n",
    "#     return Data\n",
    "\n",
    "# for i in range(9):\n",
    "#     globals()['Data{}'.format(i+1)] = pd.read_csv(r'/home/ftmlab/다운로드/HaKang/case%d_total_uniform_wedge.csv'%(i+1))\n",
    "# Data10 = pd.read_csv(r'/home/ftmlab/다운로드/HaKang/0D_mean_orig_channel.csv')\n",
    "\n",
    "# Data = pd.concat([Data1,Data2,Data3,Data4,Data5,Data6,Data7,Data8,Data9,Data10])\n",
    "\n",
    "# del Data['X']\n",
    "# del Data['Y']\n",
    "# del Data['y_plus']\n",
    "# del Data['wedge_height']\n",
    "# del Data['Alpha_t']\n",
    "# # del Data['Pr']\n",
    "# # del Data['Re']\n",
    "\n",
    "# # Data = pd.DataFrame()\n",
    "# # Data['dk_dx_i_abs'] = data['dk_dx_i_abs']\n",
    "# # Data['dT/dx'] = data['dT/dx']\n",
    "# # Data['dT/dy'] = data['dT/dy']\n",
    "# # # Data['Nu_t_lsq_n'] = data['Nu_t_lsq_n']\n",
    "# # Data['PHI-Alpha_t_lsq_n'] = data['PHI-Alpha_t_lsq_n']\n",
    "# # # Data['PHI-Pr_t_new'] = data['PHI-Pr_t_new']\n",
    "\n",
    "# denorm_min = Data['Pr_t'].min()\n",
    "# denorm_max = Data['Pr_t'].max()\n",
    "\n",
    "# norm_Data = norm(Data)\n",
    "# pre_Data = preprocess(norm_Data)\n",
    "\n",
    "# aa = sess.run(tf.gradients(hidden11,X),feed_dict={X:pre_Data[pre_Data.columns[:-1]]})\n",
    "bb = sess.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f377c330860>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl8VPW98PHPN5NMNpYsBES2QEBstBppBNxRsJtre8Wrz70VW+9Fe2+fUuvTVu2i3R7topb23hZpq8JjqwVvrV4tVwVxQQQJGJAtkkBCCCEM2Ugmy2SS3/PHzBwmyUwySWYyk8n3/Xr5ysyZMzPfnOD3/M73/BYxxqCUUmrkS4h2AEoppcJDE7pSSsUJTehKKRUnNKErpVSc0ISulFJxQhO6UkrFCU3oSikVJzShK6VUnNCErpRScSJxOL9swoQJJjc3dzi/UimlRrydO3eeMsbk9LffsCb03NxcioqKhvMrlVJqxBORilD205KLUkrFCU3oSikVJzShK6VUnNCErpRScUITulJKxYmQermISDnQBHQCbmNMoYhkAX8BcoFy4FZjTH1kwlRKKdWfgbTQrzbGFBhjCr3P7wc2GWPmAJu8z5VSSkXJUEouNwFrvI/XADcPPRw1WtU5XTz5dhl1Tle0Q1FqxAo1oRvgdRHZKSLLvdsmGWOqvY9PAJMCvVFElotIkYgUORyOIYar4tX6okoe2XCQ9UWV0Q5FqREr1JGilxtjqkRkIvCGiBz0f9EYY0Qk4GrTxpjVwGqAwsJCXZFaBbS0cFq3n0qpgQspoRtjqrw/T4rIi8B8oEZEJhtjqkVkMnAygnGqOJeVbufuq/KiHYZSI1q/JRcRSReRsb7HwKeBvcDLwDLvbsuAlyIVpFJKqf6F0kKfBLwoIr79/2yM+R8R2QGsE5G7gArg1siFqZRSqj/9JnRjzGHgwgDba4HFkQhKKaXUwOlIUaWUihOa0JVSKk5oQldKqTihCV0ppeKEJnSllIoTmtCVUipOaEJXSqk4oQldKaXihCZ0pZSKE5rQlVIqTmhCV0qpOKEJXSml4oQmdKWUihOa0JVSKk5oQlcqAF20Wo1EISd0EbGJyIci8or3+TMickREir3/FUQuTKWGly5arUaiUBeJBlgBHADG+W37ljHmhfCGpFT06aLVaiQKqYUuIlOB64A/RDYcpWKDb9HqrHR7tENRKmShllx+BXwb6Oqx/aciskdEnhCR5PCGppRSaiD6Tegicj1w0hizs8dLDwDnAhcDWcB3grx/uYgUiUiRw+EYarxKKaWCCKWFfhlwo4iUA88D14jIs8aYauPRDjwNzA/0ZmPMamNMoTGmMCcnJ2yBK6WU6q7fhG6MecAYM9UYkwvcBrxpjPlnEZkMICIC3AzsjWikSiml+jSQXi49/UlEcgABioF7whOSUkqpwRhQQjfGvAW85X18TQTiUUopNUg6UlQppeKEJnSllIoTmtCVUipOaEJXSqk4oQldKaXihCZ0pZSKE5rQlVIqTmhCV0qpOKEJXSml4oQmdKWUihOa0JVSKk5oQldKqTihCV0ppeKEJnSlhqDO6eLJt8uoc7qiHYpSmtCVGor1RZU8suEg64sqox2KUkNa4EKpUW9p4bRuP5WKppBb6CJiE5EPReQV7/OZIrJdREpF5C8iYo9cmErFpqx0O3dflUdWuv7zV9E3kJLLCuCA3/OfAU8YY2YD9cBd4QxMKaXUwISU0EVkKnAd8AfvcwGuAV7w7rIGz0LRSimloiTUFvqvgG8DXd7n2UCDMcbtfX4MmBLm2JRSSg1AvwldRK4HThpjdg7mC0RkuYgUiUiRw+EYzEcopZQKQSgt9MuAG0WkHHgeT6llJZAhIr5eMlOBqkBvNsasNsYUGmMKc3JywhCyUkqpQPpN6MaYB4wxU40xucBtwJvGmH8CNgO3eHdbBrwUsSiVUkr1aygDi74DfFNESvHU1P8YnpCUUkoNxoAGFhlj3gLe8j4+DMwPf0hKKaUGQ4f+K6VUnNCErpRScUITulJKxQlN6EopFSc0oSulVJzQhK6UUnFCE7pSSsUJTehKKRUnNKErpVSc0ISulFJxQhO6UkrFCU3oSikVJzShK6VUnNCErpRScUITuoqYOqeLJ98uo87pinYoSo0KmtBVxKwvquSRDQdZX1QZ7VCUGhX6XeBCRFKAd4Bk7/4vGGMeEpFngKuARu+udxpjiiMVqBp5lhZO6/ZzNKhzulhfVMnSwmlkpdujHY4aZUJZsagduMYY0ywiScAWEdngfe1bxpgXIheeGsmy0u3cfVVetMMYVr6rEmDU/e4q+vpN6MYYAzR7nyZ5/zORDEqpkWo0XpWo2BFSDV1EbCJSDJwE3jDGbPe+9FMR2SMiT4hIcpD3LheRIhEpcjgcYQpbqdjkuyrRcouKhpASujGm0xhTAEwF5ovI+cADwLnAxUAW8J0g711tjCk0xhTm5OSEKWwVi7RXi1LRNaBeLsaYBmAz8FljTLXxaAeeBuZHIkA1cmivFqWiK5ReLjlAhzGmQURSgWuBn4nIZGNMtYgIcDOwN8Kxqhin9WOloiuUXi6TgTUiYsPTol9njHlFRN70JnsBioF7IhinGgFGY68WpWJJKL1c9gAXBdh+TUQiUkopNSg6UlQppeKEJnSllIoTmtCVUipOaEJXSqk4oQldKaXihCZ0pZSKE5rQlVIqTmhCV0qpOKEJXSml4oQmdKWUihOa0JVSKk5oQldKqTihCV0ppeKEJnSlBklXaFKxJpT50JVSAfhWaGpxdZJmt7G0cJquJaqiKpQVi1KAd4Bk7/4vGGMeEpGZwPNANrAT+JIxRpsqatTwrczU4nLzyIaDALrAh4qqUFro7cA1xphmEUkCtojIBuCbwBPGmOdFZBVwF/C7CMaqVEzxrdBU53SRZk/UpfdU1PVbQ/cuBN3sfZrk/c8A1wAveLevwbOuqFKjji+xa7lFRVtIN0VFxCYixcBJ4A2gDGgwxri9uxwDpkQmRKWUUqEIKaEbYzqNMQXAVGA+cG6oXyAiy0WkSESKHA7HIMNUSinVnwF1WzTGNACbgUuADBHx1eCnAlVB3rPaGFNojCnMyckZUrBKKaWC6zehi0iOiGR4H6cC1wIH8CT2W7y7LQNeilSQSiml+hdKL5fJwBoRseE5AawzxrwiIvuB50XkJ8CHwB8jGKdSSql+9JvQjTF7gIsCbD+Mp56ulFIqBujQf6WUihOa0FXIdO4SpWKbJnQVMt/cJeuLKqMdilIqAJ2cS4XMN7R9NA9xr3O6WF9UqRNxqZikLXQVMh3irlcpKrZpC12NGLHQOtarFBXLtIWuRoxYaB3rVYqKZdpCVyOGto6V6psmdDVi+FrHSqnAtOSilFJxQhO6UkrFCU3oakB0tKhSsUsTuhqQWOhpMhh6IlKjgd4UVQMyUnua+E5EgN5YVXFLE7oakJHa0yQcJ6JYGNikVF+05KKGZKSUMsIxIGiklpvU6BHKEnTTRGSziOwXkX0issK7/WERqRKRYu9/n498uCrWhJrkRkri78vSwmk88LlzR1y5SY0eoZRc3MB9xphdIjIW2Ckib3hfe8IY88vIhadiXailjHioYY/UcpMaPUJZgq4aqPY+bhKRA8CUSAemRoZQk9xIvZmq1EgyoBq6iOTiWV90u3fT10Rkj4g8JSKZYY5NxRGd1EqpyAs5oYvIGOC/gG8YY04DvwPygAI8LfjHgrxvuYgUiUiRw+EIQ8hqNAln7T0e6vhK9SWkhC4iSXiS+Z+MMX8FMMbUGGM6jTFdwO+B+YHea4xZbYwpNMYU5uTkhCtuNUqEs2eJ9lJR8a7fGrqICPBH4IAx5nG/7ZO99XWALwB7IxOiGs3CWXsf6mdpP3QV60Lp5XIZ8CXgIxEp9m57ELhdRAoAA5QDd0ckQhUTopXMwtmzZKifFQ89dVR8C6WXyxZAArz09/CHo2KVJjPtqaNinw79VyEJdzIbieUL7YeuYp0O/VchCXe3w2jeoNTeLipeaUJXQzLY5BjNYfQ9Tyaa4FW80JKLGpLB1tajWb7oWT4ayO8wEktFavTQhK6GJNI3CiORQHueTAbyO+jNYRXLNKGrIYl0S3s4EuhAfgft6aJimSZ0FZJolRoimUDrnC7WbD0CCMsuzQ3p99KeLiqW6U1R1U2wG4TR6pUSyUm91hdVsnJTKSs3HWJ9UaXeHFUjnrbQVTfBShzxWGpYWjiNFpcbEJYWTgu5vKM3RlWs0oQexwaTeIIl7kiVGoaaHIfy/qx0O/deO9d6PpoW61DxSRN6HBtM4hnuGvFQk2M0kms8Xq2o+KAJPY6NhMQTaozBWuLh/B1DPTnojVEVq/SmaByLxA3FaN04DHZTNpy/o2/06pL8SX3+jnrzVMUqbaGrAfEl1hZXJ2l225BvDIbaKg6lJT7Uerzv5PDk22V9xqQ1dBWrNKGPEuHqmeFLqC0ud1iSWqglk1DKHOFKtL5YfC31nsdsSf4kth2uZUn+pEF/h1KRoAl9lAhXsvMl1jqnizR74pBr11npdqvLYLhONuGIqa+W+svFx9lc4uCCqce599pzhvRdSoVTKEvQTQPWApPwrE602hizUkSygL8AuXhWLLrVGFMfuVDVUIT7Bmk4bwyG+2QD4bkiCd4SNz1+KhUbQrkp6gbuM8bkAwuBfxeRfOB+YJMxZg6wyftcDZOB3pgbjhuksTSVbqgjW/uKeeP+GjaXONi4v6bb9mWXzuSBz53Lsktnhi1epcIhlCXoqoFq7+MmETkATAFuAhZ5d1sDvAV8JyJRql6G2qoNRwu2ZwyxdLMwHIOERkK3T6X8DaiGLiK5wEXAdmCSN9kDnMBTkgn0nuXAcoDp06cPNk7Vw1CTTTiSb88YBhtTJE4EoZaE+oo52GfE0olLKX9iTGh1QBEZA7wN/NQY81cRaTDGZPi9Xm+MyezrMwoLC01RUdGQAlbhEUvzkcRSLKEYzCyNSg2FiOw0xhT2t19ILXQRSQL+C/iTMeav3s01IjLZGFMtIpOBk4MPNz7tqqjnm+uKmZ+bRUa6ndSkBG4smMLLxVWEOxkMNCmO1tGOgzl5+L8H8NblhZWbDpFmt43K46hiUyi9XAT4I3DAGPO430svA8uAR70/X4pIhCPUrop6bn3yfdxdhvLaFmv7zooGtpSeAqC6oRVHczvLLsllzfvlfO/6fPJyxoT8HWWOZh56aR+zJqRTUnOa7UfqaXF1jriudMNZwhjMd/m/B+CRDQdZsXh2txu5I+0qQ8WnUFrolwFfAj4SkWLvtgfxJPJ1InIXUAHcGpkQR6ZvvbAbd5ennJWdlkRSYgInTrdzqKaJscmJNLW7eXnPcdo6uth9rIE6ZwdHTu3gpoIp/bbcfcnj3UOn2FJ6yjpBALxUXMWNBWeTmWYfMQnGM41tJy0uN3VOV0TjHUyd3/899S0uth2u5caCKd2OsdbVVSwIpZfLFkCCvLw4vOHEj1/cciF3PLWd5vZOals6rO01Te0AJCYIbR1dzMhKo2DaeN762EF5bQsrNx1iZ0Udv759Xq/EVud0sertMl7fd4Ly2hamZaYyb3oGVfWt1DS1k5KYQHltC8vXFrH43ImsfvcIz26r4HOfnMw9A+yyOBzT2vrvk2a38ciGg6TZEyOaEHuWmkKJ03/wU4vLzeYSBwtneboy+pK49ohRsUBHikbIvBmZZKbZaW5vtbYl24T2TsPYZBtN7Z2kJyfQZQwv7a7u9t4tpbV89dmdJNmEH950vlWGWfV2GavfOQx4TgiV9a3YEoSJY+3UNLWzaO4EPiivp8zhpLPLk3Aq61tZ/c5hNnxUPaDEHqjFOZAkH0qL1X+faA2nD7Vl7dtvxeI5vfrM+46HtsxVtGlCj6Crz53I2vcrrOftnYbc7DRaXG6a2jtxtnfhbG8lPdmGs72Ts8ancKKxjSkZKWw/UgfAt9bv5g/LLmbV22U898GZz3J3GVISpVt9vrm9izpnB3k56ZQ5nKQkJtDm7gLOJPZ9VY0U5mZZZZ2eSdr33JdYlxZOs64MXtt7goq6Fp58p4zHlxZQUtPEkvxJbNxf0+e0tqFMfbu+qNJq+eZd1fd9hHDWq0NtWfvv5/+dvmkQAs35onV1Ndw0oUfQN5acw0vFVTS2ugHPsFz/BGwT6DRgujxJd/K4ZL58aS6bDtRQ1dAGwIdHG3h0wwHWFR2z3nfWuGROnG6nzW0Yn5pIY6ubaZmpzJqQzqdmZHDVORP5l7U7qHN2kJwojE1OJEGEhAThvbJa3iur5bntFTx39yVs3F/DIxsOUtvsYn91Iy2uTnYdbWDTgRoKpmey6q1S9lc3WXX6BIE6Zwf3PLuTNncXz26roLLecxXi30L1b7EGmxPFfx/fcnAtrk5r1GawZBjOerWvnBKoG2LP3i0A9S29k3SweM7MTOm25r3RxK4iSRP6AN373E5e3H0CgHGpCTxz50LmzQjc/T4r3c7Td87nllVb6TLQ1eP1Tu8QgNwJY9hf3cTFM7O5+6o8Ls7N4mt/3kV1YxsGuiVzgE/nn8XhU062lJ6isdVNSmIClfWtrN1WwR0LZ3DvX4qpc3ZYLfR2dwc9nWx2cd3Kd1j1z4XccckM1r5fbrXmAT4or+eD8jNT86TbbThdnXQZSE1KoLXjTMt/bIqNuZPG8sQbJbS6umhocfH+4VoumZVNRloSbR1dLJiZRW2zK2iy9v1cuekQYEizJwZN2hfnZpGXk87FuVmB/0gD5FssGrCmBPbUyzu98WA9fveQgy2ltd3iCtbKPzMzZafeMFXDQhP6APmSOcDp1i6++Lut1vNHvnA+ty+Y0W3/eTMyeWrZxdz5zI5en5Ug0GUgJcnGisVzuLHgbJ54o4TNJQ6ON7aRl5NGmaOl1/u2H6llwcxsDjuaOd7YRpu7i5REoc1tWFd0lDa350yRnpzQLUn31OY2PPzf++jsMr32S00E74UFAE5Xp/X4hgsm89r+GuvKo6mtk7vW7LBOUD6VO7ufiLYfqWP3sQaSbNIrKQK0urqsn8suDV4K+c2bhyhzOPnNm4d4+svzg/5+/voqfwRbLNq/a6KnBQ/5k8dzxZycbnEFq593n5nSFnQ6XqXCRRP6AE0am0RNU+8WL8ADL+7lgRf3AnDnJdN5+KZPArDo3IkB9/f2amTX0QYcTe08/8FRqxcMwOkWt5X0/ZXUNFNS02w993WDTElKoK3jTGKudboJxJYAnd7dGltcmAB9mPyT+ZSMFKoa2khJTODGCydTUddKY6ubBM5cdfgn87wJaZTXttBpYFxKIqfb3CQnJtDu7rLuDZw9PoVX9xzn1T3HSbQlUDgjy+pLlWq3BU2SdU4XcyaOoaPT8L3r8wP+foH0V6bxL4n4ulGC6Za4VyyeE7Qk01eC7jkd77qiSlbfUTigMQdKhUKXoAsi2Cx8f15+KamJ/R+2Z94/Su79r3LvczsB+OaS2UH3FTylC18yT7N7Pr+lo7NXMvd/j09Lh6f13NbRhS1Acu65rdOvMV7f6qahJXDi97nuk2eTm51Gm7uL443tzMhKA3qXkHwczS46DczISuOz550FQLu7i8tnZ7NgpqdMcryxjT1Vp9lTdZpdRxtY/e5h2lydXD03hxsLzg4ay/qiSla/e4Qr5kywEmIoszz6z+jYc/+eMzNmpdtJs9tYuamUpau2suqtMlZuKiXNe6Lxfed964q7vc/3uWWO5oDxLC2cZt2w/skr+3UpOxV2oyqhD+R/oGDTr+bljOG9Bxbz2fNC61734u4T5N7/Ko9vLA26T8+cLd4ms3+Zo6/3dPplff+WckpiAuLdlpgA9kH8tX3dIn3fUVHrZO/x032+53Sb5wQxPjWRlCQbAPOmZ/CpGZl857PnMi0zFYB0ewITxyYzIT0JgL/sOMrmEoeV7AL9vQJNtRvob9Xzvf7TB/vvX+d00eLqZMXi2b26IvqS7+v7T/R63dcrJy8n3eoR5Pvc5WuLAiZ6gNV3FHL13By+d32+tf9964o1qauwGFUll4H0juhvFr5VXyqkzunitlXv8XGAOvdQODs6sdsEV8+i9AD518X7KKX3qbPL8JO/e46ZTTxXEonS2s+7PPZUnabNe/VQUuNpie+saLB6xThdXThd7UzJSAE6aO802AQ2lzisZNjz7xVohaNAf6tQp8X13BA9xAOfOxegW4179R2FLF9bRJnDSZo9sVeXy22Ha6350vOuGtNt22V52VaPnZ6x+Or+mYV2a//1RZV6w1QNme3hhx8eti9bvXr1w8uXLx+27+tpVs4YKwGk2m197ptqt1GYm9Xnfql2G1+6dCZ5E9LZsPdE0P0GY4i5vE8JMri1dnzvGci5oanVTaeBDu8v5O7sIj3ZRnN7J/OmZ3DDhWfz8Ykmmtrd1ndMy0wlMUF4bV8NNxdM4YufmsqareVsO3yKuWeNsxJkVrrd+hvNyhnD+qJKZuWMsZ77/63rnC7Wvl9ubfd/n3/XxV++/jEpSQlckjcBgFaXm4WzsvlfC2Z0+7eQardx5Tk5pCTZ6OjsYu5Z48hKt3PlOTlkpdvJGZvCyk2HyEq3syR/EmUnmxmTksTZGams2XqEbYfrKJiWwWfOO6vbZ/T371KNTj/84Q+rH3744dX97TeqWuiBbrSFY/DHDQVTuGxOTkRa65EQrC4fCTljkznu7X4Jntq5T0nNaY43tHLidDv2BPB2cqGyvtVqxf/5g6MUH2tgz7FG4MzNy55zv/RsBff8W/d83f/v7nu+s6LBu7dY71m5qZSr5+YE7H/uq7U/suEge4418titBb16tviuAnz9/zcdqKHM4QTglT3HWX1H4bBNe6Di36hK6IGEcz3L1++7ml0V9Sx7ejtNbcHr36OJfzLvyTNS1nMj2L/V7xtwBZ4Rsb5kvmBmlpVQeybBYCWyYCNf71tXzOYSB3/efpSr5uawt6qRXUcbWDDTM4rWt6+vJAL7vT+7/ztZkj+Jdd56un/ZxL80tCR/Ei0uNzsr6tlSWktudhqdXca6OfrYrQUBY1dqoEZ9Qg/3pErzZmTy0cOf5bntFVYXxtEs1IsB/xp/sHLTgerT/Grjx3xjyTksyZ/Eu4dOUdvcbrXSA52Q12wtZ+WmQ9a0wv7JPDUpgYq6lm7TM1TVt7Lq7TJSkxJYdulMHru1wErKC2fV9OpLvnG/p8V9+ewJvWaL9DUWth2u5bFbC7ixYIpVk19+xUwOnWzme9fnW2WZrz/3IfmTx3LPotnaT10NyqhP6JGaVOn2BTO4fcEMTexhdLrNzdr3K/ifj6qZmTOG7Ufq2FJ6ilS7jXuvnRukfOY5O7S63Dz5dhm1ThebSxzkZnv6ys/ISuOquTkAvF3ioKKuxZoAbdvhOv7vFz/ZLYaXi6tYuanUGs7va/m3uNys3FTKK3uq+cUtF7KjvM4a0bq5xMF964qZM3EsZQ4nC2ZmgggXTB1PZponzp+8st+aCjnVnmiVazSxq4EIeQm6cIinJegGUnvfVVHP3WuLcGjXtIi4YMp4Em1worGd441trFg8m3uvnQuc+Tv5hu77EvnyK2aSPSa529/Pt7TcX3dVWTX8q+fmsLnEweWzJ7Cl9BTLr5xFdrqd2mYXq989bH1XndPFF3/7HuW1LdZ3+N7re+4bZDUtM9X6/NzsNP5458UAPPTSPvInjyXV2wd+xeLZOgeMAsK8BN1oFixx+9fee3aj62nejEx2fP9adlXUs/z/7eBUc+CRpqo3of+yzZ6qxm7P39hfw/qiY2SkJZGcmMCcSWM5VNPEtMxUymtbuCwvm9QAiTIr3c69187lxoIp/OBvezlvynhrYNS0zFS2lMK+qkZ+dPP5PPjXjwB4Zms5F03LpKSmiSvnTKC89ijzczOZOSGdZZfkWu8trz1q9c+vrG9lfEoijW1uymtbWLpqK3+442I+NSMDEGtglW91q9pmF4dONg14RSs1+vTbQheRp4DrgZPGmPO92x4G/hVweHd70Bjz9/6+bCS20H3DtR/43LlBF0bwJfe+9vFPHGWOZv7t2SJKapzD+rsoz1QEWelJlNe2cs3cHAxYibLn36vM0cxdz+zwtOivnMXuyga2H6ljwcwsawoD8MxN7+4yzJueQZrdxqwJY1i7rcKaimHF4jm8X3aq22Rn4J1rp8PQ2WWsVjzA8itm8fp+zyImKYkJZKQlceJ0O1fPzQl57hoVX8LZQn8G+A9gbY/tTxhjfjmI2EaUYDdNe079GmifYD1o8nLG8Nq9i9hVUc/tq7bSPozdCEcL/3lm/J1uc1st5Te9vVZqm4tZmJfNho+qqaxv5T83l5KbncbJpnZOnPb0wmlocbHnmKdbY0enZxqD7HQ7r+2vsebP2XXU8/oxbzmlraOLlKQEWjs6eeQfLuChl/ZZ0xAnJwrO9jMR1pz2dOeclpnKhr3VVkmmzd3FidPt5GanMWfimH6nFlajW0g1dBHJBV7p0UJvHmhCH2wLva96dX+17GCvD3T7YGL01WR9l9GBFoIA+MM7ZdZoTBV7EoFxaYnUeee88U0fPCbZxkVTM9h6pNaaH8dXIjpn0hgO1TRb5aLc7DQev7WAx9/42ErqPctJ/iehdHsCXV2GVrchMQHyzx7PnmON5OWks/gTk1j9zmEWzMwiMUH40c3naykmzg1HDf1rInIHUATcZ4ypD7STiCwHlgNMnz59UF/UV1/x/vqR97f4AHSvgff1eb6kfXFuFr9581C3muaarUes3g++G3IAe441srnEwZ5jDWwucfRa7KDO6ZnIakK6nVN60zQmucFK5oA1F3xzeyfvltV229eXoA+fbO6WrMtrW/ji77ZyeV62lbh7NqX8ryicru7TNuw51kiqTShzOHE0HeWCKeOsss9dz+zgj3deHLTBMFS7KupZ8fyHpNltOJracLq6+OUtF3BDwZRei4AEagztqqjnm+uKmZ+bRUa63eoS6tvff9WrntuW5E9izXvlvHPIweO3FgRde0B5DDah/w74MZ5/kz8GHgO+EmhHY8xqYDV4WuiD+bK++or3txZlf4sP9EzifX2Xbz/fpE2wn6e/PN87ytB3PpNu+/smcPrf18xh4azsbosdLC2cZvWJvmPhDJ4DRSXHAAAQKUlEQVTfcXTI87eo2OAO8mfc0uMEMBCt3n8bp9vc3SZIK69t4c6nPqCyvpXX9p0gzZ7ID286r1ervczRzE9e2c/3rs8nM83eLRGv2XqE1o4uK9lmpdt56+BJvv78hzS1uXudfP7P+t3cUDCl2/870HvuHYBvriumvLal22pdv91cRnJSAs3tnTy15Qg1Te385+ZDNLd7Zhj99aZDOF2d/HrTx9bJ7Z/+sI1P509i44EajBGgk5YOWDJ3An/48oJBH9d4MqiEboyp8T0Wkd8Dr4QtogD66iu+cX9Nn2tR9rf4AAx8XUn/Fjp4EveW0lqunptjjTL07e8babijvC7gkPDNJQ6unpvDN649h2WX5fKF/3zPqvEqFUzP6Rt8NXdfHX/xY29br+VPSudwbStjkxO9XWf3s3BWtpV8q+pbWLvtqLX/b94sxSbQ0cekPe2dhtz7XyXR237xjNqFJJuw/XAtr+07gbvLcPRUMw0BRk13dBk62j3bfdNGn/bbzzfTqP+VSmtHV68F1QE2lpziue0V3RaX8R8h/HJxFb6y58vFxwFjnbTizWBr6JONMdXex/cCC4wxt/X3OZHo5RLOmjcE79Uy2BgG+lqZo1mTulKDcMfCGXzj2nOob3Hxlad3UFHXwvzcTKt30WV52bznvUIayP/fsSDUGnoo3RafAxYBE4Aa4CHv8wI8JZdy4G5fgu9LLHVbDKU7YjTO4HVOF6veKuXl3cetHhZKqdBMy0wlZ6ydXUc9YxMmjrFzstlzb2pcSiJnjUumub2Ty+dMICPVTqrd1m0VqlgVtoQeTrGU0KOduIPxnWhWLJ7N5oMn2VPV92ISSqnuBrqWwK2FU/n5LRdGMKKhCzWhj6oVi/z5r2ATS3wr8iy7dCbPfGUBKTqWV6kBGWjHgld2H49QJMNv1LbQR4pdFfV88Xdbox2GUqNWEuCbrOObS2bz9SVz+9o9IrSFHid+9boOOFIqmvxnXnqij7WBY4Em9GE20JXe3ymr638npVTEJPk9vnfJ7KjFEQqt0A6zcK2QpJQauEtyMzjp7LCWAQzkq1fO5PkPKqhv62J8svBv18yNuc4TwWgLfZj5bnrqcmNKRU5WuqddffnsbJZfOYvc7DQAShxOyhxOrvYuagKeOe93ff9a8nLSAXj9wEk2fWsx5Y9ex52Xz+aRDQf5+nMfUud0sauinsWPvcVbB0/y5NtllDmarZ9PvPExT7xRwq6Ker789AeUOZqH/ffWFvowi9QKSUqNZsk2uOmiqWSk2q3ZKhMEtpTWsqXUM5goKz2JOmeHNRXHnIlj2V/dyPeuz2d9USVlDidZ6UmUOZx+68N6Oo1sKT3F+qJK1nn3++b6YuqcHdZI8HcPOazvean4OOW1LTjb93BJ3gSGc2SqJnSl1IiUZBMeX3ohf/2wqtfiH6vfPUyXgcy0JG644GzKHM3c9+m5/ObNQ2wucfD2xydJtSeQf/Z4Xi6u4saCKbS4Oml1ddLW4ebNgyepdbr4x4s9V9Ktri5aXJ18/7p8fvzqfr5/XT4lNU3WWrO1zS62lNZy+exsZk0YQ3ltBSLCyk2HAKzFzCNNE7pSasRJSUzg1RVXkJczhhsKpnR77Z5FebR1dLK55CSX5GVT5mjmvbJaCj92cMHUDC6YOh44k2zBk3DBsPrdw9ZiI9uP1JGaZANg9zHP4iYTxybT1tFJU5un70tmmt2aoyl7jN0qpU7JTPXOI+OZO2a4Sqya0GNc+aPX8S9Pb2djyaloh6JURIxNsdHU1kmCeOYq7W9cUHJiAn/+14VB54DPSrfzo5vPt0Zdg6dO3upys/rdI6xYPNs7iZ7xTIVsjKd17p2N7Mo5OWSlN+BoclHvdLF2W4X12Se9E4l94y/FVpz+029D9ymE7732HO+6COUMR+lFE/oIEGhq0PtfKOb5oqooRKNUaJJsQoc36/kWyAYYm2xjTHISBsOJ0+3cPn8G2en2Xss5+p775kTfeKCGs8an8IulF3ZL5sGm8VhaOI1ap4t9VZ46uae1DCBkpdtZdulM1mw9Yq3dumLxbOt771tXzK6jjRw+1WxN6nX2+BSON3pWluo0kJeT7onNby0EX8v/3UOn+PXtF5GV7pmmeLhKL5rQR6hHbyng0VsKem3Pvf/VKESjYtHic3N48Lr8iC18AXDFz960pu71SUlM4MYLz+buRXlWyeGiaZl8/fkPOd3m5gvzpvKjm84PmIj9p7L270Dwo5vP50c3nx8whmBdgbPS7WSn23mvrJaN+2tYdmmuNXW1730rN3kGCnmmvj7TevZMjd197njfVLytHV3sq2q0PvfMGghn1qDy3US9+6o8lhZOo8XVyXCUXnTofxzSpB5/nrnzYhadO7Hb5fvOinqrZ8WCmZl0dBp2HW1g+RWzePC6TwxLXD/420es3XaUSWOT+cz5Z3HY4bSW2BuumUyHMn21b4nIgc64GGylJmDQn9kXnW1xFKtzuviH327hSG1r/zvHkWALQ490eTnpbLpvEXVOl7XC1QOfO5cl+ZN46KW95E8ezz2LPIlzuGcQ7Zkwh7NePJpoQlf8emMJj4cw90QS8Ps7Lwbgy8/s6LXcWKzyXeBmpSdS53Rzx8IZZKbbqW5o4eXdx2kLtg7cEGWk2Gjp6BrScoEJ0nvVoWCWXzGTB6/Lt27yXT03h8duLdBkOYqEbZFoEXkKuB446bdiURbwFyAXzwIXtwZbJFpFz9eXzB3wzHA7v38tv3qjhP/eU019S0e313omoUTxrJ2ZIGBM70WPw6ln6zs5URiXnITD6SIpwQa4SUlKoNXlZt3OMzeLp4xPoaqxza+6OXhjk2387WuXk5czhjqni1+9UcLzOyoHldhDTeaTxiZzzyLP/CE968tK9RTKikVXAs3AWr+E/nOgzhjzqIjcD2QaY77T35dpC33k8CSsj9lccpJWl5tTzjPJ3b/HwkBamv5J1b8HRH/sCeAKUkvJSEvkqjk5vLS7mnnTM3A0tVNZ34pNPD0R0pMTcLZ3kZ2WRG1LByk2oW0QCXhcSiIv/vtlARdefvCve+joNDS3dfDxyeBzhITCBvivwLn8ylk8+PnhqYer2BXWkkuANUVLgEXGmGoRmQy8ZYzptymoCX1kKnM084O/7SUvZwyZ6Ulcdc5EfvY/BzHG8KWFM/j5ayVkptspmJpBW4eb9w/XccmsLDLSPYMwDlafpmB6Jm0dnax9v6LX56fbbRi6aHEZJo5Nxuly4Ww3jElJ4JyJ46yFj88al8zZGal4Tgtibb9gyrhuKzslJgjuIGeZdLvNWoAY6LPlnpFqw90Fsyak88RtFwXt9+zjqx/XO9t5bkdl0BNWKFcL41MT+ceLp3NPDC7CooZfpBN6gzEmw/tYgHrf875oQh/dfAmv1eUG8dRpUu2J3kEeBO018NVnd7L9SB0LZmax/YhnOuHLZ2fT4upk19EGzhqXzInT7YxJtiEITe1uxqcmkpczxkr6Y5JtNHtXmU9NSqC1o4us9CR+eMN5fPdve7HbhKwxdk63upk4NpmFeROGlEx3VdTz1Wd30uJyM3l8SsCWe7DEPi0zlWe+Mr/fE4gaPYYtoXuf1xtjMoO8dzmwHGD69Omfqqjo3UJTqi++nhS+odRF5XW8V1ZrDfiYNz3DStz+ViyebQ0aueOSGRx2NJM/eTyX5mXz41f384tbLmTejID/bMMe/5qt5ZSfauLNEgepSTZONvWeD9/Xf/v+z39CW+WqGy25qLjln+A37q/pNuDD1+RNtSew7NKZwPB35euP74bq5hIH86aP58RpFxdOzeCeRVpeUYFFOqH/Aqj1uymaZYz5dn+fowldKaUGLmxriorIc8D7wFwROSYidwGPAteKyCFgife5UkqpKOq3H7ox5vYgLy0OcyxKKaWGQJegU0qpOKEJXSml4oQmdKWUihOa0JVSKk5oQldKqTgxrNPniogD6Guo6AQgVhfP1NgGL5bj09gGJ5Zjg9iObzCxzTDG5PS307Am9P6ISFEoneejQWMbvFiOT2MbnFiODWI7vkjGpiUXpZSKE5rQlVIqTsRaQl8d7QD6oLENXizHp7ENTizHBrEdX8Rii6kaulJKqcGLtRa6UkqpQYqZhC4i94mIEZEJ3uciIr8WkVIR2SMi86IQ04+9310sIq+LyNne7YtEpNG7vVhEfjDcsfUTXywcu1+IyEHv978oIr4VrnJFpNXv2K2Kldi8rz3gPW4lIvKZ4Y7NG8NSEdknIl0iUui3PRaOXcDYvK9F/dj5xfKwiFT5HavPRzMeHxH5rPf4lHqnHg8vY0zU/wOmAa/h6aM+wbvt88AGPCt1LQS2RyGucX6Pvw6s8j5ehGd++Ggft2DxxcKx+zSQ6H38M+Bn3se5wN4oH7dgseUDu4FkYCZQBtiiEN8ngLnAW0Ch3/ZYOHbBYouJY+cXz8PA/4nmsQoQk817XGYBdu/xyg/nd8RKC/0J4Nt0X2LxJmCt8dgGZHhXRxo2xpjTfk/T6X9t32HVR3yxcOxeN8a4vU+3AVOH8/v70kdsNwHPG2PajTFHgFJgfhTiO2CMKRnu7w1FH7HFxLGLcfOBUmPMYWOMC3gez3ELm6gndBG5Cagyxuzu8dIUoNLv+THvtmElIj8VkUrgnwD/0solIrJbRDaIyHnDHZdPkPhi4tj5+QqeKwafmSLyoYi8LSJXRCsoL//YYu24BRJLx85fLB67r3nLak+JSOQXj+1fxI9RvwtchIOIbATOCvDSd4EH8VwCR0VfsRljXjLGfBf4rog8AHwNeAjYhWcobrO3Nvc3YE4MxTcs+ovNu893ATfwJ+9r1cB0Y0ytiHwK+JuInNfjaiNasQ2bUOILIGaOXSzoJ6/8DvgxnqvWHwOP4Tl5x7VhSejGmCWBtovIJ/HU23aLCHgufXeJyHygCk9t3Weqd9uwxBbAn4C/Aw/5/w9kjPm7iPxWRCYYY8I+d8Rg4iNGjp2I3AlcDyw23iKiMaYdaPc+3ikiZcA5QFgXmx1MbAzTcQslviDviYljF8SwHTufUOMUkd8Dr0QylhBF/BhFteRijPnIGDPRGJNrjMnFcwkyzxhzAngZuMPbY2Mh0GiMqR7O+ETEv9V9E3DQu/0s8Z6BvCefBKB2OGPrKz5i49h9Fs99kRuNMS1+23NExOZ9PAvPlc3hWIgNz3G7TUSSRWSmN7YPhjO2vsTCsetDTB27HveMvgDsjVYsfnYAc0RkpojYgdvwHLewGZYW+iD9HU9vjVKgBfhyFGJ4VETmAl14euDc491+C/BVEXEDrcBtfq28WIgvFo7df+Dp8fCG99y3zRhzD3Al8CMR6cAT9z3GmLpYiM0Ys09E1gH78ZRi/t0Y0znMsSEiXwB+A+QAr4pIsTHmM8TAsQsWW6wcOz8/F5ECPCWXcuDuKMYCgDHGLSJfw9OjzwY8ZYzZF87v0JGiSikVJ6Ley0UppVR4aEJXSqk4oQldKaXihCZ0pZSKE5rQlVIqTmhCV0qpOKEJXSml4oQmdKWUihP/HzKnR+wtvxGjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# init = tf.initialize_all_variables()\n",
    "# sess.run(init)\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "plt.scatter(sess.run(hidden11,feed_dict={X: x_train,is_training:False}),y_train,s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X', 'Y', 'y_plus', 'wedge_height', 'Nu_t_lsq', 'Alpha_t', 'tke',\n",
       "       'dk/dx', 'dk/dy', 'dk/dx_i_abs', 'tke_diss', 'TV_prod(al_t_1)',\n",
       "       'tke_prod(nu_t_1_new)', 'Rp', 'Rd', 'TV', 'tke_sdm', 'tke_conv_turb',\n",
       "       'tke_pre', 'tke_diff', 'TV_sdm', 'TV_conv_turb', 'TV_diff', 'TV_diss',\n",
       "       'dp/dx', 'dp/dy', 'dp/dx_i_abs', 'u_du/dx+v_dv/dx', 'MKE_pre',\n",
       "       'MKE_diss', 'MKE_visc_diff', 'MTV_diss', 'MTV_mol_diff', 'dT/dx',\n",
       "       'dT/dy', 'dT/dx_i_abs', 'S_ij_abs', 'S_11', 'S_12(=S_21)', 'S_22', 'Re',\n",
       "       'Pr', 'dTvar/dx_i_abs', 'Rp/Rd', 'U-AVG-X', 'U-AVG-Y', 'U-AVG-Z',\n",
       "       'du/dx', 'du/dy', 'dv/dx', 'dv/dy', 'P_AVG', 'Pr_t'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "Data = pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\new\\새 폴더 (3)\\0D_mean_orig_channel.csv')\n",
    "Data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Nu_t_lsq', 'tke', 'tke_diss', 'dk/dx', 'dk/dy', 'dk/dx_i', 'dp_dx',\n",
       "       'dp_dy', 'dp_dx_i', 'dT/dx', 'dT/dy', 'dT/dx_i', 'S_11', 'S_12', 'S_22',\n",
       "       'S_ij_abs', 'u_du/dx+v_dv/dx', 'MKE_diff', 'MKE_pre', 'MKE_diss',\n",
       "       'MTV_diff', 'MTV_diss', 'Re_tau', 'Pr', 'Pr_t', 'X', 'Y',\n",
       "       'Alpha_t_lsq'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = pd.read_csv(r'D:\\Desktop\\190925\\wedge_pr_t\\csv_file\\RANS_wedge_Re180_Pr02.csv')\n",
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nu_t_lsq</th>\n",
       "      <th>tke</th>\n",
       "      <th>tke_diss</th>\n",
       "      <th>dk/dx</th>\n",
       "      <th>dk/dy</th>\n",
       "      <th>dk/dx_i</th>\n",
       "      <th>dp_dx</th>\n",
       "      <th>dp_dy</th>\n",
       "      <th>dp_dx_i</th>\n",
       "      <th>dT/dx</th>\n",
       "      <th>...</th>\n",
       "      <th>MKE_pre</th>\n",
       "      <th>MKE_diss</th>\n",
       "      <th>MTV_diff</th>\n",
       "      <th>MTV_diss</th>\n",
       "      <th>Re_tau</th>\n",
       "      <th>Pr</th>\n",
       "      <th>Pr_t</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Alpha_t_lsq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>-0.014934</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.659227</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-642.0495</td>\n",
       "      <td>-0.004652</td>\n",
       "      <td>-11.75585</td>\n",
       "      <td>590</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.077835</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006114</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>-0.014934</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.659227</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-642.0495</td>\n",
       "      <td>-0.031497</td>\n",
       "      <td>-69.59485</td>\n",
       "      <td>590</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.030240</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006114</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>-0.014934</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.659227</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-642.0495</td>\n",
       "      <td>-0.120045</td>\n",
       "      <td>-236.00250</td>\n",
       "      <td>590</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.026915</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006114</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>-0.014070</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>0.683528</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.012773</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-604.7260</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>-11.62130</td>\n",
       "      <td>590</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.076085</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>-0.014070</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>0.683528</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.012773</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-604.7260</td>\n",
       "      <td>-0.035687</td>\n",
       "      <td>-66.80715</td>\n",
       "      <td>590</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.023545</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nu_t_lsq       tke  tke_diss     dk/dx     dk/dy   dk/dx_i     dp_dx  \\\n",
       "0  0.000005  0.002493 -0.014934  0.000218  0.004311  0.659227 -0.000017   \n",
       "1  0.000005  0.002493 -0.014934  0.000218  0.004311  0.659227 -0.000017   \n",
       "2  0.000005  0.002493 -0.014934  0.000218  0.004311  0.659227 -0.000017   \n",
       "3  0.000007  0.003223 -0.014070  0.000062  0.004664  0.683528 -0.000017   \n",
       "4  0.000007  0.003223 -0.014070  0.000062  0.004664  0.683528 -0.000017   \n",
       "\n",
       "      dp_dy   dp_dx_i     dT/dx  ...   MKE_pre  MKE_diss  MTV_diff   MTV_diss  \\\n",
       "0  0.000017  0.009884  0.000001  ...  0.000011 -642.0495 -0.004652  -11.75585   \n",
       "1  0.000017  0.009884  0.000007  ...  0.000011 -642.0495 -0.031497  -69.59485   \n",
       "2  0.000017  0.009884  0.000019  ...  0.000011 -642.0495 -0.120045 -236.00250   \n",
       "3  0.000022  0.012773  0.000002  ...  0.000014 -604.7260 -0.005351  -11.62130   \n",
       "4  0.000022  0.012773  0.000009  ...  0.000014 -604.7260 -0.035687  -66.80715   \n",
       "\n",
       "   Re_tau   Pr      Pr_t  X         Y  Alpha_t_lsq  \n",
       "0     590  0.2  1.077835  0  0.006114     0.000004  \n",
       "1     590  0.7  1.030240  0  0.006114     0.000004  \n",
       "2     590  2.0  1.026915  0  0.006114     0.000004  \n",
       "3     590  0.2  1.076085  0  0.007173     0.000007  \n",
       "4     590  0.7  1.023545  0  0.007173     0.000007  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.rename(columns={'dk/dx_i_abs':'dk/dx_i','dp/dx':'dp_dx','dp/dy':'dp_dy','dp/dx_i_abs':'dp_dx_i',\n",
    "                     'dT/dx_i_abs':'dT/dx_i','S_12(=S_21)':'S_12','MKE_visc_diff':'MKE_diff',\n",
    "                     'MTV_mol_diff':'MTV_diff','Re':'Re_tau','Alpha_t':'Alpha_t_lsq'},inplace=True)\n",
    "data = pd.DataFrame(Data,columns=data1.columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(r'D:\\Desktop\\190925\\wedge_pr_t\\csv_file\\RANS_flat.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nu_t_lsq</th>\n",
       "      <th>tke</th>\n",
       "      <th>tke_diss</th>\n",
       "      <th>dk/dx</th>\n",
       "      <th>dk/dy</th>\n",
       "      <th>dk/dx_i</th>\n",
       "      <th>dp_dx</th>\n",
       "      <th>dp_dy</th>\n",
       "      <th>dp_dx_i</th>\n",
       "      <th>dT/dx</th>\n",
       "      <th>...</th>\n",
       "      <th>MKE_pre</th>\n",
       "      <th>MKE_diss</th>\n",
       "      <th>MTV_diff</th>\n",
       "      <th>MTV_diss</th>\n",
       "      <th>Re_tau</th>\n",
       "      <th>Pr</th>\n",
       "      <th>Pr_t</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Alpha_t_lsq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>-0.014934</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.659227</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-642.0495</td>\n",
       "      <td>-0.004652</td>\n",
       "      <td>-11.75585</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.077835</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006114</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>-0.014934</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.659227</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-642.0495</td>\n",
       "      <td>-0.031497</td>\n",
       "      <td>-69.59485</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.030240</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006114</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>-0.014934</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.659227</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-642.0495</td>\n",
       "      <td>-0.120045</td>\n",
       "      <td>-236.00250</td>\n",
       "      <td>0.59</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.026915</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006114</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>-0.014070</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>0.683528</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.012773</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-604.7260</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>-11.62130</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.076085</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>-0.014070</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>0.683528</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.012773</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-604.7260</td>\n",
       "      <td>-0.035687</td>\n",
       "      <td>-66.80715</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.023545</td>\n",
       "      <td>0</td>\n",
       "      <td>0.007173</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nu_t_lsq       tke  tke_diss     dk/dx     dk/dy   dk/dx_i     dp_dx  \\\n",
       "0  0.000005  0.002493 -0.014934  0.000218  0.004311  0.659227 -0.000017   \n",
       "1  0.000005  0.002493 -0.014934  0.000218  0.004311  0.659227 -0.000017   \n",
       "2  0.000005  0.002493 -0.014934  0.000218  0.004311  0.659227 -0.000017   \n",
       "3  0.000007  0.003223 -0.014070  0.000062  0.004664  0.683528 -0.000017   \n",
       "4  0.000007  0.003223 -0.014070  0.000062  0.004664  0.683528 -0.000017   \n",
       "\n",
       "      dp_dy   dp_dx_i     dT/dx  ...   MKE_pre  MKE_diss  MTV_diff   MTV_diss  \\\n",
       "0  0.000017  0.009884  0.000001  ...  0.000011 -642.0495 -0.004652  -11.75585   \n",
       "1  0.000017  0.009884  0.000007  ...  0.000011 -642.0495 -0.031497  -69.59485   \n",
       "2  0.000017  0.009884  0.000019  ...  0.000011 -642.0495 -0.120045 -236.00250   \n",
       "3  0.000022  0.012773  0.000002  ...  0.000014 -604.7260 -0.005351  -11.62130   \n",
       "4  0.000022  0.012773  0.000009  ...  0.000014 -604.7260 -0.035687  -66.80715   \n",
       "\n",
       "   Re_tau   Pr      Pr_t  X         Y  Alpha_t_lsq  \n",
       "0    0.59  0.2  1.077835  0  0.006114     0.000004  \n",
       "1    0.59  0.7  1.030240  0  0.006114     0.000004  \n",
       "2    0.59  2.0  1.026915  0  0.006114     0.000004  \n",
       "3    0.59  0.2  1.076085  0  0.007173     0.000007  \n",
       "4    0.59  0.7  1.023545  0  0.007173     0.000007  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data10 = pd.read_csv(r'D:\\Desktop\\190925\\wedge_pr_t\\csv_file\\RANS_flat.csv')\n",
    "Data10['Re_tau'] = Data10['Re_tau']/1000\n",
    "Data10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nu_t_lsq</th>\n",
       "      <th>tke</th>\n",
       "      <th>tke_diss</th>\n",
       "      <th>dk/dx</th>\n",
       "      <th>dk/dy</th>\n",
       "      <th>dk/dx_i</th>\n",
       "      <th>dp_dx</th>\n",
       "      <th>dp_dy</th>\n",
       "      <th>dp_dx_i</th>\n",
       "      <th>dT/dx</th>\n",
       "      <th>...</th>\n",
       "      <th>S_12</th>\n",
       "      <th>S_22</th>\n",
       "      <th>S_ij_abs</th>\n",
       "      <th>u_du/dx+v_dv/dx</th>\n",
       "      <th>MKE_diff</th>\n",
       "      <th>MKE_pre</th>\n",
       "      <th>MKE_diss</th>\n",
       "      <th>MTV_diff</th>\n",
       "      <th>MTV_diss</th>\n",
       "      <th>Pr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.132986</td>\n",
       "      <td>14.377132</td>\n",
       "      <td>22.268086</td>\n",
       "      <td>37.114486</td>\n",
       "      <td>44.346723</td>\n",
       "      <td>39.466290</td>\n",
       "      <td>48.009760</td>\n",
       "      <td>20.425027</td>\n",
       "      <td>26.667895</td>\n",
       "      <td>25.449422</td>\n",
       "      <td>...</td>\n",
       "      <td>37.441323</td>\n",
       "      <td>18.579268</td>\n",
       "      <td>27.418088</td>\n",
       "      <td>36.907974</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>21.496533</td>\n",
       "      <td>42.226601</td>\n",
       "      <td>20.145804</td>\n",
       "      <td>36.800436</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.185886</td>\n",
       "      <td>16.245140</td>\n",
       "      <td>22.510143</td>\n",
       "      <td>37.402969</td>\n",
       "      <td>45.271994</td>\n",
       "      <td>41.187298</td>\n",
       "      <td>47.862485</td>\n",
       "      <td>19.678991</td>\n",
       "      <td>26.818636</td>\n",
       "      <td>25.147700</td>\n",
       "      <td>...</td>\n",
       "      <td>37.512448</td>\n",
       "      <td>18.593374</td>\n",
       "      <td>27.545938</td>\n",
       "      <td>37.314369</td>\n",
       "      <td>49.868454</td>\n",
       "      <td>21.114644</td>\n",
       "      <td>42.114543</td>\n",
       "      <td>21.000677</td>\n",
       "      <td>36.867342</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.249500</td>\n",
       "      <td>18.250517</td>\n",
       "      <td>22.825082</td>\n",
       "      <td>37.582998</td>\n",
       "      <td>45.944272</td>\n",
       "      <td>42.437739</td>\n",
       "      <td>47.711269</td>\n",
       "      <td>18.942071</td>\n",
       "      <td>27.003289</td>\n",
       "      <td>24.887386</td>\n",
       "      <td>...</td>\n",
       "      <td>37.532589</td>\n",
       "      <td>18.652764</td>\n",
       "      <td>27.582043</td>\n",
       "      <td>37.693985</td>\n",
       "      <td>49.624822</td>\n",
       "      <td>20.757066</td>\n",
       "      <td>42.082673</td>\n",
       "      <td>21.784650</td>\n",
       "      <td>36.957200</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.324497</td>\n",
       "      <td>20.366414</td>\n",
       "      <td>23.175629</td>\n",
       "      <td>37.684747</td>\n",
       "      <td>46.345855</td>\n",
       "      <td>43.184686</td>\n",
       "      <td>47.554859</td>\n",
       "      <td>18.224296</td>\n",
       "      <td>27.211999</td>\n",
       "      <td>24.667237</td>\n",
       "      <td>...</td>\n",
       "      <td>37.502653</td>\n",
       "      <td>18.747683</td>\n",
       "      <td>27.528010</td>\n",
       "      <td>38.045613</td>\n",
       "      <td>49.295051</td>\n",
       "      <td>20.418061</td>\n",
       "      <td>42.130238</td>\n",
       "      <td>22.499872</td>\n",
       "      <td>37.069875</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.412217</td>\n",
       "      <td>22.562516</td>\n",
       "      <td>23.524736</td>\n",
       "      <td>37.727042</td>\n",
       "      <td>46.472720</td>\n",
       "      <td>43.420656</td>\n",
       "      <td>47.392680</td>\n",
       "      <td>17.532720</td>\n",
       "      <td>27.436014</td>\n",
       "      <td>24.485448</td>\n",
       "      <td>...</td>\n",
       "      <td>37.424750</td>\n",
       "      <td>18.872329</td>\n",
       "      <td>27.387712</td>\n",
       "      <td>38.368020</td>\n",
       "      <td>48.902306</td>\n",
       "      <td>20.094091</td>\n",
       "      <td>42.253057</td>\n",
       "      <td>23.150194</td>\n",
       "      <td>37.204829</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Nu_t_lsq        tke   tke_diss      dk/dx      dk/dy    dk/dx_i  \\\n",
       "0  10.132986  14.377132  22.268086  37.114486  44.346723  39.466290   \n",
       "1  10.185886  16.245140  22.510143  37.402969  45.271994  41.187298   \n",
       "2  10.249500  18.250517  22.825082  37.582998  45.944272  42.437739   \n",
       "3  10.324497  20.366414  23.175629  37.684747  46.345855  43.184686   \n",
       "4  10.412217  22.562516  23.524736  37.727042  46.472720  43.420656   \n",
       "\n",
       "       dp_dx      dp_dy    dp_dx_i      dT/dx  ...       S_12       S_22  \\\n",
       "0  48.009760  20.425027  26.667895  25.449422  ...  37.441323  18.579268   \n",
       "1  47.862485  19.678991  26.818636  25.147700  ...  37.512448  18.593374   \n",
       "2  47.711269  18.942071  27.003289  24.887386  ...  37.532589  18.652764   \n",
       "3  47.554859  18.224296  27.211999  24.667237  ...  37.502653  18.747683   \n",
       "4  47.392680  17.532720  27.436014  24.485448  ...  37.424750  18.872329   \n",
       "\n",
       "    S_ij_abs  u_du/dx+v_dv/dx   MKE_diff    MKE_pre   MKE_diss   MTV_diff  \\\n",
       "0  27.418088        36.907974  50.000000  21.496533  42.226601  20.145804   \n",
       "1  27.545938        37.314369  49.868454  21.114644  42.114543  21.000677   \n",
       "2  27.582043        37.693985  49.624822  20.757066  42.082673  21.784650   \n",
       "3  27.528010        38.045613  49.295051  20.418061  42.130238  22.499872   \n",
       "4  27.387712        38.368020  48.902306  20.094091  42.253057  23.150194   \n",
       "\n",
       "    MTV_diss    Pr  \n",
       "0  36.800436  10.0  \n",
       "1  36.867342  10.0  \n",
       "2  36.957200  10.0  \n",
       "3  37.069875  10.0  \n",
       "4  37.204829  10.0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    22.268086\n",
      "1    22.510143\n",
      "2    22.825082\n",
      "3    23.175629\n",
      "4    23.524736\n",
      "Name: tke_diss, dtype: float64\n",
      "    Nu_t_lsq      dk/dx      dk/dy    dk/dx_i      dp_dx      dp_dy  \\\n",
      "0  10.132986  37.114486  44.346723  39.466290  48.009760  20.425027   \n",
      "1  10.185886  37.402969  45.271994  41.187298  47.862485  19.678991   \n",
      "2  10.249500  37.582998  45.944272  42.437739  47.711269  18.942071   \n",
      "3  10.324497  37.684747  46.345855  43.184686  47.554859  18.224296   \n",
      "4  10.412217  37.727042  46.472720  43.420656  47.392680  17.532720   \n",
      "\n",
      "     dp_dx_i      dT/dx      dT/dy    dT/dx_i  ...       S_12       S_22  \\\n",
      "0  26.667895  25.449422  43.450366  16.549153  ...  37.441323  18.579268   \n",
      "1  26.818636  25.147700  43.469361  16.530290  ...  37.512448  18.593374   \n",
      "2  27.003289  24.887386  43.494949  16.504900  ...  37.532589  18.652764   \n",
      "3  27.211999  24.667237  43.526999  16.472982  ...  37.502653  18.747683   \n",
      "4  27.436014  24.485448  43.565642  16.434603  ...  37.424750  18.872329   \n",
      "\n",
      "    S_ij_abs  u_du/dx+v_dv/dx   MKE_diff    MKE_pre   MKE_diss   MTV_diff  \\\n",
      "0  27.418088        36.907974  50.000000  21.496533  42.226601  20.145804   \n",
      "1  27.545938        37.314369  49.868454  21.114644  42.114543  21.000677   \n",
      "2  27.582043        37.693985  49.624822  20.757066  42.082673  21.784650   \n",
      "3  27.528010        38.045613  49.295051  20.418061  42.130238  22.499872   \n",
      "4  27.387712        38.368020  48.902306  20.094091  42.253057  23.150194   \n",
      "\n",
      "    MTV_diss    Pr  \n",
      "0  36.800436  10.0  \n",
      "1  36.867342  10.0  \n",
      "2  36.957200  10.0  \n",
      "3  37.069875  10.0  \n",
      "4  37.204829  10.0  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "data13 = pd.DataFrame()\n",
    "data13 = data12.pop('tke_diss')\n",
    "print(data13.head())\n",
    "print(data12.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nu_t_lsq</th>\n",
       "      <th>tke</th>\n",
       "      <th>tke_diss</th>\n",
       "      <th>dk/dx</th>\n",
       "      <th>dk/dy</th>\n",
       "      <th>dk/dx_i</th>\n",
       "      <th>dp_dx</th>\n",
       "      <th>dp_dy</th>\n",
       "      <th>dp_dx_i</th>\n",
       "      <th>dT/dx</th>\n",
       "      <th>...</th>\n",
       "      <th>S_22</th>\n",
       "      <th>S_ij_abs</th>\n",
       "      <th>u_du/dx+v_dv/dx</th>\n",
       "      <th>MKE_diff</th>\n",
       "      <th>MKE_pre</th>\n",
       "      <th>MKE_diss</th>\n",
       "      <th>MTV_diff</th>\n",
       "      <th>MTV_diss</th>\n",
       "      <th>Pr</th>\n",
       "      <th>Pr_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>-0.003849</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>0.236314</td>\n",
       "      <td>0.236329</td>\n",
       "      <td>0.029571</td>\n",
       "      <td>-0.012274</td>\n",
       "      <td>0.032017</td>\n",
       "      <td>-0.009474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109403</td>\n",
       "      <td>4.32104</td>\n",
       "      <td>0.012697</td>\n",
       "      <td>0.236450</td>\n",
       "      <td>-0.003526</td>\n",
       "      <td>-0.011347</td>\n",
       "      <td>0.004110</td>\n",
       "      <td>-0.001970</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.993037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.003724</td>\n",
       "      <td>-0.003817</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>0.250113</td>\n",
       "      <td>0.250128</td>\n",
       "      <td>0.029160</td>\n",
       "      <td>-0.013903</td>\n",
       "      <td>0.032305</td>\n",
       "      <td>-0.012064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.109189</td>\n",
       "      <td>4.35206</td>\n",
       "      <td>0.014512</td>\n",
       "      <td>0.233185</td>\n",
       "      <td>-0.004012</td>\n",
       "      <td>-0.011511</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>-0.001960</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.025760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.004418</td>\n",
       "      <td>-0.003775</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.260139</td>\n",
       "      <td>0.260154</td>\n",
       "      <td>0.028738</td>\n",
       "      <td>-0.015512</td>\n",
       "      <td>0.032657</td>\n",
       "      <td>-0.014299</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108288</td>\n",
       "      <td>4.36082</td>\n",
       "      <td>0.016207</td>\n",
       "      <td>0.227138</td>\n",
       "      <td>-0.004466</td>\n",
       "      <td>-0.011557</td>\n",
       "      <td>0.005047</td>\n",
       "      <td>-0.001946</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.052520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.005151</td>\n",
       "      <td>-0.003729</td>\n",
       "      <td>0.002872</td>\n",
       "      <td>0.266128</td>\n",
       "      <td>0.266143</td>\n",
       "      <td>0.028301</td>\n",
       "      <td>-0.017079</td>\n",
       "      <td>0.033055</td>\n",
       "      <td>-0.016189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106848</td>\n",
       "      <td>4.34771</td>\n",
       "      <td>0.017777</td>\n",
       "      <td>0.218953</td>\n",
       "      <td>-0.004897</td>\n",
       "      <td>-0.011488</td>\n",
       "      <td>0.005455</td>\n",
       "      <td>-0.001930</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.074180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000064</td>\n",
       "      <td>0.005912</td>\n",
       "      <td>-0.003683</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.268020</td>\n",
       "      <td>0.268035</td>\n",
       "      <td>0.027848</td>\n",
       "      <td>-0.018589</td>\n",
       "      <td>0.033482</td>\n",
       "      <td>-0.017750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.104957</td>\n",
       "      <td>4.31367</td>\n",
       "      <td>0.019217</td>\n",
       "      <td>0.209205</td>\n",
       "      <td>-0.005309</td>\n",
       "      <td>-0.011309</td>\n",
       "      <td>0.005827</td>\n",
       "      <td>-0.001909</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.091570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nu_t_lsq       tke  tke_diss     dk/dx     dk/dy   dk/dx_i     dp_dx  \\\n",
       "0  0.000022  0.003077 -0.003849  0.002599  0.236314  0.236329  0.029571   \n",
       "1  0.000030  0.003724 -0.003817  0.002737  0.250113  0.250128  0.029160   \n",
       "2  0.000040  0.004418 -0.003775  0.002823  0.260139  0.260154  0.028738   \n",
       "3  0.000051  0.005151 -0.003729  0.002872  0.266128  0.266143  0.028301   \n",
       "4  0.000064  0.005912 -0.003683  0.002893  0.268020  0.268035  0.027848   \n",
       "\n",
       "      dp_dy   dp_dx_i     dT/dx  ...      S_22  S_ij_abs  u_du/dx+v_dv/dx  \\\n",
       "0 -0.012274  0.032017 -0.009474  ... -0.109403   4.32104         0.012697   \n",
       "1 -0.013903  0.032305 -0.012064  ... -0.109189   4.35206         0.014512   \n",
       "2 -0.015512  0.032657 -0.014299  ... -0.108288   4.36082         0.016207   \n",
       "3 -0.017079  0.033055 -0.016189  ... -0.106848   4.34771         0.017777   \n",
       "4 -0.018589  0.033482 -0.017750  ... -0.104957   4.31367         0.019217   \n",
       "\n",
       "   MKE_diff   MKE_pre  MKE_diss  MTV_diff  MTV_diss   Pr      Pr_t  \n",
       "0  0.236450 -0.003526 -0.011347  0.004110 -0.001970  0.2  0.993037  \n",
       "1  0.233185 -0.004012 -0.011511  0.004598 -0.001960  0.2  1.025760  \n",
       "2  0.227138 -0.004466 -0.011557  0.005047 -0.001946  0.2  1.052520  \n",
       "3  0.218953 -0.004897 -0.011488  0.005455 -0.001930  0.2  1.074180  \n",
       "4  0.209205 -0.005309 -0.011309  0.005827 -0.001909  0.2  1.091570  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nu_t_lsq           0.002727\n",
      "tke                0.007270\n",
      "tke_diss          -0.001688\n",
      "dk/dx             -0.000013\n",
      "dk/dy             -0.000632\n",
      "dk/dx_i            0.046858\n",
      "dp_dx             -0.000021\n",
      "dp_dy             -0.000017\n",
      "dp_dx_i            0.013928\n",
      "dT/dx              0.000325\n",
      "dT/dy             -0.781370\n",
      "dT/dx_i            0.781511\n",
      "S_11              -0.000277\n",
      "S_12              -0.016264\n",
      "S_22               0.000277\n",
      "S_ij_abs           1.404156\n",
      "u_du/dx+v_dv/dx   -0.000380\n",
      "MKE_diff          -0.001191\n",
      "MKE_pre            0.000149\n",
      "MKE_diss          -0.003325\n",
      "MTV_diff           0.001562\n",
      "MTV_diss          -0.000604\n",
      "Pr                 0.966707\n",
      "Pr_t               0.982858\n",
      "dtype: float64\n",
      "Nu_t_lsq           0.001812\n",
      "tke                0.003245\n",
      "tke_diss           0.001240\n",
      "dk/dx              0.001948\n",
      "dk/dy              0.086369\n",
      "dk/dx_i            0.072581\n",
      "dp_dx              0.011790\n",
      "dp_dy              0.009446\n",
      "dp_dx_i            0.005852\n",
      "dT/dx              0.024889\n",
      "dT/dy              0.929205\n",
      "dT/dx_i            0.929420\n",
      "S_11               0.062219\n",
      "S_12               1.652594\n",
      "S_22               0.062227\n",
      "S_ij_abs           1.870493\n",
      "u_du/dx+v_dv/dx    0.023535\n",
      "MKE_diff           0.018676\n",
      "MKE_pre            0.008926\n",
      "MKE_diss           0.007077\n",
      "MTV_diff           0.003494\n",
      "MTV_diss           0.000987\n",
      "Pr                 0.758656\n",
      "Pr_t               0.140120\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(Data.mean())\n",
    "print(Data.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nu_t_lsq</th>\n",
       "      <th>tke</th>\n",
       "      <th>tke_diss</th>\n",
       "      <th>dk/dx</th>\n",
       "      <th>dk/dy</th>\n",
       "      <th>dk/dx_i</th>\n",
       "      <th>dp_dx</th>\n",
       "      <th>dp_dy</th>\n",
       "      <th>dp_dx_i</th>\n",
       "      <th>dT/dx</th>\n",
       "      <th>...</th>\n",
       "      <th>S_22</th>\n",
       "      <th>S_ij_abs</th>\n",
       "      <th>u_du/dx+v_dv/dx</th>\n",
       "      <th>MKE_diff</th>\n",
       "      <th>MKE_pre</th>\n",
       "      <th>MKE_diss</th>\n",
       "      <th>MTV_diff</th>\n",
       "      <th>MTV_diss</th>\n",
       "      <th>Pr</th>\n",
       "      <th>Pr_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.492653</td>\n",
       "      <td>-1.291952</td>\n",
       "      <td>-1.741811</td>\n",
       "      <td>1.340864</td>\n",
       "      <td>2.743425</td>\n",
       "      <td>2.610466</td>\n",
       "      <td>2.509808</td>\n",
       "      <td>-1.297647</td>\n",
       "      <td>3.091245</td>\n",
       "      <td>-0.393696</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.762572</td>\n",
       "      <td>1.559419</td>\n",
       "      <td>0.555610</td>\n",
       "      <td>12.724339</td>\n",
       "      <td>-0.411789</td>\n",
       "      <td>-1.133706</td>\n",
       "      <td>0.729269</td>\n",
       "      <td>-1.383957</td>\n",
       "      <td>-1.010612</td>\n",
       "      <td>0.072647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.488293</td>\n",
       "      <td>-1.092594</td>\n",
       "      <td>-1.716050</td>\n",
       "      <td>1.411986</td>\n",
       "      <td>2.903194</td>\n",
       "      <td>2.800585</td>\n",
       "      <td>2.474940</td>\n",
       "      <td>-1.470085</td>\n",
       "      <td>3.140394</td>\n",
       "      <td>-0.497764</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.759133</td>\n",
       "      <td>1.576003</td>\n",
       "      <td>0.632731</td>\n",
       "      <td>12.549516</td>\n",
       "      <td>-0.466175</td>\n",
       "      <td>-1.156810</td>\n",
       "      <td>0.869148</td>\n",
       "      <td>-1.373851</td>\n",
       "      <td>-1.010612</td>\n",
       "      <td>0.306183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.483051</td>\n",
       "      <td>-0.878575</td>\n",
       "      <td>-1.682533</td>\n",
       "      <td>1.456370</td>\n",
       "      <td>3.019278</td>\n",
       "      <td>2.938719</td>\n",
       "      <td>2.439140</td>\n",
       "      <td>-1.640416</td>\n",
       "      <td>3.200599</td>\n",
       "      <td>-0.587550</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.744654</td>\n",
       "      <td>1.580687</td>\n",
       "      <td>0.704769</td>\n",
       "      <td>12.225733</td>\n",
       "      <td>-0.517098</td>\n",
       "      <td>-1.163381</td>\n",
       "      <td>0.997426</td>\n",
       "      <td>-1.360278</td>\n",
       "      <td>-1.010612</td>\n",
       "      <td>0.497162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.476870</td>\n",
       "      <td>-0.652762</td>\n",
       "      <td>-1.645226</td>\n",
       "      <td>1.481456</td>\n",
       "      <td>3.088620</td>\n",
       "      <td>3.021234</td>\n",
       "      <td>2.402109</td>\n",
       "      <td>-1.806321</td>\n",
       "      <td>3.268648</td>\n",
       "      <td>-0.663482</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.721513</td>\n",
       "      <td>1.573678</td>\n",
       "      <td>0.771496</td>\n",
       "      <td>11.787472</td>\n",
       "      <td>-0.565376</td>\n",
       "      <td>-1.153574</td>\n",
       "      <td>1.114455</td>\n",
       "      <td>-1.343259</td>\n",
       "      <td>-1.010612</td>\n",
       "      <td>0.651745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.469641</td>\n",
       "      <td>-0.418388</td>\n",
       "      <td>-1.608072</td>\n",
       "      <td>1.491883</td>\n",
       "      <td>3.110526</td>\n",
       "      <td>3.047301</td>\n",
       "      <td>2.363714</td>\n",
       "      <td>-1.966171</td>\n",
       "      <td>3.341688</td>\n",
       "      <td>-0.726184</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.691124</td>\n",
       "      <td>1.555479</td>\n",
       "      <td>0.832678</td>\n",
       "      <td>11.265520</td>\n",
       "      <td>-0.611513</td>\n",
       "      <td>-1.128251</td>\n",
       "      <td>1.220864</td>\n",
       "      <td>-1.322875</td>\n",
       "      <td>-1.010612</td>\n",
       "      <td>0.775853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nu_t_lsq       tke  tke_diss     dk/dx     dk/dy   dk/dx_i     dp_dx  \\\n",
       "0 -1.492653 -1.291952 -1.741811  1.340864  2.743425  2.610466  2.509808   \n",
       "1 -1.488293 -1.092594 -1.716050  1.411986  2.903194  2.800585  2.474940   \n",
       "2 -1.483051 -0.878575 -1.682533  1.456370  3.019278  2.938719  2.439140   \n",
       "3 -1.476870 -0.652762 -1.645226  1.481456  3.088620  3.021234  2.402109   \n",
       "4 -1.469641 -0.418388 -1.608072  1.491883  3.110526  3.047301  2.363714   \n",
       "\n",
       "      dp_dy   dp_dx_i     dT/dx  ...      S_22  S_ij_abs  u_du/dx+v_dv/dx  \\\n",
       "0 -1.297647  3.091245 -0.393696  ... -1.762572  1.559419         0.555610   \n",
       "1 -1.470085  3.140394 -0.497764  ... -1.759133  1.576003         0.632731   \n",
       "2 -1.640416  3.200599 -0.587550  ... -1.744654  1.580687         0.704769   \n",
       "3 -1.806321  3.268648 -0.663482  ... -1.721513  1.573678         0.771496   \n",
       "4 -1.966171  3.341688 -0.726184  ... -1.691124  1.555479         0.832678   \n",
       "\n",
       "    MKE_diff   MKE_pre  MKE_diss  MTV_diff  MTV_diss        Pr      Pr_t  \n",
       "0  12.724339 -0.411789 -1.133706  0.729269 -1.383957 -1.010612  0.072647  \n",
       "1  12.549516 -0.466175 -1.156810  0.869148 -1.373851 -1.010612  0.306183  \n",
       "2  12.225733 -0.517098 -1.163381  0.997426 -1.360278 -1.010612  0.497162  \n",
       "3  11.787472 -0.565376 -1.153574  1.114455 -1.343259 -1.010612  0.651745  \n",
       "4  11.265520 -0.611513 -1.128251  1.220864 -1.322875 -1.010612  0.775853  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data111 = (Data - Data.mean())/Data.std()\n",
    "Data111.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.044300894464124"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data111['Pr_t'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.990952585375755"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data111['Pr_t'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-37-f18b7bd744fe>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-37-f18b7bd744fe>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    0.095883\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     1,     2, ..., 90651, 90652, 90653], dtype=int64)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Data = pd.read_csv(r'D:\\Desktop\\SynologyDrive\\Outline\\Youngjae Kim\\figures\\Figure19-22\\channel_evaluation_Pr0.7.csv')\n",
    "Data.index.values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0083165541178547"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = abs(Data['Pr_t'] - Data['Pr_t_model1'])\n",
    "bb = aa.sum()/len(aa)\n",
    "bb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1 = Data[Data['X'] == 5.46491]\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(Data1['Y'],Data1['Pr_t'],s=1)\n",
    "plt.scatter(Data1['Y'],Data1['Pr_t_model1'],s=1)\n",
    "plt.legend(['DNS','ANN full params'])\n",
    "plt.xlabel('Y')\n",
    "plt.ylabel('$Pr_t$')\n",
    "plt.savefig(r'D:\\Desktop\\SynologyDrive\\Outline\\Youngjae Kim\\figures\\Figure19-22\\Pr07_X546491.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1 = Data[Data['X'] == 10.0239]\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.scatter(Data1['Y'],Data1['Pr_t'],s=1)\n",
    "plt.scatter(Data1['Y'],Data1['Pr_t_model1'],s=1)\n",
    "plt.legend(['DNS','ANN full params'])\n",
    "plt.xlabel('Y')\n",
    "plt.ylabel('$Pr_t$')\n",
    "plt.savefig(r'D:\\Desktop\\SynologyDrive\\Outline\\Youngjae Kim\\figures\\Figure19-22\\Pr07_X100239.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([80213, 13677, 11539, ..., 25308, 24261, 72206], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(Data, test_size=0.33, random_state=42)\n",
    "test.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1     3     6 ... 90648 90652 90653]\n",
      "[    0     5    19 ... 90645 90649 90650]\n",
      "[    2     4     7 ... 90634 90643 90651]\n"
     ]
    }
   ],
   "source": [
    "k_fold = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "for train,test in k_fold.split(Data):\n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83017 17153 46563 ... 20900 26203 17009]\n",
      "[43044 52085 29298 ...  5316 58729 53510]\n"
     ]
    }
   ],
   "source": [
    "Data_index = Data.index.values\n",
    "print(Data_index)\n",
    "random.shuffle(Data_index)\n",
    "print(Data_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([43044, 52085, 29298, ...,  5316, 58729, 53510], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Pr_t</th>\n",
       "      <th>Pr_t_model1</th>\n",
       "      <th>Pr_t_model2</th>\n",
       "      <th>Pr_t_model3</th>\n",
       "      <th>Pr_t_model4</th>\n",
       "      <th>Pr_t_model5</th>\n",
       "      <th>Pr_t_model6</th>\n",
       "      <th>Pr_t_model7</th>\n",
       "      <th>Pr_t_model8</th>\n",
       "      <th>Pr_t_model9</th>\n",
       "      <th>Pr_t_model10</th>\n",
       "      <th>Pr_t_model11</th>\n",
       "      <th>Pr_t_model12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.076720</td>\n",
       "      <td>1.104610</td>\n",
       "      <td>1.197522</td>\n",
       "      <td>1.273699</td>\n",
       "      <td>1.043940</td>\n",
       "      <td>1.058620</td>\n",
       "      <td>1.296706</td>\n",
       "      <td>1.314496</td>\n",
       "      <td>1.420162</td>\n",
       "      <td>1.924836</td>\n",
       "      <td>0.928078</td>\n",
       "      <td>1.004540</td>\n",
       "      <td>0.961741</td>\n",
       "      <td>1.024329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.074086</td>\n",
       "      <td>1.127430</td>\n",
       "      <td>1.157657</td>\n",
       "      <td>1.225366</td>\n",
       "      <td>1.056956</td>\n",
       "      <td>1.067863</td>\n",
       "      <td>1.261727</td>\n",
       "      <td>1.237134</td>\n",
       "      <td>1.338431</td>\n",
       "      <td>1.764912</td>\n",
       "      <td>0.953731</td>\n",
       "      <td>1.039153</td>\n",
       "      <td>0.983685</td>\n",
       "      <td>1.024698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.071392</td>\n",
       "      <td>1.140610</td>\n",
       "      <td>1.124565</td>\n",
       "      <td>1.177078</td>\n",
       "      <td>1.067786</td>\n",
       "      <td>1.077017</td>\n",
       "      <td>1.226617</td>\n",
       "      <td>1.169545</td>\n",
       "      <td>1.245782</td>\n",
       "      <td>1.567871</td>\n",
       "      <td>0.983676</td>\n",
       "      <td>1.058335</td>\n",
       "      <td>1.002349</td>\n",
       "      <td>1.029069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.068635</td>\n",
       "      <td>1.146200</td>\n",
       "      <td>1.098349</td>\n",
       "      <td>1.130779</td>\n",
       "      <td>1.077624</td>\n",
       "      <td>1.087376</td>\n",
       "      <td>1.194690</td>\n",
       "      <td>1.110717</td>\n",
       "      <td>1.209067</td>\n",
       "      <td>1.380159</td>\n",
       "      <td>1.006633</td>\n",
       "      <td>1.065341</td>\n",
       "      <td>1.020842</td>\n",
       "      <td>1.035166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.065814</td>\n",
       "      <td>1.146200</td>\n",
       "      <td>1.079288</td>\n",
       "      <td>1.084994</td>\n",
       "      <td>1.087542</td>\n",
       "      <td>1.098041</td>\n",
       "      <td>1.169597</td>\n",
       "      <td>1.072908</td>\n",
       "      <td>1.195700</td>\n",
       "      <td>1.240191</td>\n",
       "      <td>1.023299</td>\n",
       "      <td>1.062063</td>\n",
       "      <td>1.035992</td>\n",
       "      <td>1.043207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.062928</td>\n",
       "      <td>1.142420</td>\n",
       "      <td>1.069063</td>\n",
       "      <td>1.048980</td>\n",
       "      <td>1.098249</td>\n",
       "      <td>1.106905</td>\n",
       "      <td>1.150099</td>\n",
       "      <td>1.053486</td>\n",
       "      <td>1.192004</td>\n",
       "      <td>1.153273</td>\n",
       "      <td>1.037313</td>\n",
       "      <td>1.052833</td>\n",
       "      <td>1.047260</td>\n",
       "      <td>1.054282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.059976</td>\n",
       "      <td>1.136360</td>\n",
       "      <td>1.066496</td>\n",
       "      <td>1.028816</td>\n",
       "      <td>1.109692</td>\n",
       "      <td>1.112850</td>\n",
       "      <td>1.134942</td>\n",
       "      <td>1.049066</td>\n",
       "      <td>1.190492</td>\n",
       "      <td>1.116320</td>\n",
       "      <td>1.049419</td>\n",
       "      <td>1.043184</td>\n",
       "      <td>1.056611</td>\n",
       "      <td>1.068585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.056957</td>\n",
       "      <td>1.129180</td>\n",
       "      <td>1.071164</td>\n",
       "      <td>1.024920</td>\n",
       "      <td>1.122064</td>\n",
       "      <td>1.115815</td>\n",
       "      <td>1.123623</td>\n",
       "      <td>1.054408</td>\n",
       "      <td>1.186744</td>\n",
       "      <td>1.105765</td>\n",
       "      <td>1.066452</td>\n",
       "      <td>1.043665</td>\n",
       "      <td>1.064321</td>\n",
       "      <td>1.080526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.053868</td>\n",
       "      <td>1.121710</td>\n",
       "      <td>1.082207</td>\n",
       "      <td>1.031178</td>\n",
       "      <td>1.134851</td>\n",
       "      <td>1.116314</td>\n",
       "      <td>1.114686</td>\n",
       "      <td>1.065608</td>\n",
       "      <td>1.181324</td>\n",
       "      <td>1.105447</td>\n",
       "      <td>1.087794</td>\n",
       "      <td>1.056036</td>\n",
       "      <td>1.073087</td>\n",
       "      <td>1.084715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.050709</td>\n",
       "      <td>1.114490</td>\n",
       "      <td>1.097838</td>\n",
       "      <td>1.046226</td>\n",
       "      <td>1.144151</td>\n",
       "      <td>1.115274</td>\n",
       "      <td>1.106878</td>\n",
       "      <td>1.077571</td>\n",
       "      <td>1.176289</td>\n",
       "      <td>1.112949</td>\n",
       "      <td>1.101965</td>\n",
       "      <td>1.073031</td>\n",
       "      <td>1.082459</td>\n",
       "      <td>1.082267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.047478</td>\n",
       "      <td>1.107860</td>\n",
       "      <td>1.112872</td>\n",
       "      <td>1.066340</td>\n",
       "      <td>1.149724</td>\n",
       "      <td>1.113956</td>\n",
       "      <td>1.100383</td>\n",
       "      <td>1.087178</td>\n",
       "      <td>1.168853</td>\n",
       "      <td>1.123989</td>\n",
       "      <td>1.108920</td>\n",
       "      <td>1.090574</td>\n",
       "      <td>1.089062</td>\n",
       "      <td>1.073871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.044174</td>\n",
       "      <td>1.102000</td>\n",
       "      <td>1.117975</td>\n",
       "      <td>1.084790</td>\n",
       "      <td>1.152346</td>\n",
       "      <td>1.111808</td>\n",
       "      <td>1.094743</td>\n",
       "      <td>1.095011</td>\n",
       "      <td>1.153816</td>\n",
       "      <td>1.133989</td>\n",
       "      <td>1.112687</td>\n",
       "      <td>1.101784</td>\n",
       "      <td>1.095123</td>\n",
       "      <td>1.071665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.040796</td>\n",
       "      <td>1.096960</td>\n",
       "      <td>1.117090</td>\n",
       "      <td>1.098639</td>\n",
       "      <td>1.153519</td>\n",
       "      <td>1.109391</td>\n",
       "      <td>1.089635</td>\n",
       "      <td>1.102333</td>\n",
       "      <td>1.133103</td>\n",
       "      <td>1.137989</td>\n",
       "      <td>1.115208</td>\n",
       "      <td>1.105653</td>\n",
       "      <td>1.101251</td>\n",
       "      <td>1.077192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.037342</td>\n",
       "      <td>1.092750</td>\n",
       "      <td>1.112997</td>\n",
       "      <td>1.108215</td>\n",
       "      <td>1.152911</td>\n",
       "      <td>1.105037</td>\n",
       "      <td>1.085156</td>\n",
       "      <td>1.108715</td>\n",
       "      <td>1.117514</td>\n",
       "      <td>1.134602</td>\n",
       "      <td>1.114399</td>\n",
       "      <td>1.104700</td>\n",
       "      <td>1.106258</td>\n",
       "      <td>1.083207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.033810</td>\n",
       "      <td>1.089340</td>\n",
       "      <td>1.107183</td>\n",
       "      <td>1.113367</td>\n",
       "      <td>1.148445</td>\n",
       "      <td>1.099427</td>\n",
       "      <td>1.080879</td>\n",
       "      <td>1.113692</td>\n",
       "      <td>1.109214</td>\n",
       "      <td>1.128835</td>\n",
       "      <td>1.117002</td>\n",
       "      <td>1.102645</td>\n",
       "      <td>1.109049</td>\n",
       "      <td>1.088519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.030200</td>\n",
       "      <td>1.086670</td>\n",
       "      <td>1.100900</td>\n",
       "      <td>1.116258</td>\n",
       "      <td>1.141922</td>\n",
       "      <td>1.096667</td>\n",
       "      <td>1.079128</td>\n",
       "      <td>1.118614</td>\n",
       "      <td>1.105034</td>\n",
       "      <td>1.123611</td>\n",
       "      <td>1.132171</td>\n",
       "      <td>1.104635</td>\n",
       "      <td>1.106869</td>\n",
       "      <td>1.093326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.026509</td>\n",
       "      <td>1.084670</td>\n",
       "      <td>1.093861</td>\n",
       "      <td>1.117744</td>\n",
       "      <td>1.134117</td>\n",
       "      <td>1.093722</td>\n",
       "      <td>1.078926</td>\n",
       "      <td>1.122489</td>\n",
       "      <td>1.102492</td>\n",
       "      <td>1.118241</td>\n",
       "      <td>1.144488</td>\n",
       "      <td>1.107330</td>\n",
       "      <td>1.099453</td>\n",
       "      <td>1.096867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.022737</td>\n",
       "      <td>1.083260</td>\n",
       "      <td>1.086862</td>\n",
       "      <td>1.117836</td>\n",
       "      <td>1.124204</td>\n",
       "      <td>1.090374</td>\n",
       "      <td>1.080145</td>\n",
       "      <td>1.124048</td>\n",
       "      <td>1.100590</td>\n",
       "      <td>1.113995</td>\n",
       "      <td>1.157083</td>\n",
       "      <td>1.109000</td>\n",
       "      <td>1.088823</td>\n",
       "      <td>1.100653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.018881</td>\n",
       "      <td>1.082340</td>\n",
       "      <td>1.079562</td>\n",
       "      <td>1.115554</td>\n",
       "      <td>1.113458</td>\n",
       "      <td>1.082634</td>\n",
       "      <td>1.078301</td>\n",
       "      <td>1.121045</td>\n",
       "      <td>1.096914</td>\n",
       "      <td>1.107198</td>\n",
       "      <td>1.189210</td>\n",
       "      <td>1.103651</td>\n",
       "      <td>1.077279</td>\n",
       "      <td>1.100612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.014941</td>\n",
       "      <td>1.081850</td>\n",
       "      <td>1.074496</td>\n",
       "      <td>1.114766</td>\n",
       "      <td>1.106120</td>\n",
       "      <td>1.079597</td>\n",
       "      <td>1.080070</td>\n",
       "      <td>1.119334</td>\n",
       "      <td>1.098276</td>\n",
       "      <td>1.109983</td>\n",
       "      <td>1.201406</td>\n",
       "      <td>1.104971</td>\n",
       "      <td>1.070821</td>\n",
       "      <td>1.104341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.010915</td>\n",
       "      <td>1.081700</td>\n",
       "      <td>1.070120</td>\n",
       "      <td>1.113621</td>\n",
       "      <td>1.100821</td>\n",
       "      <td>1.078745</td>\n",
       "      <td>1.082523</td>\n",
       "      <td>1.116801</td>\n",
       "      <td>1.099512</td>\n",
       "      <td>1.109599</td>\n",
       "      <td>1.206899</td>\n",
       "      <td>1.105505</td>\n",
       "      <td>1.067182</td>\n",
       "      <td>1.107386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.006800</td>\n",
       "      <td>1.081820</td>\n",
       "      <td>1.066807</td>\n",
       "      <td>1.112815</td>\n",
       "      <td>1.097472</td>\n",
       "      <td>1.080699</td>\n",
       "      <td>1.085323</td>\n",
       "      <td>1.113914</td>\n",
       "      <td>1.101633</td>\n",
       "      <td>1.108672</td>\n",
       "      <td>1.194500</td>\n",
       "      <td>1.107027</td>\n",
       "      <td>1.067262</td>\n",
       "      <td>1.109762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>-0.002597</td>\n",
       "      <td>1.082160</td>\n",
       "      <td>1.064483</td>\n",
       "      <td>1.112596</td>\n",
       "      <td>1.095874</td>\n",
       "      <td>1.085214</td>\n",
       "      <td>1.087922</td>\n",
       "      <td>1.111411</td>\n",
       "      <td>1.104100</td>\n",
       "      <td>1.107802</td>\n",
       "      <td>1.186318</td>\n",
       "      <td>1.109225</td>\n",
       "      <td>1.069292</td>\n",
       "      <td>1.110965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.001697</td>\n",
       "      <td>1.082680</td>\n",
       "      <td>1.063434</td>\n",
       "      <td>1.112809</td>\n",
       "      <td>1.095668</td>\n",
       "      <td>1.091245</td>\n",
       "      <td>1.090065</td>\n",
       "      <td>1.109394</td>\n",
       "      <td>1.106475</td>\n",
       "      <td>1.107641</td>\n",
       "      <td>1.184760</td>\n",
       "      <td>1.112704</td>\n",
       "      <td>1.071122</td>\n",
       "      <td>1.110778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.006084</td>\n",
       "      <td>1.083380</td>\n",
       "      <td>1.063847</td>\n",
       "      <td>1.113321</td>\n",
       "      <td>1.095991</td>\n",
       "      <td>1.096023</td>\n",
       "      <td>1.091644</td>\n",
       "      <td>1.107845</td>\n",
       "      <td>1.108527</td>\n",
       "      <td>1.107998</td>\n",
       "      <td>1.183251</td>\n",
       "      <td>1.117493</td>\n",
       "      <td>1.071990</td>\n",
       "      <td>1.110034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.010564</td>\n",
       "      <td>1.084250</td>\n",
       "      <td>1.065452</td>\n",
       "      <td>1.113954</td>\n",
       "      <td>1.095474</td>\n",
       "      <td>1.099311</td>\n",
       "      <td>1.092459</td>\n",
       "      <td>1.106770</td>\n",
       "      <td>1.110508</td>\n",
       "      <td>1.108606</td>\n",
       "      <td>1.180502</td>\n",
       "      <td>1.123422</td>\n",
       "      <td>1.072222</td>\n",
       "      <td>1.109129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.015140</td>\n",
       "      <td>1.085290</td>\n",
       "      <td>1.068026</td>\n",
       "      <td>1.114487</td>\n",
       "      <td>1.094162</td>\n",
       "      <td>1.101576</td>\n",
       "      <td>1.092578</td>\n",
       "      <td>1.106151</td>\n",
       "      <td>1.112308</td>\n",
       "      <td>1.109447</td>\n",
       "      <td>1.179253</td>\n",
       "      <td>1.126390</td>\n",
       "      <td>1.071951</td>\n",
       "      <td>1.105104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.019813</td>\n",
       "      <td>1.086490</td>\n",
       "      <td>1.071411</td>\n",
       "      <td>1.114797</td>\n",
       "      <td>1.092578</td>\n",
       "      <td>1.103163</td>\n",
       "      <td>1.091986</td>\n",
       "      <td>1.105987</td>\n",
       "      <td>1.113211</td>\n",
       "      <td>1.110695</td>\n",
       "      <td>1.177626</td>\n",
       "      <td>1.127676</td>\n",
       "      <td>1.071346</td>\n",
       "      <td>1.100997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.024584</td>\n",
       "      <td>1.087820</td>\n",
       "      <td>1.075479</td>\n",
       "      <td>1.114868</td>\n",
       "      <td>1.090891</td>\n",
       "      <td>1.104495</td>\n",
       "      <td>1.090770</td>\n",
       "      <td>1.106292</td>\n",
       "      <td>1.113058</td>\n",
       "      <td>1.111968</td>\n",
       "      <td>1.175335</td>\n",
       "      <td>1.128042</td>\n",
       "      <td>1.070345</td>\n",
       "      <td>1.097968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-5.000000e-09</td>\n",
       "      <td>0.029455</td>\n",
       "      <td>1.089260</td>\n",
       "      <td>1.079978</td>\n",
       "      <td>1.114697</td>\n",
       "      <td>1.089396</td>\n",
       "      <td>1.105616</td>\n",
       "      <td>1.089075</td>\n",
       "      <td>1.107005</td>\n",
       "      <td>1.112122</td>\n",
       "      <td>1.113094</td>\n",
       "      <td>1.172206</td>\n",
       "      <td>1.127442</td>\n",
       "      <td>1.069567</td>\n",
       "      <td>1.095852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90624</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.880190</td>\n",
       "      <td>0.998599</td>\n",
       "      <td>1.006844</td>\n",
       "      <td>1.009018</td>\n",
       "      <td>0.993570</td>\n",
       "      <td>0.999040</td>\n",
       "      <td>1.003353</td>\n",
       "      <td>1.005760</td>\n",
       "      <td>0.993351</td>\n",
       "      <td>1.004610</td>\n",
       "      <td>1.024097</td>\n",
       "      <td>0.998305</td>\n",
       "      <td>0.998692</td>\n",
       "      <td>1.004226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90625</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.884860</td>\n",
       "      <td>0.994975</td>\n",
       "      <td>1.003983</td>\n",
       "      <td>1.005506</td>\n",
       "      <td>0.990713</td>\n",
       "      <td>0.995467</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>1.001256</td>\n",
       "      <td>0.993155</td>\n",
       "      <td>1.000312</td>\n",
       "      <td>1.024766</td>\n",
       "      <td>0.994329</td>\n",
       "      <td>0.995446</td>\n",
       "      <td>1.000440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90626</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.889440</td>\n",
       "      <td>0.991615</td>\n",
       "      <td>1.001112</td>\n",
       "      <td>1.002190</td>\n",
       "      <td>0.988381</td>\n",
       "      <td>0.992401</td>\n",
       "      <td>0.996412</td>\n",
       "      <td>0.996896</td>\n",
       "      <td>0.993217</td>\n",
       "      <td>0.995925</td>\n",
       "      <td>1.024447</td>\n",
       "      <td>0.990263</td>\n",
       "      <td>0.992302</td>\n",
       "      <td>0.996655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90627</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.893920</td>\n",
       "      <td>0.988512</td>\n",
       "      <td>0.998191</td>\n",
       "      <td>0.999023</td>\n",
       "      <td>0.986510</td>\n",
       "      <td>0.989838</td>\n",
       "      <td>0.992950</td>\n",
       "      <td>0.993005</td>\n",
       "      <td>0.993533</td>\n",
       "      <td>0.991584</td>\n",
       "      <td>1.023690</td>\n",
       "      <td>0.986186</td>\n",
       "      <td>0.989427</td>\n",
       "      <td>0.992791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90628</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.898300</td>\n",
       "      <td>0.985649</td>\n",
       "      <td>0.995143</td>\n",
       "      <td>0.996131</td>\n",
       "      <td>0.985070</td>\n",
       "      <td>0.987818</td>\n",
       "      <td>0.989707</td>\n",
       "      <td>0.989616</td>\n",
       "      <td>0.994093</td>\n",
       "      <td>0.987397</td>\n",
       "      <td>1.022570</td>\n",
       "      <td>0.982514</td>\n",
       "      <td>0.986864</td>\n",
       "      <td>0.988969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90629</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.902600</td>\n",
       "      <td>0.983006</td>\n",
       "      <td>0.991882</td>\n",
       "      <td>0.993575</td>\n",
       "      <td>0.984075</td>\n",
       "      <td>0.985995</td>\n",
       "      <td>0.986776</td>\n",
       "      <td>0.986600</td>\n",
       "      <td>0.994822</td>\n",
       "      <td>0.983393</td>\n",
       "      <td>1.023358</td>\n",
       "      <td>0.979875</td>\n",
       "      <td>0.984601</td>\n",
       "      <td>0.985490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90630</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.906800</td>\n",
       "      <td>0.980574</td>\n",
       "      <td>0.988348</td>\n",
       "      <td>0.991311</td>\n",
       "      <td>0.984168</td>\n",
       "      <td>0.984427</td>\n",
       "      <td>0.984132</td>\n",
       "      <td>0.984096</td>\n",
       "      <td>0.995612</td>\n",
       "      <td>0.979496</td>\n",
       "      <td>1.031014</td>\n",
       "      <td>0.978722</td>\n",
       "      <td>0.981031</td>\n",
       "      <td>0.983923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90631</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.910910</td>\n",
       "      <td>0.978357</td>\n",
       "      <td>0.985244</td>\n",
       "      <td>0.989690</td>\n",
       "      <td>0.984188</td>\n",
       "      <td>0.983088</td>\n",
       "      <td>0.982675</td>\n",
       "      <td>0.983334</td>\n",
       "      <td>0.996707</td>\n",
       "      <td>0.976221</td>\n",
       "      <td>1.038640</td>\n",
       "      <td>0.979518</td>\n",
       "      <td>0.979162</td>\n",
       "      <td>0.981038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90632</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.914940</td>\n",
       "      <td>0.976371</td>\n",
       "      <td>0.981976</td>\n",
       "      <td>0.988172</td>\n",
       "      <td>0.984713</td>\n",
       "      <td>0.981663</td>\n",
       "      <td>0.981516</td>\n",
       "      <td>0.982876</td>\n",
       "      <td>0.997672</td>\n",
       "      <td>0.973469</td>\n",
       "      <td>1.040452</td>\n",
       "      <td>0.980562</td>\n",
       "      <td>0.977625</td>\n",
       "      <td>0.978289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90633</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.918880</td>\n",
       "      <td>0.974638</td>\n",
       "      <td>0.978526</td>\n",
       "      <td>0.986803</td>\n",
       "      <td>0.985824</td>\n",
       "      <td>0.979983</td>\n",
       "      <td>0.980507</td>\n",
       "      <td>0.982783</td>\n",
       "      <td>0.998342</td>\n",
       "      <td>0.971212</td>\n",
       "      <td>1.035239</td>\n",
       "      <td>0.981836</td>\n",
       "      <td>0.976192</td>\n",
       "      <td>0.975474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90634</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.922740</td>\n",
       "      <td>0.973178</td>\n",
       "      <td>0.975200</td>\n",
       "      <td>0.985626</td>\n",
       "      <td>0.987572</td>\n",
       "      <td>0.978170</td>\n",
       "      <td>0.979696</td>\n",
       "      <td>0.983201</td>\n",
       "      <td>0.998678</td>\n",
       "      <td>0.969982</td>\n",
       "      <td>1.028553</td>\n",
       "      <td>0.983386</td>\n",
       "      <td>0.974868</td>\n",
       "      <td>0.973245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90635</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.926510</td>\n",
       "      <td>0.972009</td>\n",
       "      <td>0.972211</td>\n",
       "      <td>0.984405</td>\n",
       "      <td>0.989978</td>\n",
       "      <td>0.976288</td>\n",
       "      <td>0.978546</td>\n",
       "      <td>0.983731</td>\n",
       "      <td>0.998613</td>\n",
       "      <td>0.970042</td>\n",
       "      <td>1.026853</td>\n",
       "      <td>0.985297</td>\n",
       "      <td>0.973926</td>\n",
       "      <td>0.971740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90636</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.930200</td>\n",
       "      <td>0.971143</td>\n",
       "      <td>0.969785</td>\n",
       "      <td>0.983722</td>\n",
       "      <td>0.992902</td>\n",
       "      <td>0.974873</td>\n",
       "      <td>0.976621</td>\n",
       "      <td>0.984014</td>\n",
       "      <td>0.998041</td>\n",
       "      <td>0.971048</td>\n",
       "      <td>1.026312</td>\n",
       "      <td>0.987202</td>\n",
       "      <td>0.973708</td>\n",
       "      <td>0.971018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90637</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.933810</td>\n",
       "      <td>0.970591</td>\n",
       "      <td>0.968059</td>\n",
       "      <td>0.983331</td>\n",
       "      <td>0.995996</td>\n",
       "      <td>0.973986</td>\n",
       "      <td>0.974413</td>\n",
       "      <td>0.983774</td>\n",
       "      <td>0.996610</td>\n",
       "      <td>0.972273</td>\n",
       "      <td>1.026379</td>\n",
       "      <td>0.988270</td>\n",
       "      <td>0.974193</td>\n",
       "      <td>0.971179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90638</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.937340</td>\n",
       "      <td>0.970359</td>\n",
       "      <td>0.967243</td>\n",
       "      <td>0.982340</td>\n",
       "      <td>0.998805</td>\n",
       "      <td>0.973844</td>\n",
       "      <td>0.973423</td>\n",
       "      <td>0.984057</td>\n",
       "      <td>0.995458</td>\n",
       "      <td>0.974163</td>\n",
       "      <td>1.026462</td>\n",
       "      <td>0.988017</td>\n",
       "      <td>0.975229</td>\n",
       "      <td>0.972253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90639</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.940800</td>\n",
       "      <td>0.970461</td>\n",
       "      <td>0.967806</td>\n",
       "      <td>0.979284</td>\n",
       "      <td>1.001854</td>\n",
       "      <td>0.974223</td>\n",
       "      <td>0.974006</td>\n",
       "      <td>0.984875</td>\n",
       "      <td>0.995219</td>\n",
       "      <td>0.976658</td>\n",
       "      <td>1.026144</td>\n",
       "      <td>0.986242</td>\n",
       "      <td>0.976529</td>\n",
       "      <td>0.974376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90640</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.944170</td>\n",
       "      <td>0.970912</td>\n",
       "      <td>0.968916</td>\n",
       "      <td>0.975516</td>\n",
       "      <td>1.005417</td>\n",
       "      <td>0.974415</td>\n",
       "      <td>0.974746</td>\n",
       "      <td>0.986256</td>\n",
       "      <td>0.995763</td>\n",
       "      <td>0.978795</td>\n",
       "      <td>1.024716</td>\n",
       "      <td>0.982781</td>\n",
       "      <td>0.977927</td>\n",
       "      <td>0.977169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90641</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.947480</td>\n",
       "      <td>0.971733</td>\n",
       "      <td>0.969990</td>\n",
       "      <td>0.972850</td>\n",
       "      <td>1.008876</td>\n",
       "      <td>0.974286</td>\n",
       "      <td>0.975195</td>\n",
       "      <td>0.987160</td>\n",
       "      <td>0.998111</td>\n",
       "      <td>0.979794</td>\n",
       "      <td>1.020699</td>\n",
       "      <td>0.978545</td>\n",
       "      <td>0.979009</td>\n",
       "      <td>0.979769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90642</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.950710</td>\n",
       "      <td>0.972948</td>\n",
       "      <td>0.971280</td>\n",
       "      <td>0.972400</td>\n",
       "      <td>1.012722</td>\n",
       "      <td>0.973707</td>\n",
       "      <td>0.975850</td>\n",
       "      <td>0.986603</td>\n",
       "      <td>1.002242</td>\n",
       "      <td>0.979579</td>\n",
       "      <td>1.018303</td>\n",
       "      <td>0.973616</td>\n",
       "      <td>0.981346</td>\n",
       "      <td>0.981719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90643</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.953870</td>\n",
       "      <td>0.974586</td>\n",
       "      <td>0.972566</td>\n",
       "      <td>0.975361</td>\n",
       "      <td>1.014352</td>\n",
       "      <td>0.975660</td>\n",
       "      <td>0.977232</td>\n",
       "      <td>0.984100</td>\n",
       "      <td>1.006317</td>\n",
       "      <td>0.979392</td>\n",
       "      <td>1.017842</td>\n",
       "      <td>0.969189</td>\n",
       "      <td>0.986189</td>\n",
       "      <td>0.982925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90644</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.956960</td>\n",
       "      <td>0.976674</td>\n",
       "      <td>0.973853</td>\n",
       "      <td>0.981257</td>\n",
       "      <td>1.012828</td>\n",
       "      <td>0.980836</td>\n",
       "      <td>0.980103</td>\n",
       "      <td>0.980189</td>\n",
       "      <td>1.008876</td>\n",
       "      <td>0.978065</td>\n",
       "      <td>1.016868</td>\n",
       "      <td>0.967524</td>\n",
       "      <td>0.991102</td>\n",
       "      <td>0.983548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90645</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.959980</td>\n",
       "      <td>0.979236</td>\n",
       "      <td>0.976699</td>\n",
       "      <td>0.981621</td>\n",
       "      <td>1.010673</td>\n",
       "      <td>0.988088</td>\n",
       "      <td>0.984115</td>\n",
       "      <td>0.977301</td>\n",
       "      <td>1.007229</td>\n",
       "      <td>0.977285</td>\n",
       "      <td>1.015444</td>\n",
       "      <td>0.968732</td>\n",
       "      <td>0.994794</td>\n",
       "      <td>0.984086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90646</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.962930</td>\n",
       "      <td>0.982288</td>\n",
       "      <td>0.979136</td>\n",
       "      <td>0.976949</td>\n",
       "      <td>1.009424</td>\n",
       "      <td>0.995438</td>\n",
       "      <td>0.988447</td>\n",
       "      <td>0.976945</td>\n",
       "      <td>1.002733</td>\n",
       "      <td>0.978025</td>\n",
       "      <td>1.012970</td>\n",
       "      <td>0.973292</td>\n",
       "      <td>0.996751</td>\n",
       "      <td>0.985004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90647</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.965810</td>\n",
       "      <td>0.985833</td>\n",
       "      <td>0.981525</td>\n",
       "      <td>0.976719</td>\n",
       "      <td>1.011663</td>\n",
       "      <td>0.999728</td>\n",
       "      <td>0.992393</td>\n",
       "      <td>0.983677</td>\n",
       "      <td>1.001409</td>\n",
       "      <td>0.978373</td>\n",
       "      <td>1.010319</td>\n",
       "      <td>0.981466</td>\n",
       "      <td>0.998745</td>\n",
       "      <td>0.986727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90648</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.968630</td>\n",
       "      <td>0.989858</td>\n",
       "      <td>0.985725</td>\n",
       "      <td>0.982498</td>\n",
       "      <td>1.015650</td>\n",
       "      <td>1.002462</td>\n",
       "      <td>0.995706</td>\n",
       "      <td>0.993917</td>\n",
       "      <td>1.000313</td>\n",
       "      <td>0.978471</td>\n",
       "      <td>1.008850</td>\n",
       "      <td>0.991474</td>\n",
       "      <td>1.002899</td>\n",
       "      <td>0.989302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90649</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.971390</td>\n",
       "      <td>0.994321</td>\n",
       "      <td>0.992835</td>\n",
       "      <td>0.992159</td>\n",
       "      <td>1.021567</td>\n",
       "      <td>1.005896</td>\n",
       "      <td>0.998328</td>\n",
       "      <td>1.002408</td>\n",
       "      <td>1.000974</td>\n",
       "      <td>0.977384</td>\n",
       "      <td>1.009575</td>\n",
       "      <td>1.001972</td>\n",
       "      <td>1.008584</td>\n",
       "      <td>0.992587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90650</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.974090</td>\n",
       "      <td>0.999155</td>\n",
       "      <td>1.003861</td>\n",
       "      <td>1.002911</td>\n",
       "      <td>1.030358</td>\n",
       "      <td>1.009350</td>\n",
       "      <td>1.000339</td>\n",
       "      <td>1.005569</td>\n",
       "      <td>1.006968</td>\n",
       "      <td>0.976500</td>\n",
       "      <td>1.012891</td>\n",
       "      <td>1.012656</td>\n",
       "      <td>1.015473</td>\n",
       "      <td>0.996415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90651</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.976720</td>\n",
       "      <td>1.004250</td>\n",
       "      <td>1.014080</td>\n",
       "      <td>1.012758</td>\n",
       "      <td>1.040448</td>\n",
       "      <td>1.011359</td>\n",
       "      <td>1.002364</td>\n",
       "      <td>1.006532</td>\n",
       "      <td>1.017668</td>\n",
       "      <td>0.975544</td>\n",
       "      <td>1.018599</td>\n",
       "      <td>1.021499</td>\n",
       "      <td>1.025126</td>\n",
       "      <td>0.999669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90652</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.979290</td>\n",
       "      <td>1.009470</td>\n",
       "      <td>1.022036</td>\n",
       "      <td>1.017535</td>\n",
       "      <td>1.048712</td>\n",
       "      <td>1.011865</td>\n",
       "      <td>1.004674</td>\n",
       "      <td>1.004485</td>\n",
       "      <td>1.029886</td>\n",
       "      <td>0.975703</td>\n",
       "      <td>1.026485</td>\n",
       "      <td>1.029013</td>\n",
       "      <td>1.034770</td>\n",
       "      <td>1.002567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90653</th>\n",
       "      <td>1.256640e+01</td>\n",
       "      <td>1.981810</td>\n",
       "      <td>1.014620</td>\n",
       "      <td>1.026101</td>\n",
       "      <td>1.015391</td>\n",
       "      <td>1.055430</td>\n",
       "      <td>1.012963</td>\n",
       "      <td>1.007153</td>\n",
       "      <td>0.999552</td>\n",
       "      <td>1.037693</td>\n",
       "      <td>0.980395</td>\n",
       "      <td>1.036856</td>\n",
       "      <td>1.035727</td>\n",
       "      <td>1.045785</td>\n",
       "      <td>1.005899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90654 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  X         Y      Pr_t  Pr_t_model1  Pr_t_model2  \\\n",
       "0     -5.000000e-09 -0.076720  1.104610     1.197522     1.273699   \n",
       "1     -5.000000e-09 -0.074086  1.127430     1.157657     1.225366   \n",
       "2     -5.000000e-09 -0.071392  1.140610     1.124565     1.177078   \n",
       "3     -5.000000e-09 -0.068635  1.146200     1.098349     1.130779   \n",
       "4     -5.000000e-09 -0.065814  1.146200     1.079288     1.084994   \n",
       "5     -5.000000e-09 -0.062928  1.142420     1.069063     1.048980   \n",
       "6     -5.000000e-09 -0.059976  1.136360     1.066496     1.028816   \n",
       "7     -5.000000e-09 -0.056957  1.129180     1.071164     1.024920   \n",
       "8     -5.000000e-09 -0.053868  1.121710     1.082207     1.031178   \n",
       "9     -5.000000e-09 -0.050709  1.114490     1.097838     1.046226   \n",
       "10    -5.000000e-09 -0.047478  1.107860     1.112872     1.066340   \n",
       "11    -5.000000e-09 -0.044174  1.102000     1.117975     1.084790   \n",
       "12    -5.000000e-09 -0.040796  1.096960     1.117090     1.098639   \n",
       "13    -5.000000e-09 -0.037342  1.092750     1.112997     1.108215   \n",
       "14    -5.000000e-09 -0.033810  1.089340     1.107183     1.113367   \n",
       "15    -5.000000e-09 -0.030200  1.086670     1.100900     1.116258   \n",
       "16    -5.000000e-09 -0.026509  1.084670     1.093861     1.117744   \n",
       "17    -5.000000e-09 -0.022737  1.083260     1.086862     1.117836   \n",
       "18    -5.000000e-09 -0.018881  1.082340     1.079562     1.115554   \n",
       "19    -5.000000e-09 -0.014941  1.081850     1.074496     1.114766   \n",
       "20    -5.000000e-09 -0.010915  1.081700     1.070120     1.113621   \n",
       "21    -5.000000e-09 -0.006800  1.081820     1.066807     1.112815   \n",
       "22    -5.000000e-09 -0.002597  1.082160     1.064483     1.112596   \n",
       "23    -5.000000e-09  0.001697  1.082680     1.063434     1.112809   \n",
       "24    -5.000000e-09  0.006084  1.083380     1.063847     1.113321   \n",
       "25    -5.000000e-09  0.010564  1.084250     1.065452     1.113954   \n",
       "26    -5.000000e-09  0.015140  1.085290     1.068026     1.114487   \n",
       "27    -5.000000e-09  0.019813  1.086490     1.071411     1.114797   \n",
       "28    -5.000000e-09  0.024584  1.087820     1.075479     1.114868   \n",
       "29    -5.000000e-09  0.029455  1.089260     1.079978     1.114697   \n",
       "...             ...       ...       ...          ...          ...   \n",
       "90624  1.256640e+01  1.880190  0.998599     1.006844     1.009018   \n",
       "90625  1.256640e+01  1.884860  0.994975     1.003983     1.005506   \n",
       "90626  1.256640e+01  1.889440  0.991615     1.001112     1.002190   \n",
       "90627  1.256640e+01  1.893920  0.988512     0.998191     0.999023   \n",
       "90628  1.256640e+01  1.898300  0.985649     0.995143     0.996131   \n",
       "90629  1.256640e+01  1.902600  0.983006     0.991882     0.993575   \n",
       "90630  1.256640e+01  1.906800  0.980574     0.988348     0.991311   \n",
       "90631  1.256640e+01  1.910910  0.978357     0.985244     0.989690   \n",
       "90632  1.256640e+01  1.914940  0.976371     0.981976     0.988172   \n",
       "90633  1.256640e+01  1.918880  0.974638     0.978526     0.986803   \n",
       "90634  1.256640e+01  1.922740  0.973178     0.975200     0.985626   \n",
       "90635  1.256640e+01  1.926510  0.972009     0.972211     0.984405   \n",
       "90636  1.256640e+01  1.930200  0.971143     0.969785     0.983722   \n",
       "90637  1.256640e+01  1.933810  0.970591     0.968059     0.983331   \n",
       "90638  1.256640e+01  1.937340  0.970359     0.967243     0.982340   \n",
       "90639  1.256640e+01  1.940800  0.970461     0.967806     0.979284   \n",
       "90640  1.256640e+01  1.944170  0.970912     0.968916     0.975516   \n",
       "90641  1.256640e+01  1.947480  0.971733     0.969990     0.972850   \n",
       "90642  1.256640e+01  1.950710  0.972948     0.971280     0.972400   \n",
       "90643  1.256640e+01  1.953870  0.974586     0.972566     0.975361   \n",
       "90644  1.256640e+01  1.956960  0.976674     0.973853     0.981257   \n",
       "90645  1.256640e+01  1.959980  0.979236     0.976699     0.981621   \n",
       "90646  1.256640e+01  1.962930  0.982288     0.979136     0.976949   \n",
       "90647  1.256640e+01  1.965810  0.985833     0.981525     0.976719   \n",
       "90648  1.256640e+01  1.968630  0.989858     0.985725     0.982498   \n",
       "90649  1.256640e+01  1.971390  0.994321     0.992835     0.992159   \n",
       "90650  1.256640e+01  1.974090  0.999155     1.003861     1.002911   \n",
       "90651  1.256640e+01  1.976720  1.004250     1.014080     1.012758   \n",
       "90652  1.256640e+01  1.979290  1.009470     1.022036     1.017535   \n",
       "90653  1.256640e+01  1.981810  1.014620     1.026101     1.015391   \n",
       "\n",
       "       Pr_t_model3  Pr_t_model4  Pr_t_model5  Pr_t_model6  Pr_t_model7  \\\n",
       "0         1.043940     1.058620     1.296706     1.314496     1.420162   \n",
       "1         1.056956     1.067863     1.261727     1.237134     1.338431   \n",
       "2         1.067786     1.077017     1.226617     1.169545     1.245782   \n",
       "3         1.077624     1.087376     1.194690     1.110717     1.209067   \n",
       "4         1.087542     1.098041     1.169597     1.072908     1.195700   \n",
       "5         1.098249     1.106905     1.150099     1.053486     1.192004   \n",
       "6         1.109692     1.112850     1.134942     1.049066     1.190492   \n",
       "7         1.122064     1.115815     1.123623     1.054408     1.186744   \n",
       "8         1.134851     1.116314     1.114686     1.065608     1.181324   \n",
       "9         1.144151     1.115274     1.106878     1.077571     1.176289   \n",
       "10        1.149724     1.113956     1.100383     1.087178     1.168853   \n",
       "11        1.152346     1.111808     1.094743     1.095011     1.153816   \n",
       "12        1.153519     1.109391     1.089635     1.102333     1.133103   \n",
       "13        1.152911     1.105037     1.085156     1.108715     1.117514   \n",
       "14        1.148445     1.099427     1.080879     1.113692     1.109214   \n",
       "15        1.141922     1.096667     1.079128     1.118614     1.105034   \n",
       "16        1.134117     1.093722     1.078926     1.122489     1.102492   \n",
       "17        1.124204     1.090374     1.080145     1.124048     1.100590   \n",
       "18        1.113458     1.082634     1.078301     1.121045     1.096914   \n",
       "19        1.106120     1.079597     1.080070     1.119334     1.098276   \n",
       "20        1.100821     1.078745     1.082523     1.116801     1.099512   \n",
       "21        1.097472     1.080699     1.085323     1.113914     1.101633   \n",
       "22        1.095874     1.085214     1.087922     1.111411     1.104100   \n",
       "23        1.095668     1.091245     1.090065     1.109394     1.106475   \n",
       "24        1.095991     1.096023     1.091644     1.107845     1.108527   \n",
       "25        1.095474     1.099311     1.092459     1.106770     1.110508   \n",
       "26        1.094162     1.101576     1.092578     1.106151     1.112308   \n",
       "27        1.092578     1.103163     1.091986     1.105987     1.113211   \n",
       "28        1.090891     1.104495     1.090770     1.106292     1.113058   \n",
       "29        1.089396     1.105616     1.089075     1.107005     1.112122   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "90624     0.993570     0.999040     1.003353     1.005760     0.993351   \n",
       "90625     0.990713     0.995467     0.999987     1.001256     0.993155   \n",
       "90626     0.988381     0.992401     0.996412     0.996896     0.993217   \n",
       "90627     0.986510     0.989838     0.992950     0.993005     0.993533   \n",
       "90628     0.985070     0.987818     0.989707     0.989616     0.994093   \n",
       "90629     0.984075     0.985995     0.986776     0.986600     0.994822   \n",
       "90630     0.984168     0.984427     0.984132     0.984096     0.995612   \n",
       "90631     0.984188     0.983088     0.982675     0.983334     0.996707   \n",
       "90632     0.984713     0.981663     0.981516     0.982876     0.997672   \n",
       "90633     0.985824     0.979983     0.980507     0.982783     0.998342   \n",
       "90634     0.987572     0.978170     0.979696     0.983201     0.998678   \n",
       "90635     0.989978     0.976288     0.978546     0.983731     0.998613   \n",
       "90636     0.992902     0.974873     0.976621     0.984014     0.998041   \n",
       "90637     0.995996     0.973986     0.974413     0.983774     0.996610   \n",
       "90638     0.998805     0.973844     0.973423     0.984057     0.995458   \n",
       "90639     1.001854     0.974223     0.974006     0.984875     0.995219   \n",
       "90640     1.005417     0.974415     0.974746     0.986256     0.995763   \n",
       "90641     1.008876     0.974286     0.975195     0.987160     0.998111   \n",
       "90642     1.012722     0.973707     0.975850     0.986603     1.002242   \n",
       "90643     1.014352     0.975660     0.977232     0.984100     1.006317   \n",
       "90644     1.012828     0.980836     0.980103     0.980189     1.008876   \n",
       "90645     1.010673     0.988088     0.984115     0.977301     1.007229   \n",
       "90646     1.009424     0.995438     0.988447     0.976945     1.002733   \n",
       "90647     1.011663     0.999728     0.992393     0.983677     1.001409   \n",
       "90648     1.015650     1.002462     0.995706     0.993917     1.000313   \n",
       "90649     1.021567     1.005896     0.998328     1.002408     1.000974   \n",
       "90650     1.030358     1.009350     1.000339     1.005569     1.006968   \n",
       "90651     1.040448     1.011359     1.002364     1.006532     1.017668   \n",
       "90652     1.048712     1.011865     1.004674     1.004485     1.029886   \n",
       "90653     1.055430     1.012963     1.007153     0.999552     1.037693   \n",
       "\n",
       "       Pr_t_model8  Pr_t_model9  Pr_t_model10  Pr_t_model11  Pr_t_model12  \n",
       "0         1.924836     0.928078      1.004540      0.961741      1.024329  \n",
       "1         1.764912     0.953731      1.039153      0.983685      1.024698  \n",
       "2         1.567871     0.983676      1.058335      1.002349      1.029069  \n",
       "3         1.380159     1.006633      1.065341      1.020842      1.035166  \n",
       "4         1.240191     1.023299      1.062063      1.035992      1.043207  \n",
       "5         1.153273     1.037313      1.052833      1.047260      1.054282  \n",
       "6         1.116320     1.049419      1.043184      1.056611      1.068585  \n",
       "7         1.105765     1.066452      1.043665      1.064321      1.080526  \n",
       "8         1.105447     1.087794      1.056036      1.073087      1.084715  \n",
       "9         1.112949     1.101965      1.073031      1.082459      1.082267  \n",
       "10        1.123989     1.108920      1.090574      1.089062      1.073871  \n",
       "11        1.133989     1.112687      1.101784      1.095123      1.071665  \n",
       "12        1.137989     1.115208      1.105653      1.101251      1.077192  \n",
       "13        1.134602     1.114399      1.104700      1.106258      1.083207  \n",
       "14        1.128835     1.117002      1.102645      1.109049      1.088519  \n",
       "15        1.123611     1.132171      1.104635      1.106869      1.093326  \n",
       "16        1.118241     1.144488      1.107330      1.099453      1.096867  \n",
       "17        1.113995     1.157083      1.109000      1.088823      1.100653  \n",
       "18        1.107198     1.189210      1.103651      1.077279      1.100612  \n",
       "19        1.109983     1.201406      1.104971      1.070821      1.104341  \n",
       "20        1.109599     1.206899      1.105505      1.067182      1.107386  \n",
       "21        1.108672     1.194500      1.107027      1.067262      1.109762  \n",
       "22        1.107802     1.186318      1.109225      1.069292      1.110965  \n",
       "23        1.107641     1.184760      1.112704      1.071122      1.110778  \n",
       "24        1.107998     1.183251      1.117493      1.071990      1.110034  \n",
       "25        1.108606     1.180502      1.123422      1.072222      1.109129  \n",
       "26        1.109447     1.179253      1.126390      1.071951      1.105104  \n",
       "27        1.110695     1.177626      1.127676      1.071346      1.100997  \n",
       "28        1.111968     1.175335      1.128042      1.070345      1.097968  \n",
       "29        1.113094     1.172206      1.127442      1.069567      1.095852  \n",
       "...            ...          ...           ...           ...           ...  \n",
       "90624     1.004610     1.024097      0.998305      0.998692      1.004226  \n",
       "90625     1.000312     1.024766      0.994329      0.995446      1.000440  \n",
       "90626     0.995925     1.024447      0.990263      0.992302      0.996655  \n",
       "90627     0.991584     1.023690      0.986186      0.989427      0.992791  \n",
       "90628     0.987397     1.022570      0.982514      0.986864      0.988969  \n",
       "90629     0.983393     1.023358      0.979875      0.984601      0.985490  \n",
       "90630     0.979496     1.031014      0.978722      0.981031      0.983923  \n",
       "90631     0.976221     1.038640      0.979518      0.979162      0.981038  \n",
       "90632     0.973469     1.040452      0.980562      0.977625      0.978289  \n",
       "90633     0.971212     1.035239      0.981836      0.976192      0.975474  \n",
       "90634     0.969982     1.028553      0.983386      0.974868      0.973245  \n",
       "90635     0.970042     1.026853      0.985297      0.973926      0.971740  \n",
       "90636     0.971048     1.026312      0.987202      0.973708      0.971018  \n",
       "90637     0.972273     1.026379      0.988270      0.974193      0.971179  \n",
       "90638     0.974163     1.026462      0.988017      0.975229      0.972253  \n",
       "90639     0.976658     1.026144      0.986242      0.976529      0.974376  \n",
       "90640     0.978795     1.024716      0.982781      0.977927      0.977169  \n",
       "90641     0.979794     1.020699      0.978545      0.979009      0.979769  \n",
       "90642     0.979579     1.018303      0.973616      0.981346      0.981719  \n",
       "90643     0.979392     1.017842      0.969189      0.986189      0.982925  \n",
       "90644     0.978065     1.016868      0.967524      0.991102      0.983548  \n",
       "90645     0.977285     1.015444      0.968732      0.994794      0.984086  \n",
       "90646     0.978025     1.012970      0.973292      0.996751      0.985004  \n",
       "90647     0.978373     1.010319      0.981466      0.998745      0.986727  \n",
       "90648     0.978471     1.008850      0.991474      1.002899      0.989302  \n",
       "90649     0.977384     1.009575      1.001972      1.008584      0.992587  \n",
       "90650     0.976500     1.012891      1.012656      1.015473      0.996415  \n",
       "90651     0.975544     1.018599      1.021499      1.025126      0.999669  \n",
       "90652     0.975703     1.026485      1.029013      1.034770      1.002567  \n",
       "90653     0.980395     1.036856      1.035727      1.045785      1.005899  \n",
       "\n",
       "[90654 rows x 15 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 9, 8, 7, 3, 1, 5, 4, 2, 10]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,2,3,4,5,6,7,8,9,10]\n",
    "random.shuffle(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([43044, 52085, 29298, ...,  5316, 58729, 53510], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Pr_t</th>\n",
       "      <th>Pr_t_model1</th>\n",
       "      <th>Pr_t_model2</th>\n",
       "      <th>Pr_t_model3</th>\n",
       "      <th>Pr_t_model4</th>\n",
       "      <th>Pr_t_model5</th>\n",
       "      <th>Pr_t_model6</th>\n",
       "      <th>Pr_t_model7</th>\n",
       "      <th>Pr_t_model8</th>\n",
       "      <th>Pr_t_model9</th>\n",
       "      <th>Pr_t_model10</th>\n",
       "      <th>Pr_t_model11</th>\n",
       "      <th>Pr_t_model12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61043</th>\n",
       "      <td>8.445770</td>\n",
       "      <td>1.459900</td>\n",
       "      <td>0.941288</td>\n",
       "      <td>0.952879</td>\n",
       "      <td>0.943810</td>\n",
       "      <td>0.948880</td>\n",
       "      <td>0.970266</td>\n",
       "      <td>0.979655</td>\n",
       "      <td>0.948912</td>\n",
       "      <td>0.969265</td>\n",
       "      <td>0.962497</td>\n",
       "      <td>0.978226</td>\n",
       "      <td>0.976618</td>\n",
       "      <td>0.942965</td>\n",
       "      <td>0.956116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84851</th>\n",
       "      <td>11.777300</td>\n",
       "      <td>0.604984</td>\n",
       "      <td>0.876677</td>\n",
       "      <td>0.882014</td>\n",
       "      <td>0.880476</td>\n",
       "      <td>0.883672</td>\n",
       "      <td>0.880458</td>\n",
       "      <td>0.900107</td>\n",
       "      <td>0.882035</td>\n",
       "      <td>0.900853</td>\n",
       "      <td>0.921806</td>\n",
       "      <td>0.915922</td>\n",
       "      <td>0.896533</td>\n",
       "      <td>0.880608</td>\n",
       "      <td>0.894326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69613</th>\n",
       "      <td>9.643960</td>\n",
       "      <td>1.615110</td>\n",
       "      <td>1.050250</td>\n",
       "      <td>1.044785</td>\n",
       "      <td>1.053393</td>\n",
       "      <td>1.041060</td>\n",
       "      <td>1.040492</td>\n",
       "      <td>1.036874</td>\n",
       "      <td>1.045349</td>\n",
       "      <td>1.058080</td>\n",
       "      <td>1.036525</td>\n",
       "      <td>1.040968</td>\n",
       "      <td>1.046795</td>\n",
       "      <td>1.042910</td>\n",
       "      <td>1.039833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11892</th>\n",
       "      <td>1.607330</td>\n",
       "      <td>1.982250</td>\n",
       "      <td>0.943615</td>\n",
       "      <td>0.953676</td>\n",
       "      <td>0.938032</td>\n",
       "      <td>0.958043</td>\n",
       "      <td>0.925098</td>\n",
       "      <td>0.938735</td>\n",
       "      <td>0.941899</td>\n",
       "      <td>0.948100</td>\n",
       "      <td>0.935128</td>\n",
       "      <td>0.959363</td>\n",
       "      <td>0.939401</td>\n",
       "      <td>0.975637</td>\n",
       "      <td>0.940601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38313</th>\n",
       "      <td>5.260340</td>\n",
       "      <td>1.973670</td>\n",
       "      <td>0.950802</td>\n",
       "      <td>0.943151</td>\n",
       "      <td>0.962912</td>\n",
       "      <td>0.927510</td>\n",
       "      <td>0.946043</td>\n",
       "      <td>0.954719</td>\n",
       "      <td>0.960530</td>\n",
       "      <td>0.943175</td>\n",
       "      <td>0.947005</td>\n",
       "      <td>0.958799</td>\n",
       "      <td>0.946367</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>0.953489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48236</th>\n",
       "      <td>6.663100</td>\n",
       "      <td>0.266621</td>\n",
       "      <td>1.197980</td>\n",
       "      <td>1.196175</td>\n",
       "      <td>1.202818</td>\n",
       "      <td>1.151249</td>\n",
       "      <td>1.192933</td>\n",
       "      <td>1.207349</td>\n",
       "      <td>1.213757</td>\n",
       "      <td>1.217458</td>\n",
       "      <td>1.192869</td>\n",
       "      <td>1.205963</td>\n",
       "      <td>1.204781</td>\n",
       "      <td>1.186584</td>\n",
       "      <td>1.213202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80116</th>\n",
       "      <td>11.105200</td>\n",
       "      <td>1.931750</td>\n",
       "      <td>1.035210</td>\n",
       "      <td>1.035259</td>\n",
       "      <td>1.044752</td>\n",
       "      <td>1.040893</td>\n",
       "      <td>1.042166</td>\n",
       "      <td>1.043295</td>\n",
       "      <td>1.049647</td>\n",
       "      <td>1.036197</td>\n",
       "      <td>1.042988</td>\n",
       "      <td>1.094417</td>\n",
       "      <td>1.037700</td>\n",
       "      <td>1.039002</td>\n",
       "      <td>1.032696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14216</th>\n",
       "      <td>1.928790</td>\n",
       "      <td>1.949010</td>\n",
       "      <td>0.919665</td>\n",
       "      <td>0.921209</td>\n",
       "      <td>0.914899</td>\n",
       "      <td>0.940598</td>\n",
       "      <td>0.923133</td>\n",
       "      <td>0.917220</td>\n",
       "      <td>0.928918</td>\n",
       "      <td>0.917534</td>\n",
       "      <td>0.924196</td>\n",
       "      <td>0.946036</td>\n",
       "      <td>0.921255</td>\n",
       "      <td>0.921013</td>\n",
       "      <td>0.917140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51797</th>\n",
       "      <td>7.159910</td>\n",
       "      <td>0.322335</td>\n",
       "      <td>1.154720</td>\n",
       "      <td>1.152172</td>\n",
       "      <td>1.141388</td>\n",
       "      <td>1.144469</td>\n",
       "      <td>1.155042</td>\n",
       "      <td>1.158755</td>\n",
       "      <td>1.168244</td>\n",
       "      <td>1.162583</td>\n",
       "      <td>1.156581</td>\n",
       "      <td>1.144906</td>\n",
       "      <td>1.171846</td>\n",
       "      <td>1.156136</td>\n",
       "      <td>1.163035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82811</th>\n",
       "      <td>11.485100</td>\n",
       "      <td>1.760940</td>\n",
       "      <td>1.099280</td>\n",
       "      <td>1.096786</td>\n",
       "      <td>1.091541</td>\n",
       "      <td>1.094371</td>\n",
       "      <td>1.100629</td>\n",
       "      <td>1.102220</td>\n",
       "      <td>1.094628</td>\n",
       "      <td>1.081418</td>\n",
       "      <td>1.100404</td>\n",
       "      <td>1.099430</td>\n",
       "      <td>1.094880</td>\n",
       "      <td>1.093860</td>\n",
       "      <td>1.101269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16295</th>\n",
       "      <td>2.221030</td>\n",
       "      <td>1.743920</td>\n",
       "      <td>0.932989</td>\n",
       "      <td>0.936309</td>\n",
       "      <td>0.940408</td>\n",
       "      <td>0.924710</td>\n",
       "      <td>0.935573</td>\n",
       "      <td>0.929375</td>\n",
       "      <td>0.942313</td>\n",
       "      <td>0.926071</td>\n",
       "      <td>0.937516</td>\n",
       "      <td>0.939750</td>\n",
       "      <td>0.931719</td>\n",
       "      <td>0.935166</td>\n",
       "      <td>0.943353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37392</th>\n",
       "      <td>5.143440</td>\n",
       "      <td>1.511790</td>\n",
       "      <td>0.781052</td>\n",
       "      <td>0.796403</td>\n",
       "      <td>0.793003</td>\n",
       "      <td>0.776096</td>\n",
       "      <td>0.793468</td>\n",
       "      <td>0.795877</td>\n",
       "      <td>0.797942</td>\n",
       "      <td>0.802026</td>\n",
       "      <td>0.785395</td>\n",
       "      <td>0.771671</td>\n",
       "      <td>0.785947</td>\n",
       "      <td>0.776986</td>\n",
       "      <td>0.788064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80237</th>\n",
       "      <td>11.134400</td>\n",
       "      <td>0.777315</td>\n",
       "      <td>0.895635</td>\n",
       "      <td>0.945127</td>\n",
       "      <td>0.889781</td>\n",
       "      <td>0.891626</td>\n",
       "      <td>0.890434</td>\n",
       "      <td>0.938208</td>\n",
       "      <td>0.893615</td>\n",
       "      <td>0.910625</td>\n",
       "      <td>0.932946</td>\n",
       "      <td>0.983472</td>\n",
       "      <td>0.911891</td>\n",
       "      <td>0.894016</td>\n",
       "      <td>0.904901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11408</th>\n",
       "      <td>1.548880</td>\n",
       "      <td>1.686640</td>\n",
       "      <td>0.928483</td>\n",
       "      <td>0.933877</td>\n",
       "      <td>0.934936</td>\n",
       "      <td>0.934770</td>\n",
       "      <td>0.945278</td>\n",
       "      <td>0.925480</td>\n",
       "      <td>0.929646</td>\n",
       "      <td>0.940314</td>\n",
       "      <td>0.939875</td>\n",
       "      <td>0.938675</td>\n",
       "      <td>0.919065</td>\n",
       "      <td>0.933583</td>\n",
       "      <td>0.937318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39144</th>\n",
       "      <td>5.377240</td>\n",
       "      <td>1.945620</td>\n",
       "      <td>0.941884</td>\n",
       "      <td>0.943467</td>\n",
       "      <td>0.944330</td>\n",
       "      <td>0.930272</td>\n",
       "      <td>0.949933</td>\n",
       "      <td>0.929807</td>\n",
       "      <td>0.953469</td>\n",
       "      <td>0.936102</td>\n",
       "      <td>0.943263</td>\n",
       "      <td>0.993894</td>\n",
       "      <td>0.936559</td>\n",
       "      <td>0.939395</td>\n",
       "      <td>0.938890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35812</th>\n",
       "      <td>4.938880</td>\n",
       "      <td>0.155351</td>\n",
       "      <td>0.876913</td>\n",
       "      <td>0.882664</td>\n",
       "      <td>0.887981</td>\n",
       "      <td>0.877622</td>\n",
       "      <td>0.876279</td>\n",
       "      <td>0.871205</td>\n",
       "      <td>0.884830</td>\n",
       "      <td>0.877537</td>\n",
       "      <td>0.874246</td>\n",
       "      <td>0.904863</td>\n",
       "      <td>0.874278</td>\n",
       "      <td>0.865272</td>\n",
       "      <td>0.873887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84640</th>\n",
       "      <td>11.748100</td>\n",
       "      <td>0.605609</td>\n",
       "      <td>0.878620</td>\n",
       "      <td>0.884949</td>\n",
       "      <td>0.882736</td>\n",
       "      <td>0.885633</td>\n",
       "      <td>0.881792</td>\n",
       "      <td>0.902861</td>\n",
       "      <td>0.883907</td>\n",
       "      <td>0.900695</td>\n",
       "      <td>0.920835</td>\n",
       "      <td>0.918683</td>\n",
       "      <td>0.898999</td>\n",
       "      <td>0.882160</td>\n",
       "      <td>0.896448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18578</th>\n",
       "      <td>2.542500</td>\n",
       "      <td>1.235800</td>\n",
       "      <td>0.694338</td>\n",
       "      <td>0.696837</td>\n",
       "      <td>0.678397</td>\n",
       "      <td>0.693290</td>\n",
       "      <td>0.691965</td>\n",
       "      <td>0.711152</td>\n",
       "      <td>0.682893</td>\n",
       "      <td>0.698953</td>\n",
       "      <td>0.689215</td>\n",
       "      <td>0.732949</td>\n",
       "      <td>0.711331</td>\n",
       "      <td>0.696858</td>\n",
       "      <td>0.682437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3928</th>\n",
       "      <td>0.526034</td>\n",
       "      <td>1.211510</td>\n",
       "      <td>0.910278</td>\n",
       "      <td>0.857995</td>\n",
       "      <td>0.880108</td>\n",
       "      <td>0.896055</td>\n",
       "      <td>0.915543</td>\n",
       "      <td>0.872803</td>\n",
       "      <td>0.890122</td>\n",
       "      <td>0.850600</td>\n",
       "      <td>0.847263</td>\n",
       "      <td>0.861335</td>\n",
       "      <td>0.880019</td>\n",
       "      <td>0.882102</td>\n",
       "      <td>0.894474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20472</th>\n",
       "      <td>2.805520</td>\n",
       "      <td>0.737260</td>\n",
       "      <td>0.752250</td>\n",
       "      <td>0.701056</td>\n",
       "      <td>0.732210</td>\n",
       "      <td>0.748482</td>\n",
       "      <td>0.750986</td>\n",
       "      <td>0.709525</td>\n",
       "      <td>0.744486</td>\n",
       "      <td>0.716035</td>\n",
       "      <td>0.721697</td>\n",
       "      <td>0.726881</td>\n",
       "      <td>0.732929</td>\n",
       "      <td>0.751853</td>\n",
       "      <td>0.741640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76791</th>\n",
       "      <td>10.666800</td>\n",
       "      <td>0.002269</td>\n",
       "      <td>1.100270</td>\n",
       "      <td>1.099077</td>\n",
       "      <td>1.126818</td>\n",
       "      <td>1.107626</td>\n",
       "      <td>1.102999</td>\n",
       "      <td>1.100525</td>\n",
       "      <td>1.126557</td>\n",
       "      <td>1.108562</td>\n",
       "      <td>1.102311</td>\n",
       "      <td>1.142576</td>\n",
       "      <td>1.115689</td>\n",
       "      <td>1.099783</td>\n",
       "      <td>1.113449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21302</th>\n",
       "      <td>2.922410</td>\n",
       "      <td>0.543589</td>\n",
       "      <td>0.805431</td>\n",
       "      <td>0.795784</td>\n",
       "      <td>0.797863</td>\n",
       "      <td>0.798497</td>\n",
       "      <td>0.810813</td>\n",
       "      <td>0.794541</td>\n",
       "      <td>0.801724</td>\n",
       "      <td>0.804840</td>\n",
       "      <td>0.804233</td>\n",
       "      <td>0.814926</td>\n",
       "      <td>0.801513</td>\n",
       "      <td>0.795263</td>\n",
       "      <td>0.804267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25482</th>\n",
       "      <td>3.506890</td>\n",
       "      <td>0.134202</td>\n",
       "      <td>0.891762</td>\n",
       "      <td>0.897983</td>\n",
       "      <td>0.903026</td>\n",
       "      <td>0.895110</td>\n",
       "      <td>0.890492</td>\n",
       "      <td>0.878617</td>\n",
       "      <td>0.904844</td>\n",
       "      <td>0.905500</td>\n",
       "      <td>0.883012</td>\n",
       "      <td>0.931439</td>\n",
       "      <td>0.889604</td>\n",
       "      <td>0.883717</td>\n",
       "      <td>0.890345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45193</th>\n",
       "      <td>6.224740</td>\n",
       "      <td>1.677720</td>\n",
       "      <td>0.918831</td>\n",
       "      <td>0.919094</td>\n",
       "      <td>0.913721</td>\n",
       "      <td>0.893954</td>\n",
       "      <td>0.921195</td>\n",
       "      <td>0.912020</td>\n",
       "      <td>0.921578</td>\n",
       "      <td>0.929364</td>\n",
       "      <td>0.907693</td>\n",
       "      <td>0.926219</td>\n",
       "      <td>0.925783</td>\n",
       "      <td>0.893954</td>\n",
       "      <td>0.918510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51573</th>\n",
       "      <td>7.130680</td>\n",
       "      <td>0.225792</td>\n",
       "      <td>1.074210</td>\n",
       "      <td>1.067354</td>\n",
       "      <td>1.084244</td>\n",
       "      <td>1.087965</td>\n",
       "      <td>1.064401</td>\n",
       "      <td>1.062945</td>\n",
       "      <td>1.086897</td>\n",
       "      <td>1.072696</td>\n",
       "      <td>1.085105</td>\n",
       "      <td>1.166564</td>\n",
       "      <td>1.094615</td>\n",
       "      <td>1.085779</td>\n",
       "      <td>1.084419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33545</th>\n",
       "      <td>4.617410</td>\n",
       "      <td>0.449243</td>\n",
       "      <td>0.829803</td>\n",
       "      <td>0.832630</td>\n",
       "      <td>0.834006</td>\n",
       "      <td>0.833467</td>\n",
       "      <td>0.843210</td>\n",
       "      <td>0.838728</td>\n",
       "      <td>0.842065</td>\n",
       "      <td>0.850251</td>\n",
       "      <td>0.827330</td>\n",
       "      <td>0.827005</td>\n",
       "      <td>0.854972</td>\n",
       "      <td>0.835360</td>\n",
       "      <td>0.837707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45199</th>\n",
       "      <td>6.224740</td>\n",
       "      <td>1.724460</td>\n",
       "      <td>0.945270</td>\n",
       "      <td>0.943938</td>\n",
       "      <td>0.942026</td>\n",
       "      <td>0.916476</td>\n",
       "      <td>0.948501</td>\n",
       "      <td>0.936012</td>\n",
       "      <td>0.954313</td>\n",
       "      <td>0.949245</td>\n",
       "      <td>0.931088</td>\n",
       "      <td>0.955453</td>\n",
       "      <td>0.950453</td>\n",
       "      <td>0.917068</td>\n",
       "      <td>0.943623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7885</th>\n",
       "      <td>1.081290</td>\n",
       "      <td>0.034449</td>\n",
       "      <td>0.842284</td>\n",
       "      <td>0.858245</td>\n",
       "      <td>0.854267</td>\n",
       "      <td>0.832743</td>\n",
       "      <td>0.846432</td>\n",
       "      <td>0.836655</td>\n",
       "      <td>0.858630</td>\n",
       "      <td>0.867217</td>\n",
       "      <td>0.843246</td>\n",
       "      <td>0.877239</td>\n",
       "      <td>0.856647</td>\n",
       "      <td>0.827416</td>\n",
       "      <td>0.836962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49868</th>\n",
       "      <td>6.896890</td>\n",
       "      <td>0.101745</td>\n",
       "      <td>1.442880</td>\n",
       "      <td>1.421224</td>\n",
       "      <td>1.446862</td>\n",
       "      <td>1.403169</td>\n",
       "      <td>1.410003</td>\n",
       "      <td>1.369385</td>\n",
       "      <td>1.412419</td>\n",
       "      <td>1.436414</td>\n",
       "      <td>1.475941</td>\n",
       "      <td>1.324873</td>\n",
       "      <td>1.392234</td>\n",
       "      <td>1.375569</td>\n",
       "      <td>1.440983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>2.454830</td>\n",
       "      <td>1.786020</td>\n",
       "      <td>0.930817</td>\n",
       "      <td>0.928872</td>\n",
       "      <td>0.938380</td>\n",
       "      <td>0.924210</td>\n",
       "      <td>0.933136</td>\n",
       "      <td>0.933123</td>\n",
       "      <td>0.940138</td>\n",
       "      <td>0.918843</td>\n",
       "      <td>0.933147</td>\n",
       "      <td>0.936675</td>\n",
       "      <td>0.934419</td>\n",
       "      <td>0.943510</td>\n",
       "      <td>0.939461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21287</th>\n",
       "      <td>2.922410</td>\n",
       "      <td>0.387273</td>\n",
       "      <td>0.869073</td>\n",
       "      <td>0.859839</td>\n",
       "      <td>0.865828</td>\n",
       "      <td>0.870461</td>\n",
       "      <td>0.873126</td>\n",
       "      <td>0.868256</td>\n",
       "      <td>0.870617</td>\n",
       "      <td>0.866038</td>\n",
       "      <td>0.861000</td>\n",
       "      <td>0.876409</td>\n",
       "      <td>0.889483</td>\n",
       "      <td>0.856353</td>\n",
       "      <td>0.864963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45256</th>\n",
       "      <td>6.224740</td>\n",
       "      <td>1.981250</td>\n",
       "      <td>1.005730</td>\n",
       "      <td>0.990274</td>\n",
       "      <td>1.014590</td>\n",
       "      <td>0.985202</td>\n",
       "      <td>1.001811</td>\n",
       "      <td>1.010737</td>\n",
       "      <td>1.011644</td>\n",
       "      <td>0.913454</td>\n",
       "      <td>1.026272</td>\n",
       "      <td>1.017385</td>\n",
       "      <td>0.995797</td>\n",
       "      <td>1.008737</td>\n",
       "      <td>0.995340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9115</th>\n",
       "      <td>1.227410</td>\n",
       "      <td>1.920390</td>\n",
       "      <td>0.925797</td>\n",
       "      <td>0.927199</td>\n",
       "      <td>0.937922</td>\n",
       "      <td>0.923548</td>\n",
       "      <td>0.922709</td>\n",
       "      <td>0.929497</td>\n",
       "      <td>0.926736</td>\n",
       "      <td>0.923068</td>\n",
       "      <td>0.920462</td>\n",
       "      <td>0.978710</td>\n",
       "      <td>0.938409</td>\n",
       "      <td>0.934900</td>\n",
       "      <td>0.921208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82559</th>\n",
       "      <td>11.455900</td>\n",
       "      <td>1.361220</td>\n",
       "      <td>0.985317</td>\n",
       "      <td>0.978791</td>\n",
       "      <td>0.978614</td>\n",
       "      <td>0.974327</td>\n",
       "      <td>0.983091</td>\n",
       "      <td>0.993476</td>\n",
       "      <td>0.976565</td>\n",
       "      <td>0.936667</td>\n",
       "      <td>0.957112</td>\n",
       "      <td>0.972089</td>\n",
       "      <td>0.976420</td>\n",
       "      <td>0.966906</td>\n",
       "      <td>0.984187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32163</th>\n",
       "      <td>4.412840</td>\n",
       "      <td>1.816850</td>\n",
       "      <td>0.913729</td>\n",
       "      <td>0.907638</td>\n",
       "      <td>0.917836</td>\n",
       "      <td>0.906418</td>\n",
       "      <td>0.917683</td>\n",
       "      <td>0.903869</td>\n",
       "      <td>0.916995</td>\n",
       "      <td>0.919860</td>\n",
       "      <td>0.918610</td>\n",
       "      <td>0.934746</td>\n",
       "      <td>0.908356</td>\n",
       "      <td>0.904422</td>\n",
       "      <td>0.910798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85480</th>\n",
       "      <td>11.865000</td>\n",
       "      <td>0.565138</td>\n",
       "      <td>0.882272</td>\n",
       "      <td>0.873699</td>\n",
       "      <td>0.885062</td>\n",
       "      <td>0.884109</td>\n",
       "      <td>0.885349</td>\n",
       "      <td>0.892416</td>\n",
       "      <td>0.886796</td>\n",
       "      <td>0.900006</td>\n",
       "      <td>0.922958</td>\n",
       "      <td>0.896356</td>\n",
       "      <td>0.895434</td>\n",
       "      <td>0.877926</td>\n",
       "      <td>0.896913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41623</th>\n",
       "      <td>5.727930</td>\n",
       "      <td>1.736880</td>\n",
       "      <td>0.922363</td>\n",
       "      <td>0.911264</td>\n",
       "      <td>0.916544</td>\n",
       "      <td>0.895591</td>\n",
       "      <td>0.916236</td>\n",
       "      <td>0.923138</td>\n",
       "      <td>0.931287</td>\n",
       "      <td>0.919804</td>\n",
       "      <td>0.910594</td>\n",
       "      <td>0.932626</td>\n",
       "      <td>0.924878</td>\n",
       "      <td>0.899534</td>\n",
       "      <td>0.915319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73771</th>\n",
       "      <td>10.228400</td>\n",
       "      <td>1.421120</td>\n",
       "      <td>0.982098</td>\n",
       "      <td>0.972533</td>\n",
       "      <td>0.970160</td>\n",
       "      <td>0.966410</td>\n",
       "      <td>0.979613</td>\n",
       "      <td>0.990223</td>\n",
       "      <td>0.968483</td>\n",
       "      <td>0.956230</td>\n",
       "      <td>0.970645</td>\n",
       "      <td>0.977655</td>\n",
       "      <td>0.983272</td>\n",
       "      <td>0.958167</td>\n",
       "      <td>0.979435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23023</th>\n",
       "      <td>3.156200</td>\n",
       "      <td>1.256190</td>\n",
       "      <td>0.684525</td>\n",
       "      <td>0.692622</td>\n",
       "      <td>0.674849</td>\n",
       "      <td>0.684527</td>\n",
       "      <td>0.681558</td>\n",
       "      <td>0.704958</td>\n",
       "      <td>0.674669</td>\n",
       "      <td>0.696001</td>\n",
       "      <td>0.682989</td>\n",
       "      <td>0.723489</td>\n",
       "      <td>0.704223</td>\n",
       "      <td>0.687906</td>\n",
       "      <td>0.672488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11708</th>\n",
       "      <td>1.607330</td>\n",
       "      <td>0.059033</td>\n",
       "      <td>0.866467</td>\n",
       "      <td>0.876558</td>\n",
       "      <td>0.873297</td>\n",
       "      <td>0.855212</td>\n",
       "      <td>0.869228</td>\n",
       "      <td>0.854747</td>\n",
       "      <td>0.879501</td>\n",
       "      <td>0.886075</td>\n",
       "      <td>0.884677</td>\n",
       "      <td>0.883775</td>\n",
       "      <td>0.878190</td>\n",
       "      <td>0.865441</td>\n",
       "      <td>0.864448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57768</th>\n",
       "      <td>7.978180</td>\n",
       "      <td>1.938410</td>\n",
       "      <td>1.050530</td>\n",
       "      <td>1.050905</td>\n",
       "      <td>1.068079</td>\n",
       "      <td>1.033776</td>\n",
       "      <td>1.041365</td>\n",
       "      <td>1.032904</td>\n",
       "      <td>1.060078</td>\n",
       "      <td>1.046475</td>\n",
       "      <td>1.049181</td>\n",
       "      <td>1.117430</td>\n",
       "      <td>1.045644</td>\n",
       "      <td>1.045272</td>\n",
       "      <td>1.043252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60652</th>\n",
       "      <td>8.387320</td>\n",
       "      <td>1.715030</td>\n",
       "      <td>1.073190</td>\n",
       "      <td>1.070988</td>\n",
       "      <td>1.084028</td>\n",
       "      <td>1.072301</td>\n",
       "      <td>1.071295</td>\n",
       "      <td>1.075176</td>\n",
       "      <td>1.081803</td>\n",
       "      <td>1.088609</td>\n",
       "      <td>1.069376</td>\n",
       "      <td>1.116461</td>\n",
       "      <td>1.084766</td>\n",
       "      <td>1.062548</td>\n",
       "      <td>1.072189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15149</th>\n",
       "      <td>2.074910</td>\n",
       "      <td>0.384982</td>\n",
       "      <td>0.855641</td>\n",
       "      <td>0.854963</td>\n",
       "      <td>0.853439</td>\n",
       "      <td>0.852313</td>\n",
       "      <td>0.862412</td>\n",
       "      <td>0.859572</td>\n",
       "      <td>0.862629</td>\n",
       "      <td>0.844396</td>\n",
       "      <td>0.849308</td>\n",
       "      <td>0.890304</td>\n",
       "      <td>0.874212</td>\n",
       "      <td>0.842182</td>\n",
       "      <td>0.851411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8275</th>\n",
       "      <td>1.110520</td>\n",
       "      <td>1.954640</td>\n",
       "      <td>0.933711</td>\n",
       "      <td>0.928422</td>\n",
       "      <td>0.923867</td>\n",
       "      <td>0.955603</td>\n",
       "      <td>0.936465</td>\n",
       "      <td>0.925580</td>\n",
       "      <td>0.937236</td>\n",
       "      <td>0.956681</td>\n",
       "      <td>0.925188</td>\n",
       "      <td>0.948909</td>\n",
       "      <td>0.922961</td>\n",
       "      <td>0.941741</td>\n",
       "      <td>0.930539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78762</th>\n",
       "      <td>10.929800</td>\n",
       "      <td>0.623121</td>\n",
       "      <td>0.911927</td>\n",
       "      <td>0.927079</td>\n",
       "      <td>0.913571</td>\n",
       "      <td>0.917140</td>\n",
       "      <td>0.904710</td>\n",
       "      <td>0.934819</td>\n",
       "      <td>0.913472</td>\n",
       "      <td>0.904409</td>\n",
       "      <td>0.900780</td>\n",
       "      <td>0.944330</td>\n",
       "      <td>0.924913</td>\n",
       "      <td>0.908132</td>\n",
       "      <td>0.925622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4551</th>\n",
       "      <td>0.613706</td>\n",
       "      <td>0.627104</td>\n",
       "      <td>0.725950</td>\n",
       "      <td>0.712449</td>\n",
       "      <td>0.727638</td>\n",
       "      <td>0.721983</td>\n",
       "      <td>0.731362</td>\n",
       "      <td>0.726399</td>\n",
       "      <td>0.734011</td>\n",
       "      <td>0.807543</td>\n",
       "      <td>0.770360</td>\n",
       "      <td>0.707851</td>\n",
       "      <td>0.737095</td>\n",
       "      <td>0.739640</td>\n",
       "      <td>0.729204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39002</th>\n",
       "      <td>5.377240</td>\n",
       "      <td>0.314563</td>\n",
       "      <td>0.871159</td>\n",
       "      <td>0.869120</td>\n",
       "      <td>0.876536</td>\n",
       "      <td>0.861486</td>\n",
       "      <td>0.874872</td>\n",
       "      <td>0.871805</td>\n",
       "      <td>0.881553</td>\n",
       "      <td>0.879509</td>\n",
       "      <td>0.876600</td>\n",
       "      <td>0.901674</td>\n",
       "      <td>0.869388</td>\n",
       "      <td>0.865524</td>\n",
       "      <td>0.869167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20873</th>\n",
       "      <td>2.863960</td>\n",
       "      <td>0.486844</td>\n",
       "      <td>0.819296</td>\n",
       "      <td>0.812309</td>\n",
       "      <td>0.816914</td>\n",
       "      <td>0.811907</td>\n",
       "      <td>0.829721</td>\n",
       "      <td>0.822827</td>\n",
       "      <td>0.823116</td>\n",
       "      <td>0.813377</td>\n",
       "      <td>0.820163</td>\n",
       "      <td>0.844408</td>\n",
       "      <td>0.829648</td>\n",
       "      <td>0.809215</td>\n",
       "      <td>0.820891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43685</th>\n",
       "      <td>6.020170</td>\n",
       "      <td>1.338960</td>\n",
       "      <td>0.752117</td>\n",
       "      <td>0.724343</td>\n",
       "      <td>0.728587</td>\n",
       "      <td>0.741552</td>\n",
       "      <td>0.767979</td>\n",
       "      <td>0.731589</td>\n",
       "      <td>0.742605</td>\n",
       "      <td>0.758335</td>\n",
       "      <td>0.715946</td>\n",
       "      <td>0.767208</td>\n",
       "      <td>0.744350</td>\n",
       "      <td>0.748239</td>\n",
       "      <td>0.738745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41857</th>\n",
       "      <td>5.757150</td>\n",
       "      <td>1.877300</td>\n",
       "      <td>0.933367</td>\n",
       "      <td>0.926096</td>\n",
       "      <td>0.937188</td>\n",
       "      <td>0.940631</td>\n",
       "      <td>0.931568</td>\n",
       "      <td>0.930411</td>\n",
       "      <td>0.939313</td>\n",
       "      <td>0.943798</td>\n",
       "      <td>0.928754</td>\n",
       "      <td>0.993958</td>\n",
       "      <td>0.945311</td>\n",
       "      <td>0.930172</td>\n",
       "      <td>0.928231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88560</th>\n",
       "      <td>12.303400</td>\n",
       "      <td>-0.029220</td>\n",
       "      <td>1.148540</td>\n",
       "      <td>1.149764</td>\n",
       "      <td>1.126843</td>\n",
       "      <td>1.131161</td>\n",
       "      <td>1.141511</td>\n",
       "      <td>1.153083</td>\n",
       "      <td>1.138974</td>\n",
       "      <td>1.140499</td>\n",
       "      <td>1.141899</td>\n",
       "      <td>1.158038</td>\n",
       "      <td>1.141375</td>\n",
       "      <td>1.138751</td>\n",
       "      <td>1.154409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18739</th>\n",
       "      <td>2.571720</td>\n",
       "      <td>0.274245</td>\n",
       "      <td>0.921221</td>\n",
       "      <td>0.911020</td>\n",
       "      <td>0.920932</td>\n",
       "      <td>0.918676</td>\n",
       "      <td>0.924596</td>\n",
       "      <td>0.913957</td>\n",
       "      <td>0.928248</td>\n",
       "      <td>0.911965</td>\n",
       "      <td>0.910194</td>\n",
       "      <td>0.900160</td>\n",
       "      <td>0.935558</td>\n",
       "      <td>0.910472</td>\n",
       "      <td>0.921105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23445</th>\n",
       "      <td>3.214650</td>\n",
       "      <td>1.230840</td>\n",
       "      <td>0.664806</td>\n",
       "      <td>0.683490</td>\n",
       "      <td>0.655277</td>\n",
       "      <td>0.667175</td>\n",
       "      <td>0.664612</td>\n",
       "      <td>0.700288</td>\n",
       "      <td>0.658334</td>\n",
       "      <td>0.687421</td>\n",
       "      <td>0.672259</td>\n",
       "      <td>0.725366</td>\n",
       "      <td>0.698185</td>\n",
       "      <td>0.671710</td>\n",
       "      <td>0.655006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85268</th>\n",
       "      <td>11.835800</td>\n",
       "      <td>0.541034</td>\n",
       "      <td>0.893393</td>\n",
       "      <td>0.878803</td>\n",
       "      <td>0.896180</td>\n",
       "      <td>0.892481</td>\n",
       "      <td>0.894584</td>\n",
       "      <td>0.897904</td>\n",
       "      <td>0.896366</td>\n",
       "      <td>0.900082</td>\n",
       "      <td>0.922630</td>\n",
       "      <td>0.896562</td>\n",
       "      <td>0.903992</td>\n",
       "      <td>0.883280</td>\n",
       "      <td>0.906299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9062</th>\n",
       "      <td>1.227410</td>\n",
       "      <td>1.565480</td>\n",
       "      <td>0.885051</td>\n",
       "      <td>0.858706</td>\n",
       "      <td>0.868724</td>\n",
       "      <td>0.891888</td>\n",
       "      <td>0.883566</td>\n",
       "      <td>0.883438</td>\n",
       "      <td>0.884706</td>\n",
       "      <td>0.896242</td>\n",
       "      <td>0.892569</td>\n",
       "      <td>0.882311</td>\n",
       "      <td>0.894441</td>\n",
       "      <td>0.902026</td>\n",
       "      <td>0.878060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21314</th>\n",
       "      <td>2.922410</td>\n",
       "      <td>0.688221</td>\n",
       "      <td>0.769550</td>\n",
       "      <td>0.728820</td>\n",
       "      <td>0.753540</td>\n",
       "      <td>0.768248</td>\n",
       "      <td>0.769522</td>\n",
       "      <td>0.726269</td>\n",
       "      <td>0.762803</td>\n",
       "      <td>0.746050</td>\n",
       "      <td>0.752319</td>\n",
       "      <td>0.741825</td>\n",
       "      <td>0.746923</td>\n",
       "      <td>0.769119</td>\n",
       "      <td>0.761461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80056</th>\n",
       "      <td>11.105200</td>\n",
       "      <td>1.525710</td>\n",
       "      <td>1.006470</td>\n",
       "      <td>1.004394</td>\n",
       "      <td>1.006727</td>\n",
       "      <td>1.001772</td>\n",
       "      <td>1.006757</td>\n",
       "      <td>1.021759</td>\n",
       "      <td>1.005224</td>\n",
       "      <td>0.985353</td>\n",
       "      <td>0.995334</td>\n",
       "      <td>0.984537</td>\n",
       "      <td>1.003321</td>\n",
       "      <td>0.998751</td>\n",
       "      <td>1.010067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80605</th>\n",
       "      <td>11.192800</td>\n",
       "      <td>0.225864</td>\n",
       "      <td>1.081130</td>\n",
       "      <td>1.075129</td>\n",
       "      <td>1.091479</td>\n",
       "      <td>1.081034</td>\n",
       "      <td>1.079776</td>\n",
       "      <td>1.089211</td>\n",
       "      <td>1.080716</td>\n",
       "      <td>1.065497</td>\n",
       "      <td>1.075046</td>\n",
       "      <td>1.089168</td>\n",
       "      <td>1.088583</td>\n",
       "      <td>1.088341</td>\n",
       "      <td>1.076771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58260</th>\n",
       "      <td>8.065860</td>\n",
       "      <td>0.334439</td>\n",
       "      <td>1.072220</td>\n",
       "      <td>1.048927</td>\n",
       "      <td>1.054813</td>\n",
       "      <td>1.058725</td>\n",
       "      <td>1.068799</td>\n",
       "      <td>1.058819</td>\n",
       "      <td>1.063557</td>\n",
       "      <td>1.071009</td>\n",
       "      <td>1.089727</td>\n",
       "      <td>1.047257</td>\n",
       "      <td>1.053642</td>\n",
       "      <td>1.077645</td>\n",
       "      <td>1.064737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71381</th>\n",
       "      <td>9.906980</td>\n",
       "      <td>0.118532</td>\n",
       "      <td>1.080140</td>\n",
       "      <td>1.081668</td>\n",
       "      <td>1.090771</td>\n",
       "      <td>1.077115</td>\n",
       "      <td>1.086791</td>\n",
       "      <td>1.091616</td>\n",
       "      <td>1.086718</td>\n",
       "      <td>1.089412</td>\n",
       "      <td>1.099325</td>\n",
       "      <td>1.110148</td>\n",
       "      <td>1.092879</td>\n",
       "      <td>1.076817</td>\n",
       "      <td>1.083865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90654 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               X         Y      Pr_t  Pr_t_model1  Pr_t_model2  Pr_t_model3  \\\n",
       "61043   8.445770  1.459900  0.941288     0.952879     0.943810     0.948880   \n",
       "84851  11.777300  0.604984  0.876677     0.882014     0.880476     0.883672   \n",
       "69613   9.643960  1.615110  1.050250     1.044785     1.053393     1.041060   \n",
       "11892   1.607330  1.982250  0.943615     0.953676     0.938032     0.958043   \n",
       "38313   5.260340  1.973670  0.950802     0.943151     0.962912     0.927510   \n",
       "48236   6.663100  0.266621  1.197980     1.196175     1.202818     1.151249   \n",
       "80116  11.105200  1.931750  1.035210     1.035259     1.044752     1.040893   \n",
       "14216   1.928790  1.949010  0.919665     0.921209     0.914899     0.940598   \n",
       "51797   7.159910  0.322335  1.154720     1.152172     1.141388     1.144469   \n",
       "82811  11.485100  1.760940  1.099280     1.096786     1.091541     1.094371   \n",
       "16295   2.221030  1.743920  0.932989     0.936309     0.940408     0.924710   \n",
       "37392   5.143440  1.511790  0.781052     0.796403     0.793003     0.776096   \n",
       "80237  11.134400  0.777315  0.895635     0.945127     0.889781     0.891626   \n",
       "11408   1.548880  1.686640  0.928483     0.933877     0.934936     0.934770   \n",
       "39144   5.377240  1.945620  0.941884     0.943467     0.944330     0.930272   \n",
       "35812   4.938880  0.155351  0.876913     0.882664     0.887981     0.877622   \n",
       "84640  11.748100  0.605609  0.878620     0.884949     0.882736     0.885633   \n",
       "18578   2.542500  1.235800  0.694338     0.696837     0.678397     0.693290   \n",
       "3928    0.526034  1.211510  0.910278     0.857995     0.880108     0.896055   \n",
       "20472   2.805520  0.737260  0.752250     0.701056     0.732210     0.748482   \n",
       "76791  10.666800  0.002269  1.100270     1.099077     1.126818     1.107626   \n",
       "21302   2.922410  0.543589  0.805431     0.795784     0.797863     0.798497   \n",
       "25482   3.506890  0.134202  0.891762     0.897983     0.903026     0.895110   \n",
       "45193   6.224740  1.677720  0.918831     0.919094     0.913721     0.893954   \n",
       "51573   7.130680  0.225792  1.074210     1.067354     1.084244     1.087965   \n",
       "33545   4.617410  0.449243  0.829803     0.832630     0.834006     0.833467   \n",
       "45199   6.224740  1.724460  0.945270     0.943938     0.942026     0.916476   \n",
       "7885    1.081290  0.034449  0.842284     0.858245     0.854267     0.832743   \n",
       "49868   6.896890  0.101745  1.442880     1.421224     1.446862     1.403169   \n",
       "17997   2.454830  1.786020  0.930817     0.928872     0.938380     0.924210   \n",
       "...          ...       ...       ...          ...          ...          ...   \n",
       "21287   2.922410  0.387273  0.869073     0.859839     0.865828     0.870461   \n",
       "45256   6.224740  1.981250  1.005730     0.990274     1.014590     0.985202   \n",
       "9115    1.227410  1.920390  0.925797     0.927199     0.937922     0.923548   \n",
       "82559  11.455900  1.361220  0.985317     0.978791     0.978614     0.974327   \n",
       "32163   4.412840  1.816850  0.913729     0.907638     0.917836     0.906418   \n",
       "85480  11.865000  0.565138  0.882272     0.873699     0.885062     0.884109   \n",
       "41623   5.727930  1.736880  0.922363     0.911264     0.916544     0.895591   \n",
       "73771  10.228400  1.421120  0.982098     0.972533     0.970160     0.966410   \n",
       "23023   3.156200  1.256190  0.684525     0.692622     0.674849     0.684527   \n",
       "11708   1.607330  0.059033  0.866467     0.876558     0.873297     0.855212   \n",
       "57768   7.978180  1.938410  1.050530     1.050905     1.068079     1.033776   \n",
       "60652   8.387320  1.715030  1.073190     1.070988     1.084028     1.072301   \n",
       "15149   2.074910  0.384982  0.855641     0.854963     0.853439     0.852313   \n",
       "8275    1.110520  1.954640  0.933711     0.928422     0.923867     0.955603   \n",
       "78762  10.929800  0.623121  0.911927     0.927079     0.913571     0.917140   \n",
       "4551    0.613706  0.627104  0.725950     0.712449     0.727638     0.721983   \n",
       "39002   5.377240  0.314563  0.871159     0.869120     0.876536     0.861486   \n",
       "20873   2.863960  0.486844  0.819296     0.812309     0.816914     0.811907   \n",
       "43685   6.020170  1.338960  0.752117     0.724343     0.728587     0.741552   \n",
       "41857   5.757150  1.877300  0.933367     0.926096     0.937188     0.940631   \n",
       "88560  12.303400 -0.029220  1.148540     1.149764     1.126843     1.131161   \n",
       "18739   2.571720  0.274245  0.921221     0.911020     0.920932     0.918676   \n",
       "23445   3.214650  1.230840  0.664806     0.683490     0.655277     0.667175   \n",
       "85268  11.835800  0.541034  0.893393     0.878803     0.896180     0.892481   \n",
       "9062    1.227410  1.565480  0.885051     0.858706     0.868724     0.891888   \n",
       "21314   2.922410  0.688221  0.769550     0.728820     0.753540     0.768248   \n",
       "80056  11.105200  1.525710  1.006470     1.004394     1.006727     1.001772   \n",
       "80605  11.192800  0.225864  1.081130     1.075129     1.091479     1.081034   \n",
       "58260   8.065860  0.334439  1.072220     1.048927     1.054813     1.058725   \n",
       "71381   9.906980  0.118532  1.080140     1.081668     1.090771     1.077115   \n",
       "\n",
       "       Pr_t_model4  Pr_t_model5  Pr_t_model6  Pr_t_model7  Pr_t_model8  \\\n",
       "61043     0.970266     0.979655     0.948912     0.969265     0.962497   \n",
       "84851     0.880458     0.900107     0.882035     0.900853     0.921806   \n",
       "69613     1.040492     1.036874     1.045349     1.058080     1.036525   \n",
       "11892     0.925098     0.938735     0.941899     0.948100     0.935128   \n",
       "38313     0.946043     0.954719     0.960530     0.943175     0.947005   \n",
       "48236     1.192933     1.207349     1.213757     1.217458     1.192869   \n",
       "80116     1.042166     1.043295     1.049647     1.036197     1.042988   \n",
       "14216     0.923133     0.917220     0.928918     0.917534     0.924196   \n",
       "51797     1.155042     1.158755     1.168244     1.162583     1.156581   \n",
       "82811     1.100629     1.102220     1.094628     1.081418     1.100404   \n",
       "16295     0.935573     0.929375     0.942313     0.926071     0.937516   \n",
       "37392     0.793468     0.795877     0.797942     0.802026     0.785395   \n",
       "80237     0.890434     0.938208     0.893615     0.910625     0.932946   \n",
       "11408     0.945278     0.925480     0.929646     0.940314     0.939875   \n",
       "39144     0.949933     0.929807     0.953469     0.936102     0.943263   \n",
       "35812     0.876279     0.871205     0.884830     0.877537     0.874246   \n",
       "84640     0.881792     0.902861     0.883907     0.900695     0.920835   \n",
       "18578     0.691965     0.711152     0.682893     0.698953     0.689215   \n",
       "3928      0.915543     0.872803     0.890122     0.850600     0.847263   \n",
       "20472     0.750986     0.709525     0.744486     0.716035     0.721697   \n",
       "76791     1.102999     1.100525     1.126557     1.108562     1.102311   \n",
       "21302     0.810813     0.794541     0.801724     0.804840     0.804233   \n",
       "25482     0.890492     0.878617     0.904844     0.905500     0.883012   \n",
       "45193     0.921195     0.912020     0.921578     0.929364     0.907693   \n",
       "51573     1.064401     1.062945     1.086897     1.072696     1.085105   \n",
       "33545     0.843210     0.838728     0.842065     0.850251     0.827330   \n",
       "45199     0.948501     0.936012     0.954313     0.949245     0.931088   \n",
       "7885      0.846432     0.836655     0.858630     0.867217     0.843246   \n",
       "49868     1.410003     1.369385     1.412419     1.436414     1.475941   \n",
       "17997     0.933136     0.933123     0.940138     0.918843     0.933147   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "21287     0.873126     0.868256     0.870617     0.866038     0.861000   \n",
       "45256     1.001811     1.010737     1.011644     0.913454     1.026272   \n",
       "9115      0.922709     0.929497     0.926736     0.923068     0.920462   \n",
       "82559     0.983091     0.993476     0.976565     0.936667     0.957112   \n",
       "32163     0.917683     0.903869     0.916995     0.919860     0.918610   \n",
       "85480     0.885349     0.892416     0.886796     0.900006     0.922958   \n",
       "41623     0.916236     0.923138     0.931287     0.919804     0.910594   \n",
       "73771     0.979613     0.990223     0.968483     0.956230     0.970645   \n",
       "23023     0.681558     0.704958     0.674669     0.696001     0.682989   \n",
       "11708     0.869228     0.854747     0.879501     0.886075     0.884677   \n",
       "57768     1.041365     1.032904     1.060078     1.046475     1.049181   \n",
       "60652     1.071295     1.075176     1.081803     1.088609     1.069376   \n",
       "15149     0.862412     0.859572     0.862629     0.844396     0.849308   \n",
       "8275      0.936465     0.925580     0.937236     0.956681     0.925188   \n",
       "78762     0.904710     0.934819     0.913472     0.904409     0.900780   \n",
       "4551      0.731362     0.726399     0.734011     0.807543     0.770360   \n",
       "39002     0.874872     0.871805     0.881553     0.879509     0.876600   \n",
       "20873     0.829721     0.822827     0.823116     0.813377     0.820163   \n",
       "43685     0.767979     0.731589     0.742605     0.758335     0.715946   \n",
       "41857     0.931568     0.930411     0.939313     0.943798     0.928754   \n",
       "88560     1.141511     1.153083     1.138974     1.140499     1.141899   \n",
       "18739     0.924596     0.913957     0.928248     0.911965     0.910194   \n",
       "23445     0.664612     0.700288     0.658334     0.687421     0.672259   \n",
       "85268     0.894584     0.897904     0.896366     0.900082     0.922630   \n",
       "9062      0.883566     0.883438     0.884706     0.896242     0.892569   \n",
       "21314     0.769522     0.726269     0.762803     0.746050     0.752319   \n",
       "80056     1.006757     1.021759     1.005224     0.985353     0.995334   \n",
       "80605     1.079776     1.089211     1.080716     1.065497     1.075046   \n",
       "58260     1.068799     1.058819     1.063557     1.071009     1.089727   \n",
       "71381     1.086791     1.091616     1.086718     1.089412     1.099325   \n",
       "\n",
       "       Pr_t_model9  Pr_t_model10  Pr_t_model11  Pr_t_model12  \n",
       "61043     0.978226      0.976618      0.942965      0.956116  \n",
       "84851     0.915922      0.896533      0.880608      0.894326  \n",
       "69613     1.040968      1.046795      1.042910      1.039833  \n",
       "11892     0.959363      0.939401      0.975637      0.940601  \n",
       "38313     0.958799      0.946367      0.950820      0.953489  \n",
       "48236     1.205963      1.204781      1.186584      1.213202  \n",
       "80116     1.094417      1.037700      1.039002      1.032696  \n",
       "14216     0.946036      0.921255      0.921013      0.917140  \n",
       "51797     1.144906      1.171846      1.156136      1.163035  \n",
       "82811     1.099430      1.094880      1.093860      1.101269  \n",
       "16295     0.939750      0.931719      0.935166      0.943353  \n",
       "37392     0.771671      0.785947      0.776986      0.788064  \n",
       "80237     0.983472      0.911891      0.894016      0.904901  \n",
       "11408     0.938675      0.919065      0.933583      0.937318  \n",
       "39144     0.993894      0.936559      0.939395      0.938890  \n",
       "35812     0.904863      0.874278      0.865272      0.873887  \n",
       "84640     0.918683      0.898999      0.882160      0.896448  \n",
       "18578     0.732949      0.711331      0.696858      0.682437  \n",
       "3928      0.861335      0.880019      0.882102      0.894474  \n",
       "20472     0.726881      0.732929      0.751853      0.741640  \n",
       "76791     1.142576      1.115689      1.099783      1.113449  \n",
       "21302     0.814926      0.801513      0.795263      0.804267  \n",
       "25482     0.931439      0.889604      0.883717      0.890345  \n",
       "45193     0.926219      0.925783      0.893954      0.918510  \n",
       "51573     1.166564      1.094615      1.085779      1.084419  \n",
       "33545     0.827005      0.854972      0.835360      0.837707  \n",
       "45199     0.955453      0.950453      0.917068      0.943623  \n",
       "7885      0.877239      0.856647      0.827416      0.836962  \n",
       "49868     1.324873      1.392234      1.375569      1.440983  \n",
       "17997     0.936675      0.934419      0.943510      0.939461  \n",
       "...            ...           ...           ...           ...  \n",
       "21287     0.876409      0.889483      0.856353      0.864963  \n",
       "45256     1.017385      0.995797      1.008737      0.995340  \n",
       "9115      0.978710      0.938409      0.934900      0.921208  \n",
       "82559     0.972089      0.976420      0.966906      0.984187  \n",
       "32163     0.934746      0.908356      0.904422      0.910798  \n",
       "85480     0.896356      0.895434      0.877926      0.896913  \n",
       "41623     0.932626      0.924878      0.899534      0.915319  \n",
       "73771     0.977655      0.983272      0.958167      0.979435  \n",
       "23023     0.723489      0.704223      0.687906      0.672488  \n",
       "11708     0.883775      0.878190      0.865441      0.864448  \n",
       "57768     1.117430      1.045644      1.045272      1.043252  \n",
       "60652     1.116461      1.084766      1.062548      1.072189  \n",
       "15149     0.890304      0.874212      0.842182      0.851411  \n",
       "8275      0.948909      0.922961      0.941741      0.930539  \n",
       "78762     0.944330      0.924913      0.908132      0.925622  \n",
       "4551      0.707851      0.737095      0.739640      0.729204  \n",
       "39002     0.901674      0.869388      0.865524      0.869167  \n",
       "20873     0.844408      0.829648      0.809215      0.820891  \n",
       "43685     0.767208      0.744350      0.748239      0.738745  \n",
       "41857     0.993958      0.945311      0.930172      0.928231  \n",
       "88560     1.158038      1.141375      1.138751      1.154409  \n",
       "18739     0.900160      0.935558      0.910472      0.921105  \n",
       "23445     0.725366      0.698185      0.671710      0.655006  \n",
       "85268     0.896562      0.903992      0.883280      0.906299  \n",
       "9062      0.882311      0.894441      0.902026      0.878060  \n",
       "21314     0.741825      0.746923      0.769119      0.761461  \n",
       "80056     0.984537      1.003321      0.998751      1.010067  \n",
       "80605     1.089168      1.088583      1.088341      1.076771  \n",
       "58260     1.047257      1.053642      1.077645      1.064737  \n",
       "71381     1.110148      1.092879      1.076817      1.083865  \n",
       "\n",
       "[90654 rows x 15 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = pd.read_csv(r'D:\\Desktop\\SynologyDrive\\Outline\\Youngjae Kim\\figures\\Figure19-22\\channel_evaluation_Pr0.7.csv')\n",
    "Data1 = Data.sample(frac=1)\n",
    "# Data1\n",
    "# Data.iloc[Data_index]\n",
    "# Data11 = Data.loc[random.shuffle(Data.index.values)]\n",
    "# Data11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               X         Y      Pr_t  Pr_t_model1  Pr_t_model2  Pr_t_model3  \\\n",
      "0      10.637600  0.204314  1.088040     1.078359     1.090431     1.081412   \n",
      "1       5.640250  1.922210  0.941633     0.931841     0.947053     0.924275   \n",
      "2       8.416550  0.172632  1.071920     1.062873     1.071120     1.070688   \n",
      "3       2.834740  0.031426  0.913523     0.914973     0.923204     0.908866   \n",
      "4      10.433000  0.278425  1.043610     1.061031     1.055906     1.058997   \n",
      "5       5.289570  0.243217  0.857817     0.863723     0.864485     0.862467   \n",
      "6       0.584482  1.279020  0.886633     0.870646     0.874085     0.893604   \n",
      "7       1.022840  1.877350  0.947828     0.948409     0.952959     0.939076   \n",
      "8      12.069600  0.664256  0.839418     0.856340     0.833674     0.845372   \n",
      "9      11.981900  1.772970  1.078570     1.081381     1.077057     1.079804   \n",
      "10      4.412840  0.782131  0.748496     0.734644     0.728065     0.738732   \n",
      "11      1.870340  1.815300  0.944169     0.940269     0.946123     0.930051   \n",
      "12      3.945260  1.593330  0.824854     0.820462     0.818835     0.816862   \n",
      "13     10.374600  0.538283  0.934564     0.936300     0.929691     0.936167   \n",
      "14      9.497840  0.184822  1.077250     1.072879     1.073379     1.072434   \n",
      "15      9.380940  0.770917  0.933058     0.920007     0.927942     0.921249   \n",
      "16      7.218360  1.448500  0.869421     0.870488     0.863062     0.887479   \n",
      "17      2.805520  0.195711  0.930485     0.935549     0.949646     0.919954   \n",
      "18      5.669480  1.536580  0.804634     0.813690     0.814545     0.794993   \n",
      "19      4.734310  0.619115  0.796581     0.796646     0.794640     0.797457   \n",
      "20      0.029224  1.803810  1.047700     1.041975     1.047699     1.044685   \n",
      "21      1.198190  0.149800  0.942932     0.924564     0.933935     0.935160   \n",
      "22      2.104140  0.202272  0.937835     0.927613     0.947199     0.930207   \n",
      "23      8.241200  0.532456  0.966317     0.957617     0.967166     0.986720   \n",
      "24      5.990940  0.175434  0.803759     0.802848     0.827424     0.806155   \n",
      "25      2.922410  1.894330  0.899920     0.898140     0.908014     0.895860   \n",
      "26      0.233793  1.778530  1.042560     1.034216     1.035782     1.033920   \n",
      "27     10.988300  1.954970  1.052270     1.038994     1.047342     1.064294   \n",
      "28      9.380940  0.384677  1.003480     1.005135     0.996582     0.989914   \n",
      "29      2.951640  0.247097  0.929812     0.924108     0.940846     0.917130   \n",
      "...          ...       ...       ...          ...          ...          ...   \n",
      "30188   6.107840  0.321486  0.841246     0.832818     0.862726     0.828304   \n",
      "30189  11.777300  1.862160  1.051830     1.046601     1.063720     1.043515   \n",
      "30190   0.321465  1.589490  0.967614     0.960983     0.955110     0.980385   \n",
      "30191   0.087672  1.915050  0.971464     0.977571     0.983618     0.980343   \n",
      "30192   4.938880  0.097030  0.906952     0.907966     0.915855     0.907766   \n",
      "30193   8.942580  1.688670  1.082900     1.074751     1.083319     1.072161   \n",
      "30194   8.270430  0.060970  1.182090     1.197637     1.191835     1.183546   \n",
      "30195   6.955340  0.115224  1.267610     1.257285     1.271953     1.302615   \n",
      "30196   9.293270  0.190725  1.073140     1.068558     1.071974     1.070559   \n",
      "30197   5.348010  1.425940  0.748841     0.770100     0.762450     0.752523   \n",
      "30198  10.286900  1.839270  1.083920     1.083159     1.094781     1.081820   \n",
      "30199   1.081290 -0.026214  0.872334     0.863080     0.862927     0.902760   \n",
      "30200   1.461210  1.900560  0.922238     0.926127     0.930695     0.915090   \n",
      "30201   9.001030  1.571370  1.002040     1.012972     1.012466     1.004860   \n",
      "30202   4.295950  0.564246  0.809805     0.798638     0.805353     0.801761   \n",
      "30203   5.435690  0.344750  0.866832     0.854771     0.864740     0.849099   \n",
      "30204  10.812900  0.192401  1.094740     1.083883     1.093415     1.086374   \n",
      "30205   5.289570  0.762029  0.780771     0.787831     0.771652     0.774676   \n",
      "30206   8.621110  1.265540  0.957716     0.933634     0.951606     0.956460   \n",
      "30207   5.494130  1.966020  0.954362     0.945667     0.953815     0.926325   \n",
      "30208   8.884130  0.214564  1.063750     1.054188     1.072608     1.070146   \n",
      "30209   8.416550  0.053909  1.189740     1.205432     1.194718     1.188743   \n",
      "30210   4.179050  0.154278  0.885119     0.892537     0.893153     0.892073   \n",
      "30211  12.274100  1.907210  0.997653     1.003121     1.007717     0.997929   \n",
      "30212   8.533440  0.603299  0.936038     0.932366     0.931088     0.949887   \n",
      "30213  11.865000  0.381012  0.954758     0.951658     0.955414     0.959509   \n",
      "30214   2.133360  1.383450  0.762670     0.765456     0.764339     0.772865   \n",
      "30215   0.584482  0.347312  0.815660     0.818150     0.806737     0.826097   \n",
      "30216  11.280500  0.121355  1.113710     1.100927     1.115831     1.111623   \n",
      "30217   9.439390  0.514842  0.947471     0.944949     0.945221     0.957508   \n",
      "\n",
      "       Pr_t_model4  Pr_t_model5  Pr_t_model6  Pr_t_model7  Pr_t_model8  \\\n",
      "0         1.083326     1.082652     1.086699     1.081677     1.096046   \n",
      "1         0.936188     0.940054     0.942897     0.934815     0.936600   \n",
      "2         1.075405     1.076886     1.071837     1.070271     1.070025   \n",
      "3         0.898603     0.904887     0.928362     0.916237     0.916089   \n",
      "4         1.043394     1.059671     1.050984     1.048589     1.048780   \n",
      "5         0.861856     0.850688     0.871397     0.884607     0.862218   \n",
      "6         0.893595     0.880730     0.879655     0.860068     0.857322   \n",
      "7         0.945530     0.947413     0.954739     0.947894     0.947944   \n",
      "8         0.851364     0.862253     0.843240     0.910039     0.933942   \n",
      "9         1.083691     1.088165     1.080211     1.058412     1.088727   \n",
      "10        0.742710     0.733857     0.742244     0.743389     0.748185   \n",
      "11        0.942318     0.944448     0.945203     0.930946     0.945441   \n",
      "12        0.824391     0.826117     0.825786     0.842414     0.823597   \n",
      "13        0.934502     0.949932     0.934215     0.918021     0.906641   \n",
      "14        1.074475     1.072937     1.073577     1.079433     1.089798   \n",
      "15        0.916718     0.926977     0.930923     0.914252     0.909828   \n",
      "16        0.877190     0.889380     0.873904     0.912791     0.879532   \n",
      "17        0.936073     0.933431     0.932042     0.915347     0.930754   \n",
      "18        0.826824     0.818057     0.819752     0.823146     0.806448   \n",
      "19        0.798496     0.790139     0.797035     0.806170     0.805759   \n",
      "20        1.041024     1.050484     1.045552     1.015273     1.050466   \n",
      "21        0.940475     0.936181     0.949456     0.920847     0.949776   \n",
      "22        0.939723     0.936495     0.951583     0.918486     0.936797   \n",
      "23        0.985084     0.976209     0.969241     0.984814     0.977642   \n",
      "24        0.803621     0.789677     0.798623     0.815135     0.801254   \n",
      "25        0.901717     0.902811     0.908575     0.914366     0.905087   \n",
      "26        1.035141     1.034297     1.041314     1.014346     1.050316   \n",
      "27        1.040339     1.057069     1.049531     1.072105     1.051949   \n",
      "28        0.993230     1.007774     0.993359     0.991084     0.992152   \n",
      "29        0.935663     0.924557     0.936633     0.913670     0.918873   \n",
      "...            ...          ...          ...          ...          ...   \n",
      "30188     0.857311     0.847811     0.865254     0.840521     0.847836   \n",
      "30189     1.048758     1.053325     1.059213     1.038126     1.062978   \n",
      "30190     0.969644     0.975262     0.968018     0.967742     0.953932   \n",
      "30191     0.976652     0.977071     0.977858     0.991736     0.966096   \n",
      "30192     0.920329     0.914820     0.919604     0.923641     0.907451   \n",
      "30193     1.075704     1.074677     1.080410     1.092152     1.061556   \n",
      "30194     1.177952     1.186506     1.182846     1.170429     1.188421   \n",
      "30195     1.281693     1.316797     1.263774     1.270135     1.257615   \n",
      "30196     1.069981     1.068118     1.070544     1.075508     1.086671   \n",
      "30197     0.763156     0.760365     0.762813     0.756811     0.744533   \n",
      "30198     1.079113     1.086044     1.090438     1.082977     1.083368   \n",
      "30199     0.870342     0.872807     0.863167     0.878917     0.866497   \n",
      "30200     0.922339     0.927240     0.926022     0.926789     0.924269   \n",
      "30201     1.015587     1.017802     1.008077     1.022865     1.017271   \n",
      "30202     0.811404     0.803140     0.808206     0.809773     0.803637   \n",
      "30203     0.861090     0.857356     0.870882     0.872233     0.870186   \n",
      "30204     1.089958     1.087357     1.091135     1.090368     1.104329   \n",
      "30205     0.783197     0.767021     0.784536     0.777681     0.774997   \n",
      "30206     0.964962     0.942311     0.959593     0.934806     0.936501   \n",
      "30207     0.947246     0.957515     0.955794     0.953424     0.948034   \n",
      "30208     1.059825     1.054976     1.067821     1.064267     1.076847   \n",
      "30209     1.190286     1.181267     1.194188     1.177871     1.198197   \n",
      "30210     0.886066     0.871646     0.896969     0.898414     0.884717   \n",
      "30211     1.001524     0.999749     1.001445     1.013710     0.992736   \n",
      "30212     0.947230     0.950141     0.938623     0.950594     0.934979   \n",
      "30213     0.951278     0.941815     0.945576     0.969966     0.969493   \n",
      "30214     0.772345     0.765645     0.762449     0.768147     0.767659   \n",
      "30215     0.800608     0.819189     0.817449     0.863624     0.815961   \n",
      "30216     1.112861     1.117709     1.110796     1.124143     1.121533   \n",
      "30217     0.959363     0.960877     0.949489     0.942920     0.935534   \n",
      "\n",
      "       Pr_t_model9  Pr_t_model10  Pr_t_model11  Pr_t_model12  \n",
      "0         1.096637      1.087409      1.087702      1.081214  \n",
      "1         0.958260      0.940709      0.936913      0.932251  \n",
      "2         1.097664      1.071971      1.066075      1.063696  \n",
      "3         0.921012      0.906078      0.917653      0.911426  \n",
      "4         1.094023      1.060140      1.056326      1.040548  \n",
      "5         0.880140      0.867291      0.852822      0.847868  \n",
      "6         0.867724      0.885377      0.878527      0.886832  \n",
      "7         0.954579      0.947180      0.955049      0.945831  \n",
      "8         0.901232      0.856335      0.854395      0.851534  \n",
      "9         1.077672      1.082130      1.078397      1.081466  \n",
      "10        0.740389      0.734496      0.748520      0.735960  \n",
      "11        0.945867      0.937963      0.953237      0.946488  \n",
      "12        0.812754      0.833635      0.821166      0.816946  \n",
      "13        0.933762      0.936090      0.925414      0.939959  \n",
      "14        1.112577      1.078558      1.073252      1.072516  \n",
      "15        0.966956      0.917290      0.920649      0.922963  \n",
      "16        0.887370      0.888971      0.885221      0.878862  \n",
      "17        0.885231      0.936435      0.919862      0.935964  \n",
      "18        0.801094      0.816233      0.797472      0.811672  \n",
      "19        0.814213      0.796342      0.794955      0.797445  \n",
      "20        1.022647      1.043675      1.047328      1.043021  \n",
      "21        0.908234      0.929710      0.931472      0.936186  \n",
      "22        0.908893      0.942088      0.924949      0.946475  \n",
      "23        0.973462      0.962424      0.975391      0.970378  \n",
      "24        0.803273      0.812410      0.775371      0.811876  \n",
      "25        0.925119      0.910543      0.901257      0.901819  \n",
      "26        1.038380      1.041904      1.035950      1.035495  \n",
      "27        1.083931      1.039925      1.051706      1.046593  \n",
      "28        1.023713      0.997839      0.994994      0.996261  \n",
      "29        0.886281      0.936922      0.916285      0.939609  \n",
      "...            ...           ...           ...           ...  \n",
      "30188     0.844270      0.853287      0.827481      0.843090  \n",
      "30189     1.057282      1.049674      1.045303      1.050956  \n",
      "30190     0.992527      0.986432      0.977536      0.961929  \n",
      "30191     1.033905      0.975834      0.974479      0.972692  \n",
      "30192     0.918371      0.915803      0.917210      0.907674  \n",
      "30193     1.114393      1.081453      1.073629      1.076476  \n",
      "30194     1.181570      1.189085      1.203904      1.192788  \n",
      "30195     1.260214      1.322609      1.283727      1.280137  \n",
      "30196     1.115746      1.075112      1.069607      1.067883  \n",
      "30197     0.736172      0.753424      0.753419      0.756266  \n",
      "30198     1.098613      1.078854      1.070342      1.084235  \n",
      "30199     0.869505      0.862432      0.855535      0.876314  \n",
      "30200     0.956135      0.926336      0.932836      0.918776  \n",
      "30201     1.011043      1.017633      1.003879      1.004298  \n",
      "30202     0.819413      0.811421      0.796836      0.806891  \n",
      "30203     0.889194      0.855975      0.860147      0.860661  \n",
      "30204     1.094086      1.094202      1.094359      1.090508  \n",
      "30205     0.781017      0.776849      0.774494      0.778574  \n",
      "30206     0.963549      0.940408      0.942984      0.950289  \n",
      "30207     0.976214      0.956270      0.960629      0.952020  \n",
      "30208     1.122838      1.066538      1.065031      1.059027  \n",
      "30209     1.218771      1.191978      1.214763      1.198140  \n",
      "30210     0.936024      0.879172      0.869575      0.883754  \n",
      "30211     1.043010      0.994249      0.996151      0.996422  \n",
      "30212     0.969143      0.940155      0.939108      0.946567  \n",
      "30213     1.011087      0.975803      0.948645      0.947365  \n",
      "30214     0.766587      0.769277      0.769714      0.762823  \n",
      "30215     0.804737      0.815115      0.833999      0.799532  \n",
      "30216     1.101138      1.114879      1.106975      1.115102  \n",
      "30217     0.941153      0.943229      0.948778      0.951349  \n",
      "\n",
      "[30218 rows x 15 columns]\n",
      "               X         Y      Pr_t  Pr_t_model1  Pr_t_model2  Pr_t_model3  \\\n",
      "30218   3.273100  1.218430  0.651067     0.679025     0.643506     0.656927   \n",
      "30219   1.753450  0.013444  0.884949     0.879687     0.881213     0.891857   \n",
      "30220   6.283190  0.307244  1.028450     1.022590     1.061240     1.007147   \n",
      "30221   0.993620  1.500640  0.880112     0.863400     0.865223     0.873989   \n",
      "30222   4.003700  1.967890  0.931102     0.928525     0.930576     0.924044   \n",
      "30223  10.111500  1.639740  1.073770     1.059432     1.071405     1.064046   \n",
      "30224   4.354390  1.944700  0.925412     0.929954     0.931086     0.916225   \n",
      "30225   2.221030  0.256854  0.923476     0.912304     0.923624     0.922615   \n",
      "30226   9.001030  0.145453  1.077010     1.076993     1.080643     1.076312   \n",
      "30227   2.162580  0.397082  0.851830     0.848644     0.848211     0.846707   \n",
      "30228  12.391000  0.049882  1.149440     1.152065     1.163284     1.162033   \n",
      "30229   8.328870  0.631109  0.936558     0.931867     0.930308     0.948166   \n",
      "30230   4.500510  1.805240  0.914607     0.909828     0.919700     0.910898   \n",
      "30231   3.302330  0.061357  0.907789     0.908833     0.914100     0.896126   \n",
      "30232  11.514300  1.297180  0.983437     0.981659     0.978662     0.980221   \n",
      "30233   7.130680  0.375308  1.143290     1.136609     1.148524     1.128232   \n",
      "30234   9.614730  0.044125  1.089680     1.092149     1.104332     1.088235   \n",
      "30235   4.851200  0.073603  0.903974     0.906060     0.909579     0.900796   \n",
      "30236   3.097760  0.141535  0.903256     0.904749     0.914063     0.898070   \n",
      "30237   2.747070  0.346045  0.888878     0.881931     0.886362     0.891404   \n",
      "30238  12.303400 -0.022106  1.141510     1.131594     1.126063     1.128570   \n",
      "30239   5.026550  1.928620  0.928298     0.924534     0.936092     0.912468   \n",
      "30240  10.812900  1.848760  1.077010     1.072794     1.090346     1.075163   \n",
      "30241   7.510600  1.303670  0.893598     0.878633     0.888931     0.900089   \n",
      "30242   9.848530  1.302550  0.963930     0.959125     0.961244     0.968272   \n",
      "30243   9.293270  1.836330  1.084640     1.078282     1.087348     1.075095   \n",
      "30244   8.825680  1.728200  1.086950     1.088035     1.096734     1.089122   \n",
      "30245   8.211980  0.233830  1.063600     1.042838     1.072595     1.070120   \n",
      "30246   3.010080  1.946720  0.915767     0.923323     0.919417     0.923241   \n",
      "30247   2.659390  0.217901  0.932166     0.931490     0.951389     0.921928   \n",
      "...          ...       ...       ...          ...          ...          ...   \n",
      "60406  10.286900  1.542130  1.011970     1.008888     1.012997     1.006327   \n",
      "60407   6.224740  0.134387  0.714187     0.702592     0.720353     0.689432   \n",
      "60408   6.838440  1.722170  0.990114     0.988395     0.994394     0.969427   \n",
      "60409   4.529740  0.087151  0.911601     0.915494     0.919466     0.904955   \n",
      "60410   1.081290 -0.007348  0.853347     0.852930     0.851301     0.866717   \n",
      "60411   4.617410  1.597730  0.826165     0.821196     0.820105     0.812239   \n",
      "60412  10.637600  0.442838  0.953821     0.959951     0.956618     0.953664   \n",
      "60413   3.477670  1.857930  0.902354     0.896049     0.915446     0.892987   \n",
      "60414   4.646630  1.913360  0.916073     0.911929     0.923575     0.902207   \n",
      "60415   1.081290  1.543980  0.888483     0.863551     0.871021     0.888871   \n",
      "60416  10.403800  0.119111  1.092020     1.087543     1.097951     1.087826   \n",
      "60417  10.754500  1.821040  1.088800     1.088769     1.101213     1.088327   \n",
      "60418   3.039310  0.102215  0.891673     0.894351     0.901388     0.892322   \n",
      "60419   4.325170  1.956890  0.929677     0.926059     0.935406     0.917951   \n",
      "60420  10.199200  1.220450  1.000290     0.963724     0.983568     0.984579   \n",
      "60421   5.552580  0.551308  0.809092     0.803860     0.810000     0.815466   \n",
      "60422   6.166290  0.576284  0.923345     0.930235     0.920796     0.939161   \n",
      "60423   0.730603  1.930970  0.941487     0.940509     0.952172     0.952633   \n",
      "60424   0.292241  1.663400  1.008450     0.995770     1.005539     1.027355   \n",
      "60425  12.069600  0.098440  1.145410     1.127457     1.153486     1.149840   \n",
      "60426   8.211980  0.159515  1.073580     1.070781     1.074276     1.078695   \n",
      "60427   5.055770  0.100675  0.903925     0.904099     0.912892     0.905337   \n",
      "60428   8.445770  1.904650  1.053450     1.048291     1.058141     1.041548   \n",
      "60429   3.799140  1.572980  0.812622     0.811595     0.810263     0.808629   \n",
      "60430   2.922410  1.824140  0.913123     0.907554     0.925793     0.906840   \n",
      "60431  11.397400  0.704545  0.887381     0.924418     0.887287     0.895101   \n",
      "60432   3.506890  1.476840  0.771755     0.777627     0.775464     0.773551   \n",
      "60433   0.058448 -0.066802  0.664780     0.677008     0.657522     0.681078   \n",
      "60434  10.170000  0.070144  1.077520     1.072924     1.089787     1.070610   \n",
      "60435   5.815600  1.832210  0.939074     0.947753     0.937720     0.935933   \n",
      "\n",
      "       Pr_t_model4  Pr_t_model5  Pr_t_model6  Pr_t_model7  Pr_t_model8  \\\n",
      "30218     0.653766     0.698256     0.647418     0.683124     0.666909   \n",
      "30219     0.887219     0.873518     0.891081     0.895695     0.890163   \n",
      "30220     1.037466     1.046019     1.065779     0.903571     0.939136   \n",
      "30221     0.871445     0.881951     0.878669     0.885011     0.891865   \n",
      "30222     0.941362     0.931240     0.932817     0.925060     0.925509   \n",
      "30223     1.059657     1.054475     1.066547     1.073551     1.038194   \n",
      "30224     0.929638     0.921866     0.936516     0.913560     0.929646   \n",
      "30225     0.925956     0.919000     0.930566     0.914987     0.915286   \n",
      "30226     1.081759     1.085693     1.080479     1.080093     1.086408   \n",
      "30227     0.858085     0.855640     0.858010     0.838544     0.846935   \n",
      "30228     1.149447     1.156185     1.163078     1.145886     1.160733   \n",
      "30229     0.943927     0.949777     0.939165     0.950186     0.935658   \n",
      "30230     0.919528     0.906209     0.917677     0.920590     0.922073   \n",
      "30231     0.909744     0.901280     0.922399     0.923955     0.907545   \n",
      "30232     0.986782     0.983175     0.977461     0.931528     0.953135   \n",
      "30233     1.129038     1.143572     1.157111     1.167555     1.139508   \n",
      "30234     1.094184     1.087724     1.096002     1.086131     1.084349   \n",
      "30235     0.928674     0.901417     0.909377     0.899425     0.903292   \n",
      "30236     0.903016     0.893258     0.909460     0.919842     0.896281   \n",
      "30237     0.891291     0.884526     0.889926     0.889630     0.877238   \n",
      "30238     1.135191     1.136446     1.136581     1.145435     1.141115   \n",
      "30239     0.929454     0.926792     0.932913     0.919472     0.922561   \n",
      "30240     1.071906     1.079580     1.082930     1.072537     1.081185   \n",
      "30241     0.894205     0.883621     0.907156     0.907631     0.884770   \n",
      "30242     0.975550     0.965663     0.964349     0.938904     0.951742   \n",
      "30243     1.079430     1.080776     1.089247     1.092708     1.082740   \n",
      "30244     1.087231     1.094221     1.094093     1.101737     1.078306   \n",
      "30245     1.050495     1.050432     1.066480     1.062142     1.064890   \n",
      "30246     0.921174     0.916024     0.928644     0.905743     0.929382   \n",
      "30247     0.939536     0.932191     0.943270     0.915109     0.927447   \n",
      "...            ...          ...          ...          ...          ...   \n",
      "60406     1.009071     1.019489     1.008183     1.003578     1.009285   \n",
      "60407     0.730590     0.685208     0.715123     0.742682     0.648552   \n",
      "60408     0.990302     0.982800     0.999338     0.992188     0.995076   \n",
      "60409     0.919380     0.927029     0.926773     0.924172     0.913062   \n",
      "60410     0.853887     0.859629     0.852967     0.851760     0.855371   \n",
      "60411     0.822946     0.828503     0.827003     0.840786     0.828203   \n",
      "60412     0.954279     0.968213     0.953621     0.934051     0.927873   \n",
      "60413     0.905541     0.903098     0.912262     0.910080     0.911021   \n",
      "60414     0.911025     0.917495     0.919703     0.916016     0.907828   \n",
      "60415     0.883104     0.887129     0.887975     0.895241     0.893156   \n",
      "60416     1.096590     1.099855     1.093907     1.099620     1.105429   \n",
      "60417     1.082554     1.093566     1.094519     1.080784     1.092206   \n",
      "60418     0.884921     0.883966     0.899255     0.894285     0.883484   \n",
      "60419     0.936359     0.929127     0.940461     0.931040     0.939904   \n",
      "60420     0.997420     0.960761     0.983269     0.929717     0.947848   \n",
      "60421     0.809027     0.819305     0.815560     0.829665     0.817246   \n",
      "60422     0.940071     0.942463     0.942321     0.815583     0.806022   \n",
      "60423     0.940422     0.944787     0.948065     0.949954     0.932200   \n",
      "60424     1.010796     1.006268     1.010115     1.007791     1.008846   \n",
      "60425     1.145779     1.148525     1.150597     1.138195     1.151473   \n",
      "60426     1.077219     1.086180     1.074144     1.073899     1.070791   \n",
      "60427     0.919575     0.909517     0.916841     0.921884     0.904448   \n",
      "60428     1.050838     1.051542     1.054927     1.064705     1.053871   \n",
      "60429     0.816648     0.817153     0.816783     0.832925     0.815317   \n",
      "60430     0.919122     0.915513     0.925051     0.912626     0.922797   \n",
      "60431     0.887035     0.926381     0.888778     0.905338     0.922294   \n",
      "60432     0.778484     0.775304     0.775882     0.789900     0.774128   \n",
      "60433     0.639123     0.633913     0.669924     1.104193     0.935067   \n",
      "60434     1.072452     1.071163     1.082282     1.082991     1.082987   \n",
      "60435     0.936033     0.938360     0.940517     0.945619     0.934142   \n",
      "\n",
      "       Pr_t_model9  Pr_t_model10  Pr_t_model11  Pr_t_model12  \n",
      "30218     0.728675      0.694862      0.661538      0.643792  \n",
      "30219     0.917551      0.878774      0.895009      0.888863  \n",
      "30220     1.055774      1.041930      0.996534      1.037019  \n",
      "30221     0.871151      0.897260      0.882919      0.876368  \n",
      "30222     0.958308      0.926292      0.941141      0.925218  \n",
      "30223     1.075277      1.060715      1.070247      1.064606  \n",
      "30224     0.979159      0.922409      0.922378      0.920783  \n",
      "30225     0.921742      0.938615      0.910407      0.923562  \n",
      "30226     1.101622      1.082328      1.067625      1.071005  \n",
      "30227     0.884702      0.868875      0.837437      0.847043  \n",
      "30228     1.172836      1.169104      1.145095      1.158392  \n",
      "30229     0.980259      0.941451      0.935683      0.946814  \n",
      "30230     0.940477      0.910505      0.905179      0.910328  \n",
      "30231     0.942229      0.904416      0.902141      0.906821  \n",
      "30232     0.979332      0.968075      0.970337      0.984392  \n",
      "30233     1.142482      1.147652      1.146771      1.141069  \n",
      "30234     1.121832      1.083256      1.095743      1.098961  \n",
      "30235     0.910423      0.901829      0.888869      0.901320  \n",
      "30236     0.917867      0.908517      0.906836      0.897382  \n",
      "30237     0.884381      0.909456      0.877137      0.884084  \n",
      "30238     1.162569      1.127381      1.129184      1.144123  \n",
      "30239     0.952617      0.923245      0.926660      0.919263  \n",
      "30240     1.087522      1.075573      1.066081      1.078354  \n",
      "30241     0.920701      0.889371      0.885028      0.885692  \n",
      "30242     0.973071      0.959212      0.955297      0.971005  \n",
      "30243     1.118094      1.075058      1.069795      1.080145  \n",
      "30244     1.122626      1.097484      1.077250      1.089195  \n",
      "30245     1.124869      1.064486      1.068389      1.056940  \n",
      "30246     0.967792      0.920934      0.916591      0.915170  \n",
      "30247     0.890348      0.940059      0.919621      0.946496  \n",
      "...            ...           ...           ...           ...  \n",
      "60406     0.996207      1.012821      1.002915      1.008809  \n",
      "60407     0.707410      0.683323      0.671637      0.723952  \n",
      "60408     1.006904      0.981614      0.968817      0.986367  \n",
      "60409     0.915614      0.912224      0.919267      0.908420  \n",
      "60410     0.892856      0.845988      0.858362      0.854416  \n",
      "60411     0.808118      0.833056      0.814756      0.818833  \n",
      "60412     0.978234      0.963753      0.945018      0.959085  \n",
      "60413     0.914974      0.905982      0.906756      0.900880  \n",
      "60414     0.953978      0.911527      0.913497      0.912275  \n",
      "60415     0.881492      0.898908      0.898880      0.881967  \n",
      "60416     1.103022      1.096882      1.088947      1.095717  \n",
      "60417     1.102879      1.082579      1.078241      1.089869  \n",
      "60418     0.912732      0.889359      0.880077      0.890945  \n",
      "60419     0.970117      0.923253      0.928302      0.916195  \n",
      "60420     0.954293      0.951956      0.972529      0.977564  \n",
      "60421     0.846055      0.832912      0.802946      0.808598  \n",
      "60422     0.973869      0.965466      0.919176      0.934368  \n",
      "60423     0.991480      0.958904      0.946725      0.935506  \n",
      "60424     1.046518      1.017044      1.007452      1.006792  \n",
      "60425     1.125473      1.138825      1.126444      1.138722  \n",
      "60426     1.106426      1.080925      1.067328      1.063408  \n",
      "60427     0.913428      0.913639      0.914901      0.904867  \n",
      "60428     1.111547      1.051672      1.058462      1.042059  \n",
      "60429     0.804512      0.823411      0.811291      0.808166  \n",
      "60430     0.916089      0.914267      0.926216      0.918665  \n",
      "60431     0.962283      0.909735      0.896140      0.904275  \n",
      "60432     0.767721      0.773233      0.771652      0.772136  \n",
      "60433     0.716446      0.678196      0.667014      0.628432  \n",
      "60434     1.099541      1.086694      1.077109      1.083043  \n",
      "60435     0.973546      0.939182      0.940192      0.928783  \n",
      "\n",
      "[30218 rows x 15 columns]\n",
      "               X         Y      Pr_t  Pr_t_model1  Pr_t_model2  Pr_t_model3  \\\n",
      "60436   4.500510  0.098421  0.905624     0.906614     0.912623     0.890567   \n",
      "60437  11.777300  0.352482  0.976182     0.983376     0.984595     0.984521   \n",
      "60438   5.231120  0.748503  0.780983     0.790331     0.772851     0.777791   \n",
      "60439   3.039310  1.980250  0.924267     0.929894     0.935070     0.923219   \n",
      "60440   7.715170  0.679965  0.961955     0.956403     0.956160     0.964082   \n",
      "60441   8.533440  0.055231  1.163850     1.177377     1.170922     1.169363   \n",
      "60442  12.157200  1.507130  0.988944     0.990456     0.983278     0.981639   \n",
      "60443   1.285860  0.020468  0.851934     0.849863     0.843359     0.845720   \n",
      "60444   5.932500  0.365723  0.845829     0.828510     0.854151     0.833360   \n",
      "60445   4.705080  1.855710  0.908683     0.906815     0.915562     0.900859   \n",
      "60446   2.893190  1.746620  0.919364     0.917733     0.924211     0.912876   \n",
      "60447  10.783700  1.538560  1.012530     1.009252     1.013310     1.007742   \n",
      "60448  11.105200  1.262580  0.990680     0.978138     0.979363     0.983363   \n",
      "60449   6.429310  0.172495  1.099000     1.087042     1.127522     1.114011   \n",
      "60450   0.701379  1.476130  0.900027     0.893877     0.889290     0.895010   \n",
      "60451   4.003700  1.784840  0.914372     0.909507     0.922169     0.911076   \n",
      "60452  11.339000  0.528049  0.922439     0.920696     0.927061     0.919872   \n",
      "60453   6.400080  1.919240  0.972861     0.959282     0.975947     0.950038   \n",
      "60454   3.653010  1.489010  0.773808     0.782005     0.779131     0.775469   \n",
      "60455   6.224740  0.151757  0.755398     0.733542     0.737719     0.760408   \n",
      "60456   9.906980  1.943180  1.063330     1.055373     1.075281     1.056700   \n",
      "60457   2.980860  0.361111  0.881558     0.874663     0.879669     0.886003   \n",
      "60458   0.467586  1.944570  0.950483     0.951174     0.949764     0.982251   \n",
      "60459   8.825680  0.608346  0.932177     0.927516     0.924331     0.943080   \n",
      "60460   7.452150  0.123849  1.120470     1.101564     1.133379     1.088987   \n",
      "60461   9.380940  0.631814  0.923040     0.921304     0.916043     0.931318   \n",
      "60462   1.870340  1.654230  0.892472     0.893293     0.893522     0.907568   \n",
      "60463   9.965420  1.326540  0.959995     0.961764     0.958785     0.965119   \n",
      "60464   8.621110  1.803480  1.087260     1.078060     1.089448     1.070919   \n",
      "60465   3.273100  0.351032  0.887723     0.880955     0.884563     0.891406   \n",
      "...          ...       ...       ...          ...          ...          ...   \n",
      "90624   0.350689  1.979400  0.988714     1.006250     0.993366     1.029440   \n",
      "90625   6.604650  0.366519  1.255130     1.235795     1.244699     1.228433   \n",
      "90626  10.403800  0.141056  1.094780     1.088746     1.091815     1.091528   \n",
      "90627   2.045690  0.055426  0.879014     0.874569     0.875048     0.874332   \n",
      "90628   6.283190  0.519462  1.003550     1.009788     1.000294     1.027070   \n",
      "90629   3.623790  1.209690  0.629178     0.674192     0.627437     0.643320   \n",
      "90630   0.642931 -0.048475  0.833823     0.825493     0.813893     0.921649   \n",
      "90631   3.623790  1.847970  0.905349     0.897280     0.917434     0.895461   \n",
      "90632   0.905948  1.944940  0.936187     0.934946     0.929503     0.962728   \n",
      "90633  11.894200  1.226780  1.017800     0.978389     0.994986     0.998650   \n",
      "90634  10.520700  0.174008  1.095120     1.086104     1.088128     1.085878   \n",
      "90635   6.838440  0.261561  1.155950     1.160534     1.146950     1.128794   \n",
      "90636  11.485100  0.340181  0.992963     1.011119     1.004868     1.001151   \n",
      "90637  12.244900  1.262880  0.987188     0.969300     0.979310     0.985820   \n",
      "90638   4.938880  1.422070  0.744981     0.768474     0.757943     0.749502   \n",
      "90639   5.815600  0.326756  0.832736     0.822784     0.845817     0.832157   \n",
      "90640   0.613706  1.752090  1.017330     1.014666     1.019768     0.998363   \n",
      "90641   7.627490  0.693795  0.969082     0.963400     0.964136     0.966622   \n",
      "90642  12.537100 -0.046571  1.176830     1.167669     1.153921     1.196453   \n",
      "90643   8.767240  0.205904  1.065420     1.055439     1.071910     1.068932   \n",
      "90644  12.303400  0.136518  1.117710     1.127716     1.128740     1.117021   \n",
      "90645   9.673180  1.767610  1.098560     1.099157     1.104746     1.090888   \n",
      "90646   0.438362  1.960240  0.958735     0.953188     0.956351     0.982167   \n",
      "90647   5.494130  1.783660  0.928820     0.923758     0.931189     0.924749   \n",
      "90648   8.270430  0.076985  1.127430     1.135163     1.142525     1.130245   \n",
      "90649  12.332600  1.850560  1.036740     1.033260     1.048161     1.032131   \n",
      "90650   1.928790  1.241660  0.732642     0.724021     0.708486     0.729336   \n",
      "90651   0.526034  1.251890  0.901297     0.870954     0.883389     0.901618   \n",
      "90652   7.393700  1.846570  1.022670     1.019729     1.032799     1.039607   \n",
      "90653  10.696000  0.314140  1.023150     1.045573     1.029124     1.028641   \n",
      "\n",
      "       Pr_t_model4  Pr_t_model5  Pr_t_model6  Pr_t_model7  Pr_t_model8  \\\n",
      "60436     0.915472     0.916428     0.923373     0.917558     0.905771   \n",
      "60437     0.971456     0.964921     0.968694     0.999134     0.987886   \n",
      "60438     0.784105     0.767236     0.784296     0.782598     0.782073   \n",
      "60439     0.923805     0.928517     0.930699     0.936981     0.917173   \n",
      "60440     0.964891     0.972868     0.967602     0.956392     0.955924   \n",
      "60441     1.165687     1.175197     1.165099     1.153151     1.166133   \n",
      "60442     0.989353     1.007789     0.991484     0.963542     0.969578   \n",
      "60443     0.851976     0.848544     0.851122     0.844461     0.845997   \n",
      "60444     0.848812     0.825516     0.856804     0.844760     0.858892   \n",
      "60445     0.906637     0.902080     0.912327     0.916283     0.912406   \n",
      "60446     0.916759     0.916520     0.926911     0.919222     0.926980   \n",
      "60447     1.011272     1.022903     1.010548     0.996440     1.004064   \n",
      "60448     0.990358     0.976162     0.976325     0.930673     0.955236   \n",
      "60449     1.087789     1.087656     1.117029     1.081734     1.096000   \n",
      "60450     0.893524     0.909460     0.898952     0.899022     0.912326   \n",
      "60451     0.916299     0.910068     0.919864     0.918697     0.923163   \n",
      "60452     0.917623     0.931583     0.923262     0.904389     0.910270   \n",
      "60453     0.958533     0.971675     0.972625     0.967121     0.976415   \n",
      "60454     0.782853     0.779549     0.780134     0.795163     0.778650   \n",
      "60455     0.783102     0.752291     0.764145     0.773513     0.739204   \n",
      "60456     1.056765     1.065006     1.071843     1.050259     1.072786   \n",
      "60457     0.884733     0.879069     0.883283     0.884789     0.871241   \n",
      "60458     0.955755     0.952661     0.964510     0.976111     0.950539   \n",
      "60459     0.938831     0.944306     0.932682     0.940724     0.922970   \n",
      "60460     1.110571     1.145084     1.120830     1.120980     1.136716   \n",
      "60461     0.921580     0.936677     0.923418     0.925061     0.907252   \n",
      "60462     0.909586     0.891026     0.895909     0.914319     0.898739   \n",
      "60463     0.973032     0.969998     0.961689     0.941632     0.955326   \n",
      "60464     1.076390     1.074212     1.084307     1.098944     1.080484   \n",
      "60465     0.888612     0.882645     0.888833     0.892662     0.879196   \n",
      "...            ...          ...          ...          ...          ...   \n",
      "90624     0.996116     0.981833     0.985961     0.951343     0.966200   \n",
      "90625     1.247512     1.244906     1.258442     1.159649     1.216348   \n",
      "90626     1.097462     1.099474     1.094813     1.100621     1.101861   \n",
      "90627     0.873116     0.873481     0.885244     0.877982     0.875010   \n",
      "90628     1.024086     1.017175     1.031008     0.853455     0.862404   \n",
      "90629     0.638440     0.696516     0.631488     0.678448     0.659932   \n",
      "90630     0.845678     0.848102     0.826804     0.846638     0.840714   \n",
      "90631     0.907650     0.903916     0.913737     0.911015     0.915140   \n",
      "90632     0.939196     0.935123     0.944718     0.957010     0.931839   \n",
      "90633     1.014567     0.965652     0.998775     0.920709     0.937831   \n",
      "90634     1.090278     1.089869     1.088383     1.097378     1.104706   \n",
      "90635     1.157396     1.163422     1.165239     1.176553     1.162251   \n",
      "90636     0.987082     0.989956     0.988186     1.008080     0.995112   \n",
      "90637     0.998503     0.956516     0.985180     0.902296     0.914295   \n",
      "90638     0.754518     0.754264     0.756895     0.758748     0.744890   \n",
      "90639     0.842223     0.823112     0.851172     0.846042     0.840315   \n",
      "90640     1.024230     1.015924     1.020825     0.997126     1.024344   \n",
      "90641     0.969691     0.978006     0.975488     0.955400     0.959478   \n",
      "90642     1.166499     1.167142     1.162387     1.199086     1.199142   \n",
      "90643     1.062067     1.057750     1.066412     1.066605     1.078565   \n",
      "90644     1.127049     1.142080     1.120051     1.121894     1.115497   \n",
      "90645     1.091933     1.099754     1.098972     1.108522     1.093314   \n",
      "90646     0.969473     0.958443     0.956534     0.979947     0.953683   \n",
      "90647     0.924079     0.927029     0.932444     0.927699     0.933876   \n",
      "90648     1.132592     1.155944     1.127900     1.113242     1.117468   \n",
      "90649     1.035959     1.036381     1.041510     1.013472     1.036222   \n",
      "90650     0.729844     0.733414     0.720212     0.719767     0.715296   \n",
      "90651     0.909211     0.881958     0.889980     0.858375     0.858030   \n",
      "90652     1.023734     1.019984     1.021556     1.042180     1.033384   \n",
      "90653     1.017554     1.034438     1.020918     1.027933     1.016565   \n",
      "\n",
      "       Pr_t_model9  Pr_t_model10  Pr_t_model11  Pr_t_model12  \n",
      "60436     0.937379      0.902957      0.909633      0.904858  \n",
      "60437     1.053938      1.002999      0.975935      0.966608  \n",
      "60438     0.782843      0.776804      0.777512      0.780800  \n",
      "60439     0.945470      0.924324      0.936521      0.924803  \n",
      "60440     0.992222      0.964913      0.945684      0.965234  \n",
      "60441     1.165152      1.173106      1.179214      1.171359  \n",
      "60442     0.957922      0.989091      0.979395      0.990646  \n",
      "60443     0.897069      0.860630      0.847432      0.850229  \n",
      "60444     0.852074      0.845565      0.830011      0.845205  \n",
      "60445     0.938458      0.909361      0.906406      0.904288  \n",
      "60446     0.920242      0.923448      0.918967      0.921076  \n",
      "60447     0.992149      1.010217      1.004645      1.012654  \n",
      "60448     0.977596      0.961138      0.971323      0.983377  \n",
      "60449     1.135440      1.082070      1.099932      1.111723  \n",
      "60450     0.887330      0.925750      0.899109      0.899135  \n",
      "60451     0.937862      0.915134      0.908142      0.910087  \n",
      "60452     0.934028      0.933998      0.906710      0.933820  \n",
      "60453     0.989645      0.965902      0.959288      0.966033  \n",
      "60454     0.771738      0.777426      0.774263      0.775988  \n",
      "60455     0.752056      0.732505      0.747930      0.745125  \n",
      "60456     1.095085      1.053469      1.061531      1.057279  \n",
      "60457     0.873529      0.903537      0.872513      0.878413  \n",
      "60458     0.994456      0.957089      0.955690      0.952658  \n",
      "60459     0.961387      0.934125      0.932905      0.940725  \n",
      "60460     1.113396      1.126925      1.121084      1.123253  \n",
      "60461     0.956717      0.926744      0.921631      0.931162  \n",
      "60462     0.902499      0.890342      0.912738      0.894212  \n",
      "60463     0.977292      0.963770      0.952922      0.971373  \n",
      "60464     1.114282      1.085545      1.082428      1.080194  \n",
      "60465     0.860739      0.907728      0.883135      0.886983  \n",
      "...            ...           ...           ...           ...  \n",
      "90624     1.002731      1.001019      1.018242      0.976562  \n",
      "90625     1.256113      1.226137      1.236974      1.267510  \n",
      "90626     1.101065      1.095446      1.089966      1.094309  \n",
      "90627     0.882523      0.883580      0.870756      0.879670  \n",
      "90628     1.058043      1.037146      1.000749      1.011728  \n",
      "90629     0.733072      0.690296      0.645960      0.626552  \n",
      "90630     0.871767      0.836089      0.797493      0.820502  \n",
      "90631     0.914594      0.904971      0.908159      0.903608  \n",
      "90632     0.965343      0.939875      0.939415      0.933962  \n",
      "90633     0.971319      0.963292      0.989739      0.994365  \n",
      "90634     1.102581      1.093287      1.087219      1.090069  \n",
      "90635     1.161902      1.176216      1.149991      1.162443  \n",
      "90636     1.075103      1.023516      0.996983      0.986342  \n",
      "90637     0.958527      0.963510      0.977200      0.983145  \n",
      "90638     0.732055      0.746155      0.748868      0.751479  \n",
      "90639     0.874144      0.838098      0.824769      0.829423  \n",
      "90640     1.072449      1.011357      1.002365      1.016354  \n",
      "90641     0.992534      0.969292      0.947810      0.969351  \n",
      "90642     1.187501      1.165146      1.205485      1.167694  \n",
      "90643     1.127886      1.067372      1.062690      1.060140  \n",
      "90644     1.146685      1.124476      1.112666      1.115277  \n",
      "90645     1.133498      1.103635      1.101762      1.102438  \n",
      "90646     0.987226      0.944839      0.973613      0.958749  \n",
      "90647     0.943346      0.925751      0.916322      0.914461  \n",
      "90648     1.131159      1.116717      1.126370      1.139140  \n",
      "90649     1.027859      1.032098      1.030629      1.035785  \n",
      "90650     0.759016      0.736604      0.731140      0.720030  \n",
      "90651     0.869261      0.888712      0.885558      0.895532  \n",
      "90652     1.082434      1.034676      1.031360      1.021259  \n",
      "90653     1.092313      1.042411      1.032242      1.015134  \n",
      "\n",
      "[30218 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# random.shuffle(Data.index.values)\n",
    "Data = pd.read_csv(r'D:\\Desktop\\SynologyDrive\\Outline\\Youngjae Kim\\figures\\Figure19-22\\channel_evaluation_Pr0.7.csv')\n",
    "Data = Data.sample(frac=1)\n",
    "Data.index = [i for i in range(len(Data))]\n",
    "k_fold = KFold(n_splits=3)\n",
    "for train,test in k_fold.split(Data):\n",
    "    print(Data.loc[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Pr_t</th>\n",
       "      <th>Pr_t_model1</th>\n",
       "      <th>Pr_t_model2</th>\n",
       "      <th>Pr_t_model3</th>\n",
       "      <th>Pr_t_model4</th>\n",
       "      <th>Pr_t_model5</th>\n",
       "      <th>Pr_t_model6</th>\n",
       "      <th>Pr_t_model7</th>\n",
       "      <th>Pr_t_model8</th>\n",
       "      <th>Pr_t_model9</th>\n",
       "      <th>Pr_t_model10</th>\n",
       "      <th>Pr_t_model11</th>\n",
       "      <th>Pr_t_model12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.951640</td>\n",
       "      <td>0.254338</td>\n",
       "      <td>0.928889</td>\n",
       "      <td>0.921732</td>\n",
       "      <td>0.937072</td>\n",
       "      <td>0.916585</td>\n",
       "      <td>0.933274</td>\n",
       "      <td>0.921782</td>\n",
       "      <td>0.935286</td>\n",
       "      <td>0.913227</td>\n",
       "      <td>0.917287</td>\n",
       "      <td>0.885746</td>\n",
       "      <td>0.936117</td>\n",
       "      <td>0.915084</td>\n",
       "      <td>0.936218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.221030</td>\n",
       "      <td>1.591760</td>\n",
       "      <td>0.843832</td>\n",
       "      <td>0.836382</td>\n",
       "      <td>0.836184</td>\n",
       "      <td>0.854294</td>\n",
       "      <td>0.852532</td>\n",
       "      <td>0.849262</td>\n",
       "      <td>0.851861</td>\n",
       "      <td>0.863586</td>\n",
       "      <td>0.845549</td>\n",
       "      <td>0.844878</td>\n",
       "      <td>0.854726</td>\n",
       "      <td>0.866640</td>\n",
       "      <td>0.838370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.847499</td>\n",
       "      <td>-0.011170</td>\n",
       "      <td>0.828938</td>\n",
       "      <td>0.835588</td>\n",
       "      <td>0.834346</td>\n",
       "      <td>0.839645</td>\n",
       "      <td>0.826186</td>\n",
       "      <td>0.839774</td>\n",
       "      <td>0.826489</td>\n",
       "      <td>0.819158</td>\n",
       "      <td>0.831623</td>\n",
       "      <td>0.882828</td>\n",
       "      <td>0.831196</td>\n",
       "      <td>0.829582</td>\n",
       "      <td>0.831534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.045690</td>\n",
       "      <td>1.750430</td>\n",
       "      <td>0.939951</td>\n",
       "      <td>0.944121</td>\n",
       "      <td>0.947693</td>\n",
       "      <td>0.929742</td>\n",
       "      <td>0.942745</td>\n",
       "      <td>0.937353</td>\n",
       "      <td>0.950375</td>\n",
       "      <td>0.928401</td>\n",
       "      <td>0.942816</td>\n",
       "      <td>0.949293</td>\n",
       "      <td>0.938103</td>\n",
       "      <td>0.943206</td>\n",
       "      <td>0.952309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.068530</td>\n",
       "      <td>0.017418</td>\n",
       "      <td>0.928960</td>\n",
       "      <td>0.918869</td>\n",
       "      <td>0.934775</td>\n",
       "      <td>0.899026</td>\n",
       "      <td>0.932851</td>\n",
       "      <td>0.923294</td>\n",
       "      <td>0.923584</td>\n",
       "      <td>0.920101</td>\n",
       "      <td>0.920539</td>\n",
       "      <td>0.922265</td>\n",
       "      <td>0.930020</td>\n",
       "      <td>0.907759</td>\n",
       "      <td>0.921722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          X         Y      Pr_t  Pr_t_model1  Pr_t_model2  Pr_t_model3  \\\n",
       "0  2.951640  0.254338  0.928889     0.921732     0.937072     0.916585   \n",
       "1  2.221030  1.591760  0.843832     0.836382     0.836184     0.854294   \n",
       "2  0.847499 -0.011170  0.828938     0.835588     0.834346     0.839645   \n",
       "3  2.045690  1.750430  0.939951     0.944121     0.947693     0.929742   \n",
       "4  3.068530  0.017418  0.928960     0.918869     0.934775     0.899026   \n",
       "\n",
       "   Pr_t_model4  Pr_t_model5  Pr_t_model6  Pr_t_model7  Pr_t_model8  \\\n",
       "0     0.933274     0.921782     0.935286     0.913227     0.917287   \n",
       "1     0.852532     0.849262     0.851861     0.863586     0.845549   \n",
       "2     0.826186     0.839774     0.826489     0.819158     0.831623   \n",
       "3     0.942745     0.937353     0.950375     0.928401     0.942816   \n",
       "4     0.932851     0.923294     0.923584     0.920101     0.920539   \n",
       "\n",
       "   Pr_t_model9  Pr_t_model10  Pr_t_model11  Pr_t_model12  \n",
       "0     0.885746      0.936117      0.915084      0.936218  \n",
       "1     0.844878      0.854726      0.866640      0.838370  \n",
       "2     0.882828      0.831196      0.829582      0.831534  \n",
       "3     0.949293      0.938103      0.943206      0.952309  \n",
       "4     0.922265      0.930020      0.907759      0.921722  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data1.index = [i for i in range(len(Data1))]\n",
    "Data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
