{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    # Input Layer\n",
    "    # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "    # MNIST images are 28x28 pixels, and have one color channel\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "    # Convolutional Layer #1\n",
    "    # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "  # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "    conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  # First max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2\n",
    "  # Computes 64 features using a 5x5 filter.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 64]\n",
    "    conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #2\n",
    "  # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Flatten tensor into a batch of vectors\n",
    "  # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "  # Dense Layer\n",
    "  # Densely connected layer with 1024 neurons\n",
    "  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  # Output Tensor Shape: [batch_size, 1024]\n",
    "    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "  # Add dropout operation; 0.6 probability that element will be kept\n",
    "    dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits layer\n",
    "  # Input Tensor Shape: [batch_size, 1024]\n",
    "  # Output Tensor Shape: [batch_size, 10]\n",
    "    logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "    predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "        train_op = optimizer.minimize(\n",
    "           loss=loss,\n",
    "           global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def per_device_batch_size(batch_size, num_gpus):\n",
    "    \"\"\"For multi-gpu, batch-size must be a multiple of the number of GPUs.\n",
    "    Note that this should eventually be handled by DistributionStrategies\n",
    "    directly. Multi-GPU support is currently experimental, however,\n",
    "    so doing the work here until that feature is in place.\n",
    "    Args:\n",
    "      batch_size: Global batch size to be divided among devices. This should be\n",
    "      equal to num_gpus times the single-GPU batch_size for multi-gpu training.\n",
    "      num_gpus: How many GPUs are used with DistributionStrategies.\n",
    "    Returns:\n",
    "      Batch size per device.\n",
    "    Raises:\n",
    "      ValueError: if batch_size is not divisible by number of devices\n",
    "    \"\"\"\n",
    "    if num_gpus <= 1:\n",
    "        return batch_size\n",
    "\n",
    "    remainder = batch_size % num_gpus\n",
    "    if remainder:\n",
    "        err = ('When running with multiple GPUs, batch size '\n",
    "               'must be a multiple of the number of available GPUs. Found {} '\n",
    "               'GPUs with a batch size of {}; try --batch_size={} instead.'\n",
    "               ).format(num_gpus, batch_size, batch_size - remainder)\n",
    "        raise ValueError(err)\n",
    "    return int(batch_size / num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFnProvider:\n",
    "    def __init__(self, train_batch_size):\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.__load_data()\n",
    "\n",
    "    def __load_data(self):\n",
    "       # Load training and eval data\n",
    "        mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "        self.train_data = mnist.train.images  # Returns np.array\n",
    "        self.train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "        self.eval_data = mnist.test.images  # Returns np.array\n",
    "        self.eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "    def train_input_fn(self):\n",
    "        \"\"\"An input function for training\"\"\"\n",
    "        # Shuffle, repeat, and batch the examples.\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(({\"x\": self.train_data}, self.train_labels))\n",
    "        dataset = dataset.shuffle(1000).repeat().batch(self.train_batch_size)\n",
    "        return dataset\n",
    "\n",
    "    def eval_input_fn(self):\n",
    "        \"\"\"An input function for evaluation or prediction\"\"\"\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(({\"x\": self.eval_data}, self.eval_labels))\n",
    "        dataset = dataset.batch(1)\n",
    "        return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(unused_argv):\n",
    "    batch_size = 100\n",
    "    num_gpus = 2\n",
    "\n",
    "    # input_fn which serves Dataset\n",
    "    input_fn_provider = InputFnProvider(per_device_batch_size(batch_size, num_gpus))\n",
    "\n",
    "    # Use multiple GPUs by MirroredStragtegy.\n",
    "    # All avaiable GPUs will be used if `num_gpus` is omitted.\n",
    "    if num_gpus > 1:\n",
    "          distribution = tf.contrib.distribute.MirroredStrategy(num_gpus=num_gpus)\n",
    "    else:\n",
    "          distribution = None\n",
    "  # Pass to RunConfig\n",
    "    config = tf.estimator.RunConfig(\n",
    "          train_distribute=distribution,\n",
    "          model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "  # Create the Estimator\n",
    "  # pass RunConfig\n",
    "    mnist_classifier = tf.estimator.Estimator(\n",
    "          model_fn=cnn_model_fn,\n",
    "          config=config)\n",
    "\n",
    "  # Train the model\n",
    "    mnist_classifier.train(\n",
    "          input_fn=input_fn_provider.train_input_fn,\n",
    "          steps=10000)\n",
    "\n",
    "  # Evaluate the model and print results\n",
    "    eval_results = mnist_classifier.evaluate(input_fn=input_fn_provider.eval_input_fn)\n",
    "    print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-12-b76f3d1fa647>:8: load_dataset (from tensorflow.contrib.learn.python.learn.datasets) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\__init__.py:80: load_mnist (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:300: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST-data\\train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST-data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST-data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\user\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "INFO:tensorflow:Initializing RunConfig with distribution strategies.\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/mnist_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x000001F1A66162E8>, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001F1A6616668>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_distribute_coordinator_mode': None}\n",
      "INFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\n",
      "WARNING:tensorflow:Not all devices in distribute strategy are visible by TensorFlow sessions.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3005, step = 0\n",
      "INFO:tensorflow:global_step/sec: 8.1851\n",
      "INFO:tensorflow:loss = 2.303437, step = 100 (12.221 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.43932\n",
      "INFO:tensorflow:loss = 2.2779791, step = 200 (11.847 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.42301\n",
      "INFO:tensorflow:loss = 2.265151, step = 300 (11.872 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.21998\n",
      "INFO:tensorflow:loss = 2.2362502, step = 400 (12.164 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.2099\n",
      "INFO:tensorflow:loss = 2.2163386, step = 500 (12.180 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.38778\n",
      "INFO:tensorflow:loss = 2.1660244, step = 600 (11.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.40888\n",
      "INFO:tensorflow:loss = 2.1102493, step = 700 (11.885 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.26744\n",
      "INFO:tensorflow:loss = 2.029243, step = 800 (12.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.22268\n",
      "INFO:tensorflow:loss = 2.0346348, step = 900 (12.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.36051\n",
      "INFO:tensorflow:loss = 1.9375489, step = 1000 (11.961 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.33479\n",
      "INFO:tensorflow:loss = 1.790267, step = 1100 (11.998 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.29685\n",
      "INFO:tensorflow:loss = 1.6121731, step = 1200 (12.053 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.22877\n",
      "INFO:tensorflow:loss = 1.4544095, step = 1300 (12.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.23485\n",
      "INFO:tensorflow:loss = 1.2696452, step = 1400 (12.145 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.10111\n",
      "INFO:tensorflow:loss = 1.2088008, step = 1500 (12.343 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.08153\n",
      "INFO:tensorflow:loss = 1.0342889, step = 1600 (12.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.9508\n",
      "INFO:tensorflow:loss = 0.8893497, step = 1700 (12.568 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.03683\n",
      "INFO:tensorflow:loss = 0.8876537, step = 1800 (12.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.28383\n",
      "INFO:tensorflow:loss = 0.8359934, step = 1900 (12.072 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.13992\n",
      "INFO:tensorflow:loss = 0.7374737, step = 2000 (12.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.2173\n",
      "INFO:tensorflow:loss = 0.68354815, step = 2100 (12.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.23688\n",
      "INFO:tensorflow:loss = 0.5998578, step = 2200 (12.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.36818\n",
      "INFO:tensorflow:loss = 0.72112525, step = 2300 (11.950 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.2362\n",
      "INFO:tensorflow:loss = 0.4982376, step = 2400 (12.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.87833\n",
      "INFO:tensorflow:loss = 0.5225909, step = 2500 (12.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.19246\n",
      "INFO:tensorflow:loss = 0.5355954, step = 2600 (12.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.20923\n",
      "INFO:tensorflow:loss = 0.30079913, step = 2700 (12.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.29\n",
      "INFO:tensorflow:loss = 0.40606612, step = 2800 (12.063 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.19782\n",
      "INFO:tensorflow:loss = 0.49857226, step = 2900 (12.198 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.16976\n",
      "INFO:tensorflow:loss = 0.45997378, step = 3000 (12.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.24907\n",
      "INFO:tensorflow:loss = 0.3142224, step = 3100 (12.122 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.37447\n",
      "INFO:tensorflow:loss = 0.47459602, step = 3200 (11.941 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.18043\n",
      "INFO:tensorflow:loss = 0.42850345, step = 3300 (12.224 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 8.15514\n",
      "INFO:tensorflow:loss = 0.50589633, step = 3400 (12.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.29137\n",
      "INFO:tensorflow:loss = 0.42503738, step = 3500 (12.061 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.42867\n",
      "INFO:tensorflow:loss = 0.45871854, step = 3600 (11.873 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.13397\n",
      "INFO:tensorflow:loss = 0.54117715, step = 3700 (12.285 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.17176\n",
      "INFO:tensorflow:loss = 0.4360995, step = 3800 (12.237 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.20184\n",
      "INFO:tensorflow:loss = 0.3783541, step = 3900 (12.192 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.32856\n",
      "INFO:tensorflow:loss = 0.3659142, step = 4000 (12.007 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.64934\n",
      "INFO:tensorflow:loss = 0.4109796, step = 4100 (13.073 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.8383\n",
      "INFO:tensorflow:loss = 0.36934358, step = 4200 (12.759 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.79382\n",
      "INFO:tensorflow:loss = 0.41129774, step = 4300 (12.830 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.24568\n",
      "INFO:tensorflow:loss = 0.33301082, step = 4400 (12.129 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.37097\n",
      "INFO:tensorflow:loss = 0.2856497, step = 4500 (11.945 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.22134\n",
      "INFO:tensorflow:loss = 0.38128525, step = 4600 (12.168 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.1287\n",
      "INFO:tensorflow:loss = 0.31333566, step = 4700 (12.297 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.24772\n",
      "INFO:tensorflow:loss = 0.46626562, step = 4800 (12.126 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4883 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 7.18763\n",
      "INFO:tensorflow:loss = 0.33591753, step = 4900 (13.912 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.19916\n",
      "INFO:tensorflow:loss = 0.25538182, step = 5000 (12.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.18778\n",
      "INFO:tensorflow:loss = 0.36217448, step = 5100 (12.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.26744\n",
      "INFO:tensorflow:loss = 0.27008086, step = 5200 (12.096 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.27153\n",
      "INFO:tensorflow:loss = 0.30921018, step = 5300 (12.090 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.1691\n",
      "INFO:tensorflow:loss = 0.31125975, step = 5400 (12.241 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.20923\n",
      "INFO:tensorflow:loss = 0.2891623, step = 5500 (12.181 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.245\n",
      "INFO:tensorflow:loss = 0.42470527, step = 5600 (12.134 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.21932\n",
      "INFO:tensorflow:loss = 0.22921662, step = 5700 (12.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.23958\n",
      "INFO:tensorflow:loss = 0.27591088, step = 5800 (12.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.21797\n",
      "INFO:tensorflow:loss = 0.2842769, step = 5900 (12.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.25791\n",
      "INFO:tensorflow:loss = 0.28526196, step = 6000 (12.109 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.3051\n",
      "INFO:tensorflow:loss = 0.23124617, step = 6100 (12.041 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.33548\n",
      "INFO:tensorflow:loss = 0.3094952, step = 6200 (11.997 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.18443\n",
      "INFO:tensorflow:loss = 0.26461756, step = 6300 (12.218 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.24094\n",
      "INFO:tensorflow:loss = 0.24705586, step = 6400 (12.135 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.29274\n",
      "INFO:tensorflow:loss = 0.27514398, step = 6500 (12.059 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.00219\n",
      "INFO:tensorflow:loss = 0.22504312, step = 6600 (12.508 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.07762\n",
      "INFO:tensorflow:loss = 0.44859755, step = 6700 (12.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.83156\n",
      "INFO:tensorflow:loss = 0.36855462, step = 6800 (12.769 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.12014\n",
      "INFO:tensorflow:loss = 0.19412757, step = 6900 (12.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.26063\n",
      "INFO:tensorflow:loss = 0.30189377, step = 7000 (12.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.31888\n",
      "INFO:tensorflow:loss = 0.19059417, step = 7100 (12.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.26199\n",
      "INFO:tensorflow:loss = 0.28908697, step = 7200 (12.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.19112\n",
      "INFO:tensorflow:loss = 0.31646574, step = 7300 (12.208 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.35075\n",
      "INFO:tensorflow:loss = 0.35526302, step = 7400 (11.975 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.32095\n",
      "INFO:tensorflow:loss = 0.27760562, step = 7500 (12.018 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.18778\n",
      "INFO:tensorflow:loss = 0.2166542, step = 7600 (12.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.79685\n",
      "INFO:tensorflow:loss = 0.17847201, step = 7700 (12.819 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.43163\n",
      "INFO:tensorflow:loss = 0.27617776, step = 7800 (13.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.90484\n",
      "INFO:tensorflow:loss = 0.2908875, step = 7900 (12.651 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.04392\n",
      "INFO:tensorflow:loss = 0.15508783, step = 8000 (12.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.51405\n",
      "INFO:tensorflow:loss = 0.24321459, step = 8100 (13.309 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.22472\n",
      "INFO:tensorflow:loss = 0.18807676, step = 8200 (12.157 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.26267\n",
      "INFO:tensorflow:loss = 0.13970017, step = 8300 (12.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.32579\n",
      "INFO:tensorflow:loss = 0.20321187, step = 8400 (12.011 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.22944\n",
      "INFO:tensorflow:loss = 0.19088532, step = 8500 (12.152 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.05491\n",
      "INFO:tensorflow:loss = 0.31509233, step = 8600 (12.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.95607\n",
      "INFO:tensorflow:loss = 0.32078236, step = 8700 (12.563 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.22472\n",
      "INFO:tensorflow:loss = 0.22688825, step = 8800 (12.158 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.23552\n",
      "INFO:tensorflow:loss = 0.23655722, step = 8900 (12.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.21259\n",
      "INFO:tensorflow:loss = 0.18776752, step = 9000 (12.176 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.86288\n",
      "INFO:tensorflow:loss = 0.20632145, step = 9100 (12.718 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.05232\n",
      "INFO:tensorflow:loss = 0.28269246, step = 9200 (12.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.17966\n",
      "INFO:tensorflow:loss = 0.12066034, step = 9300 (13.929 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.67921\n",
      "INFO:tensorflow:loss = 0.17927377, step = 9400 (13.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.85426\n",
      "INFO:tensorflow:loss = 0.32345814, step = 9500 (12.732 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.00156\n",
      "INFO:tensorflow:loss = 0.20221648, step = 9600 (12.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 7.96943\n",
      "INFO:tensorflow:loss = 0.21477887, step = 9700 (12.542 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9722 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:global_step/sec: 6.96544\n",
      "INFO:tensorflow:loss = 0.29204082, step = 9800 (14.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.1254\n",
      "INFO:tensorflow:loss = 0.1552772, step = 9900 (12.307 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into /tmp/mnist_convnet_model\\model.ckpt.\n",
      "INFO:tensorflow:Finalize system.\n",
      "INFO:tensorflow:Loss for final step: 0.22558388.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-01-22-02:51:33\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model\\model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-01-22-02:51:55\n",
      "INFO:tensorflow:Saving dict for global step 10000: accuracy = 0.951, global_step = 10000, loss = 0.16956547\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: /tmp/mnist_convnet_model\\model.ckpt-10000\n",
      "{'accuracy': 0.951, 'loss': 0.16956547, 'global_step': 10000}\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3275: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
