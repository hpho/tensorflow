{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\wedge_Re180_Pr0_2.csv')\n",
    "Data1= pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\1wedge_Re180_Pr0_2.csv')\n",
    "\n",
    "final_Data = pd.merge(Data,Data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242208, 190)\n",
      "(242208, 137)\n"
     ]
    }
   ],
   "source": [
    "print(Data.shape)\n",
    "print(Data1.shape)\n",
    "print(final_Data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['dp/dy', 'TV_conv_turb', 'dk/dx_i_abs', 'tke_conv_turb', 'TV', 'TV_prod(al_t_1)', 'Pr_t', 'MKE_diss', 'MKE_visc_diff', 'MTV_mol_diff', 'MEK_pre', 'dp/dx', 'TV_diff', 'tke_prod(nu_t_1_new)', 'TV_diss', 'S_12(=S_21)', 'MTV_diss', 'dp/dx_i_abs'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-800352c6f5ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m             \u001b[1;34m'tke_pre'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'tke_diff'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'tke_conv_turb'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Nu_t_lsq'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'tke'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'tke_diss'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dk/dx'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dk/dy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dk/dx_i_abs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'TV'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"dT'T'/dx\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"dT'T'/dy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m             \u001b[1;34m'dTvar/dx_i_abs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dp/dx'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dp/dy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dp/dx_i_abs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dT/dx_i_abs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dT/dx'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dT/dy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'S_11'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'S_12(=S_21)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'S_22'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'S_ij_abs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m             'u_du/dx+v_dv/dx','Pr_t','X','Y']]\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[1;32m-> 2934\u001b[1;33m                                                    raise_missing=True)\n\u001b[0m\u001b[0;32m   2935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[0;32m   1353\u001b[0m                           raise_missing}\n\u001b[1;32m-> 1354\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1355\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[0;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1250\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'loc'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not in index\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m             \u001b[1;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['dp/dy', 'TV_conv_turb', 'dk/dx_i_abs', 'tke_conv_turb', 'TV', 'TV_prod(al_t_1)', 'Pr_t', 'MKE_diss', 'MKE_visc_diff', 'MTV_mol_diff', 'MEK_pre', 'dp/dx', 'TV_diff', 'tke_prod(nu_t_1_new)', 'TV_diss', 'S_12(=S_21)', 'MTV_diss', 'dp/dx_i_abs'] not in index\""
     ]
    }
   ],
   "source": [
    "data = final_Data[['MKE_visc_diff','MEK_pre','MKE_diss','MTV_mol_diff','MTV_diss','TV_prod(al_t_1)','TV_diff','TV_diss','TV_conv_turb','tke_prod(nu_t_1_new)',\n",
    "            'tke_pre','tke_diff','tke_conv_turb','Nu_t_lsq','tke','tke_diss','dk/dx','dk/dy','dk/dx_i_abs','TV',\"dT'T'/dx\",\"dT'T'/dy\",\n",
    "            'dTvar/dx_i_abs','dp/dx','dp/dy','dp/dx_i_abs','dT/dx_i_abs','dT/dx','dT/dy','S_11','S_12(=S_21)','S_22','S_ij_abs',\n",
    "            'u_du/dx+v_dv/dx','Pr_t','X','Y']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242208, 190)\n",
      "Index(['X', 'Y', 'Z', 'Nu_t_lsq', 'PHI-Alpha_t_lsq', 'PHI-Pr_t', 'nu_t_1',\n",
      "       'nu_t_2', 'u_tau', 'y_plus',\n",
      "       ...\n",
      "       'dv/dx', 'dv/dy', 'd2T/dy2', 'dT/dn', 'dT'T'/dx', 'dT'T'/dy',\n",
      "       'dT'T'/dx_i', 'u_du/dx', 'u_du/dx+v_dv/dy', 'Unnamed: 189'],\n",
      "      dtype='object', length=190)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd   \n",
    "# pandas 는 csv 파일을 손쉽게 다루는 여러가지 함수를 포함한 모듈입니다. \n",
    "\n",
    "#데이터 불러오기\n",
    "data = pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\wedge_Re180_Pr0_2.csv')\n",
    "\n",
    "#데이터가 잘불러와졌는지 확인하기 위해서 데이터 사이즈를 확인하겠습니다.\n",
    "print(data.shape)\n",
    "\n",
    "#데이터의 컬럼 명을 확인해보겠습니다.\n",
    "print(data.columns)\n",
    "\n",
    "#데이터의 오름차순 정렬\n",
    "data.sort_values(by=['X','Y'], ascending=True, inplace=True)\n",
    "\n",
    "#데이터끝에 컬럼을 추가합니다. 숫자가 아니라 식을 넣어줘도 가능합니다.\n",
    "data['Pr'] = 0.2\n",
    "data['Re_tau'] = 0.18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(196272, 191)\n",
      "(179927, 191)\n"
     ]
    }
   ],
   "source": [
    "#데이터 필터링 과정 Y값이 0.8<Y<1.2 이부분 제외, y_plus가 y_plus>3 인 값만 추출\n",
    "data.drop(data[(data.Y<1.2) & (data.Y>0.8)].index, inplace=True)\n",
    "data = data[data.y_plus >= 3]\n",
    "\n",
    "#컬럼의 이름을 바꿉니다.\n",
    "data = data.rename(columns={'PHI-Alpha_t_lsq':'Alpha_t', 'dp_dx':'dp/dx'})  #따옴표 안에 쉼표를 붙여서 바꿀 열을 추가할수있습니다.\n",
    "\n",
    "#필요한 컬럼만 추출합니다.\n",
    "extracted_data = data[['Alpha_t','dp/dx']]\n",
    "\n",
    "#data size는 같지만 각기 다른 컬럼을 가진 csv파일을 합칩니다.\n",
    "#앞의 과정을 통해서 data 는 alpha_t 와 dp/dx 라는 컬럼을  data1 으 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242208, 190)\n",
      "(242208, 137)\n",
      "(179927, 55)\n",
      "(179927, 55)\n",
      "(179927, 55)\n"
     ]
    }
   ],
   "source": [
    "#판다스 모듈 임포트\n",
    "import pandas as pd\n",
    "\n",
    "#데이터 불러오기\n",
    "data=pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\wedge_Re180_Pr0_2.csv')\n",
    "data1=pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\1wedge_Re180_Pr0_2.csv')\n",
    "\n",
    "#데이터 사이즈 확인\n",
    "print(data.shape)\n",
    "print(data1.shape)\n",
    "\n",
    "#X,Y 오름차순 정렬\n",
    "data.sort_values(by=['X','Y'],inplace=True)\n",
    "data1.sort_values(by=['X','Y'],inplace=True)\n",
    "\n",
    "#데이터프레임에 단일값을 가지는 컬럼 추가\n",
    "#data[\"Pr\"]=0.7\n",
    "#data[\"Re_tau\"]=0.18\n",
    "\n",
    "#데이터 필터링 과정 Y값이 0.8<Y<1.2 인부분 제외, y_plus가 >3 인 데이터만 추출\n",
    "data=data.drop(data[(data.Y<1.2)&(data.Y>0.8)].index)\n",
    "data=data[data.y_plus>=3]\n",
    "\n",
    "data1=data1.drop(data1[(data1.Y<1.2)&(data1.Y>0.8)].index)\n",
    "data1=data1[data1.y_plus>=3]\n",
    "\n",
    "#데이터에 컬럼 추가\n",
    "data[\"wedge_height\"] = 0.1\n",
    "data[\"1/Pr\"] = 1/data['Pr']\n",
    "data[\"TV\"] = 2*data['PHI-tfe']\n",
    "data['local volume'] = 1\n",
    "\n",
    "#컬럼명을 변경합니다.\n",
    "data = data.rename(columns={'PHI-Alpha_t_lsq': 'Alpha_t','dp_dx':'dp/dx','Mean_tke_pre_diff':'MKE_pre',\n",
    "                            'Mean_tfe_mol_diff':'MTV_mol_diff','Mean_tke_diss':'MKE_diss',\n",
    "                            'Mean_tfe_diss':'MTV_diss','PHI-Rp/Rd':'Rp/Rd',\n",
    "                            'PHI-Pr_t_new':'Pr_t','S_12':'S_12(=S_21)','Mean_tke_visc_diff':'MKE_visc_diff',\n",
    "                            'U_AVG-X':'U-AVG-X','dk_dx_i_abs':'dk/dx_i_abs','dp_dx_i_abs':'dp/dx_i_abs',\n",
    "                            'U_AVG-Z':'U-AVG-Z','dp_dy':'dp/dy','U_AVG-Y':'U-AVG-Y','U_AVG-X':'U-AVG-X',\n",
    "                            'PHI-Rp':'Rp','PHI-Rd':'Rd'\n",
    "                            })\n",
    "\n",
    "data1 = data1.rename(columns={'PHI-tfe_conv_tur':'TV_conv_turb','tke_prod':'tke_prod(nu_t_1_new)',\n",
    "                              'PHI-tfe_diss':'TV_diss','PHI-tfe_prod':'TV_prod(al_t_1)',\n",
    "                              'PHI-tfe_diff':'TV_diff','PHI-tfe_sdm':'TV_sdm',\n",
    "                              'tke_conv_tur':'tke_conv_turb'})\n",
    "\n",
    "\n",
    "\n",
    "#필요한 컬럼만 뽑아냅니다.\n",
    "full_parameter_data1 = data1[['tke_conv_turb', 'TV_conv_turb', 'tke_pre', 'tke_prod(nu_t_1_new)',\n",
    "                              'TV_diss', 'TV_prod(al_t_1)', 'TV_diff', 'tke_diff',\n",
    "                              'TV_sdm', 'tke_sdm'] ]\n",
    "\n",
    "full_parameter_data2 = data[['X','Y','y_plus','wedge_height','Nu_t_lsq','Alpha_t','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss','Rp',\n",
    "                          'Rd','TV',\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22','Re','Pr','Pr_t',\n",
    "                          \"dTvar/dx_i_abs\",\"Rp/Rd\",'U-AVG-X','U-AVG-Y','U-AVG-Z','du/dx','du/dy','dv/dx','dv/dy',\n",
    "                          'P_AVG','1/Pr','local volume']]\n",
    "\n",
    "#각기 두개의 데이터를 합칩니다.\n",
    "full_parameter_data = pd.merge(full_parameter_data1,full_parameter_data2,\n",
    "                               left_on=None, right_on=None, left_index=True, right_index=True)\n",
    "\n",
    "#컬럼을 원하는 순서대로 정렬합니다.\n",
    "final_data=full_parameter_data[['X','Y','y_plus','wedge_height','Nu_t_lsq','Alpha_t','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss','TV_prod(al_t_1)','tke_prod(nu_t_1_new)','Rp',\n",
    "                          'Rd','TV','tke_sdm',\"tke_conv_turb\",\"tke_pre\",\"tke_diff\",\"TV_sdm\",\n",
    "                          \"TV_conv_turb\",\"TV_diff\",\"TV_diss\",\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22','Re','Pr','Pr_t',\n",
    "                          \"dTvar/dx_i_abs\",\"Rp/Rd\",'U-AVG-X','U-AVG-Y','U-AVG-Z','du/dx','du/dy','dv/dx','dv/dy',\n",
    "                          'P_AVG','1/Pr','local volume']]\n",
    "\n",
    "#데이터가 잘 뽑혔는지 확인\n",
    "print(final_data.shape)\n",
    "\n",
    "#데이터값들중에 1000보다 큰값은 제외합니다.\n",
    "final_data = final_data[final_data<1000]\n",
    "final_data = final_data.dropna(axis=0)\n",
    "print(final_data.shape)\n",
    "\n",
    "#X , Y 값들 중복값을 제거합니다.\n",
    "final_data = final_data.drop_duplicates(['X','Y'], keep='last')\n",
    "print(final_data.shape)\n",
    "\n",
    "# csv 파일을 저장합니다.   header : 컬럼 명 포함   index 행 번호 포함\n",
    "final_data.to_csv(r'D:\\Desktop\\190305\\csvfile\\new\\uniform_wedge_Re180_Pr0_2.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95735, 190)\n",
      "(95735, 137)\n",
      "(95735, 55)\n",
      "(95735, 55)\n",
      "(90655, 55)\n"
     ]
    }
   ],
   "source": [
    "#데이터 불러오기\n",
    "data=pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\ununiformed_wedge_Re180_Pr0_2.csv')\n",
    "data1=pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\ununiformed_1wedge_Re180_Pr0_2.csv')\n",
    "\n",
    "#X,Y 오름차순 정렬\n",
    "data.sort_values(by=['X','Y'],inplace=True)\n",
    "data1.sort_values(by=['X','Y'],inplace=True)\n",
    "\n",
    "#데이터프레임에 단일값을 가지는 컬럼 추가\n",
    "#data[\"Pr\"]=0.7\n",
    "#data[\"Re_tau\"]=0.18\n",
    "\n",
    "#데이터 필터링 과정 Y값이 0.8<Y<1.2 인부분 제외, y_plus가 >3 인 데이터만 추출\n",
    "data=data.drop(data[(data.Y<1.2)&(data.Y>0.8)].index)\n",
    "data=data[data.y_plus>=3]\n",
    "\n",
    "print(data.shape)\n",
    "\n",
    "data1=data1.drop(data1[(data1.Y<1.2)&(data1.Y>0.8)].index)\n",
    "data1=data1[data1.y_plus>3]\n",
    "\n",
    "print(data1.shape)\n",
    "\n",
    "data[\"wedge_height\"] = 0.1\n",
    "data[\"1/Pr\"] = 1/data['Pr']\n",
    "data[\"TV\"] = 2*data['PHI-tfe']\n",
    "data = data.rename(columns={'PHI-Alpha_t_lsq': 'Alpha_t','dp_dx':'dp/dx','Mean_tke_pre_diff':'MKE_pre',\n",
    "                            'Mean_tfe_mol_diff':'MTV_mol_diff','Mean_tke_diss':'MKE_diss','dp_dx':'dp/dx',\n",
    "                            'Vi-AVG':'U-AVG-Y','Mean_tfe_diss':'MTV_diss','PHI-Rp/Rd':'Rp/Rd',\n",
    "                            'PHI-Pr_t_new':'Pr_t','S_12':'S_12(=S_21)','Mean_tke_visc_diff':'MKE_visc_diff',\n",
    "                            'U_AVG-X':'U-AVG-X','dk_dx_i_abs':'dk/dx_i_abs','dp_dx_i_abs':'dp/dx_i_abs',\n",
    "                            'U_AVG-Z':'U-AVG-Z','dp_dy':'dp/dy','U_AVG-Y':'U-AVG-Y','U_AVG-X':'U-AVG-X',\n",
    "                            'PHI-Rp':'Rp','PHI-Rd':'Rd','no_volume_cc':'local volume'\n",
    "                            })\n",
    "\n",
    "data1 = data1.rename(columns={'PHI-tfe_conv_tur':'TV_conv_turb','tke_prod':'tke_prod(nu_t_1_new)',\n",
    "                              'PHI-tfe_diss':'TV_diss','PHI-tfe_prod':'TV_prod(al_t_1)',\n",
    "                              'PHI-tfe_diff':'TV_diff','PHI-tfe_sdm':'TV_sdm',\n",
    "                              'tke_conv_tur':'tke_conv_turb'})\n",
    "\n",
    "\n",
    "\n",
    "#full parameter \n",
    "\n",
    "full_parameter_data1 = data1[['tke_conv_turb', 'TV_conv_turb', 'tke_pre', 'tke_prod(nu_t_1_new)',\n",
    "                              'TV_diss', 'TV_prod(al_t_1)', 'TV_diff', 'tke_diff',\n",
    "                              'TV_sdm', 'tke_sdm'] ]\n",
    "\n",
    "full_parameter_data2 = data[['X','Y','y_plus','wedge_height','Nu_t_lsq','Alpha_t','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss','Rp',\n",
    "                          'Rd','TV',\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22','Re','Pr','Pr_t',\n",
    "                          \"dTvar/dx_i_abs\",\"Rp/Rd\",'U-AVG-X','U-AVG-Y','U-AVG-Z','du/dx','du/dy','dv/dx','dv/dy',\n",
    "                          'P_AVG','1/Pr','local volume']]\n",
    "full_parameter_data = pd.merge(full_parameter_data1,full_parameter_data2,\n",
    "                               left_on=None, right_on=None, left_index=True, right_index=True)\n",
    "\n",
    "final_data=full_parameter_data[['X','Y','y_plus','wedge_height','Nu_t_lsq','Alpha_t','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss','TV_prod(al_t_1)','tke_prod(nu_t_1_new)','Rp',\n",
    "                          'Rd','TV','tke_sdm',\"tke_conv_turb\",\"tke_pre\",\"tke_diff\",\"TV_sdm\",\n",
    "                          \"TV_conv_turb\",\"TV_diff\",\"TV_diss\",\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22','Re','Pr','Pr_t',\n",
    "                          \"dTvar/dx_i_abs\",\"Rp/Rd\",'U-AVG-X','U-AVG-Y','U-AVG-Z','du/dx','du/dy','dv/dx','dv/dy',\n",
    "                          'P_AVG','1/Pr','local volume']]\n",
    "\n",
    "print(final_data.shape)\n",
    "final_data = final_data[final_data<1000]\n",
    "final_data = final_data.dropna(axis=0)\n",
    "print(final_data.shape)\n",
    "final_data = final_data.drop_duplicates(['X','Y'], keep='last')\n",
    "print(final_data.shape)\n",
    "\n",
    "# header : 변수 이름 포함   index 행 번호 포함\n",
    "final_data.to_csv(r'D:\\Desktop\\190305\\csvfile\\new\\ununiform_wedge_Re180_Pr0_2.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179927, 55)\n",
      "(179927, 55)\n",
      "(179927, 55)\n"
     ]
    }
   ],
   "source": [
    "#데이터 불러오기\n",
    "data=pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\wedge_Re180_Pr0_7.csv')\n",
    "data1=pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\1wedge_Re180_Pr0_7.csv')\n",
    "\n",
    "#X,Y 오름차순 정렬\n",
    "data.sort_values(by=['X','Y'],inplace=True)\n",
    "data1.sort_values(by=['X','Y'],inplace=True)\n",
    "\n",
    "#데이터프레임에 단일값을 가지는 컬럼 추가\n",
    "#data[\"Pr\"]=0.7\n",
    "#data[\"Re_tau\"]=0.18\n",
    "\n",
    "#데이터 필터링 과정 Y값이 0.8<Y<1.2 인부분 제외, y_plus가 >3 인 데이터만 추출\n",
    "data=data.drop(data[(data.Y<1.2)&(data.Y>0.8)].index)\n",
    "data=data[data.y_plus>=3]\n",
    "\n",
    "data.shape\n",
    "\n",
    "data1=data1.drop(data1[(data1.Y<1.2)&(data1.Y>0.8)].index)\n",
    "data1=data1[data1.y_plus>=3]\n",
    "\n",
    "data1.shape\n",
    "\n",
    "data[\"wedge_height\"] = 0.1\n",
    "data[\"1/Pr\"] = 1/data['Pr']\n",
    "data[\"TV\"] = 2*data['PHI_2-tfe']\n",
    "data['local volume'] = 1\n",
    "data = data.rename(columns={'PHI_2-Alpha_t_lsq': 'Alpha_t','dp_dx':'dp/dx','Mean_tke_pre_diff':'MKE_pre',\n",
    "                            'Mean_tfe_mol_diff':'MTV_mol_diff','Mean_tke_diss':'MKE_diss',\n",
    "                            'U_AVG-Y':'U-AVG-Y','Mean_tfe_diss':'MTV_diss','PHI_2-Rp/Rd':'Rp/Rd',\n",
    "                            'PHI_2-Pr_t_new':'Pr_t','S_12':'S_12(=S_21)','Mean_tke_visc_diff':'MKE_visc_diff',\n",
    "                            'U_AVG-X':'U-AVG-X','dk_dx_i_abs':'dk/dx_i_abs','dp_dx_i_abs':'dp/dx_i_abs',\n",
    "                            'U_AVG-Z':'U-AVG-Z','dp_dy':'dp/dy',\n",
    "                            'PHI_2-Rp':'Rp','PHI_2-Rd':'Rd'\n",
    "                            })\n",
    "\n",
    "data1 = data1.rename(columns={'PHI_2-tfe_conv_tur':'TV_conv_turb','tke_prod':'tke_prod(nu_t_1_new)',\n",
    "                              'PHI_2-tfe_diss':'TV_diss','PHI_2-tfe_prod':'TV_prod(al_t_1)',\n",
    "                              'PHI_2-tfe_diff':'TV_diff','PHI_2-tfe_sdm':'TV_sdm',\n",
    "                              'tke_conv_tur':'tke_conv_turb'})\n",
    "\n",
    "\n",
    "\n",
    "#full parameter \n",
    "\n",
    "full_parameter_data1 = data1[['tke_conv_turb', 'TV_conv_turb', 'tke_pre', 'tke_prod(nu_t_1_new)',\n",
    "                              'TV_diss', 'TV_prod(al_t_1)', 'TV_diff', 'tke_diff',\n",
    "                              'TV_sdm', 'tke_sdm'] ]\n",
    "\n",
    "full_parameter_data2 = data[['X','Y','y_plus','wedge_height','Nu_t_lsq','Alpha_t','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss','Rp',\n",
    "                          'Rd','TV',\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22','Re','Pr','Pr_t',\n",
    "                          \"dTvar/dx_i_abs\",\"Rp/Rd\",'U-AVG-X','U-AVG-Y','U-AVG-Z','du/dx','du/dy','dv/dx','dv/dy',\n",
    "                          'P_AVG','1/Pr','local volume']]\n",
    "full_parameter_data = pd.merge(full_parameter_data1,full_parameter_data2,\n",
    "                               left_on=None, right_on=None, left_index=True, right_index=True)\n",
    "\n",
    "final_data=full_parameter_data[['X','Y','y_plus','wedge_height','Nu_t_lsq','Alpha_t','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss','TV_prod(al_t_1)','tke_prod(nu_t_1_new)','Rp',\n",
    "                          'Rd','TV','tke_sdm',\"tke_conv_turb\",\"tke_pre\",\"tke_diff\",\"TV_sdm\",\n",
    "                          \"TV_conv_turb\",\"TV_diff\",\"TV_diss\",\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22','Re','Pr','Pr_t',\n",
    "                          \"dTvar/dx_i_abs\",\"Rp/Rd\",'U-AVG-X','U-AVG-Y','U-AVG-Z','du/dx','du/dy','dv/dx','dv/dy',\n",
    "                          'P_AVG','1/Pr','local volume']]\n",
    "\n",
    "print(final_data.shape)\n",
    "final_data = final_data[final_data<1000]\n",
    "final_data = final_data.dropna(axis=0)\n",
    "print(final_data.shape)\n",
    "final_data = final_data.drop_duplicates(['X','Y'], keep='last')\n",
    "print(final_data.shape)\n",
    "\n",
    "# header : 변수 이름 포함   index 행 번호 포함\n",
    "final_data.to_csv(r'D:\\Desktop\\190305\\csvfile\\new\\uniform_wedge_Re180_Pr0_7.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95735, 55)\n",
      "(95735, 55)\n",
      "(90655, 55)\n"
     ]
    }
   ],
   "source": [
    "#데이터 불러오기\n",
    "data=pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\ununiformed_wedge_Re180_Pr0_7.csv')\n",
    "data1=pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\ununiformed_1wedge_Re180_Pr0_7.csv')\n",
    "\n",
    "#X,Y 오름차순 정렬\n",
    "data.sort_values(by=['X','Y'],inplace=True)\n",
    "data1.sort_values(by=['X','Y'],inplace=True)\n",
    "\n",
    "#데이터프레임에 단일값을 가지는 컬럼 추가\n",
    "#data[\"Pr\"]=0.7\n",
    "#data[\"Re_tau\"]=0.18\n",
    "\n",
    "#데이터 필터링 과정 Y값이 0.8<Y<1.2 인부분 제외, y_plus가 >3 인 데이터만 추출\n",
    "data=data.drop(data[(data.Y<1.2)&(data.Y>0.8)].index)\n",
    "data=data[data.y_plus>=3]\n",
    "\n",
    "data.shape\n",
    "\n",
    "data1=data1.drop(data1[(data1.Y<1.2)&(data1.Y>0.8)].index)\n",
    "data1=data1[data1.y_plus>=3]\n",
    "\n",
    "data1.shape\n",
    "\n",
    "data[\"wedge_height\"] = 0.1\n",
    "data[\"1/Pr\"] = 1/data['Pr']\n",
    "data[\"TV\"] = 2*data['PHI_2-tfe']\n",
    "data = data.rename(columns={'PHI_2-Alpha_t_lsq': 'Alpha_t','dp_dx':'dp/dx','Mean_tke_pre_diff':'MKE_pre',\n",
    "                            'Mean_tfe_mol_diff':'MTV_mol_diff','Mean_tke_diss':'MKE_diss','dp_dx':'dp/dx',\n",
    "                            'U_AVG-Y':'U-AVG-Y','Mean_tfe_diss':'MTV_diss','PHI_2-Rp/Rd':'Rp/Rd',\n",
    "                            'PHI_2-Pr_t_new':'Pr_t','S_12':'S_12(=S_21)','Mean_tke_visc_diff':'MKE_visc_diff',\n",
    "                            'U_AVG-X':'U-AVG-X','dk_dx_i_abs':'dk/dx_i_abs','dp_dx_i_abs':'dp/dx_i_abs',\n",
    "                            'U_AVG-Z':'U-AVG-Z','dp_dy':'dp/dy','U_AVG-Y':'U-AVG-Y','U_AVG-X':'U-AVG-X',\n",
    "                            'PHI_2-Rp':'Rp','PHI_2-Rd':'Rd','no_volume_cc':'local volume'\n",
    "                            })\n",
    "\n",
    "data1 = data1.rename(columns={'PHI_2-tfe_conv_tur':'TV_conv_turb','tke_prod':'tke_prod(nu_t_1_new)',\n",
    "                              'PHI_2-tfe_diss':'TV_diss','PHI_2-tfe_prod':'TV_prod(al_t_1)',\n",
    "                              'PHI_2-tfe_diff':'TV_diff','PHI_2-tfe_sdm':'TV_sdm',\n",
    "                              'tke_conv_tur':'tke_conv_turb'})\n",
    "\n",
    "\n",
    "\n",
    "#full parameter \n",
    "\n",
    "full_parameter_data1 = data1[['tke_conv_turb', 'TV_conv_turb', 'tke_pre', 'tke_prod(nu_t_1_new)',\n",
    "                              'TV_diss', 'TV_prod(al_t_1)', 'TV_diff', 'tke_diff',\n",
    "                              'TV_sdm', 'tke_sdm'] ]\n",
    "\n",
    "full_parameter_data2 = data[['X','Y','y_plus','wedge_height','Nu_t_lsq','Alpha_t','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss','Rp',\n",
    "                          'Rd','TV',\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22','Re','Pr','Pr_t',\n",
    "                          \"dTvar/dx_i_abs\",\"Rp/Rd\",'U-AVG-X','U-AVG-Y','U-AVG-Z','du/dx','du/dy','dv/dx','dv/dy',\n",
    "                          'P_AVG','1/Pr','local volume']]\n",
    "full_parameter_data = pd.merge(full_parameter_data1,full_parameter_data2,\n",
    "                               left_on=None, right_on=None, left_index=True, right_index=True)\n",
    "\n",
    "final_data=full_parameter_data[['X','Y','y_plus','wedge_height','Nu_t_lsq','Alpha_t','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss','TV_prod(al_t_1)','tke_prod(nu_t_1_new)','Rp',\n",
    "                          'Rd','TV','tke_sdm',\"tke_conv_turb\",\"tke_pre\",\"tke_diff\",\"TV_sdm\",\n",
    "                          \"TV_conv_turb\",\"TV_diff\",\"TV_diss\",\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22','Re','Pr','Pr_t',\n",
    "                          \"dTvar/dx_i_abs\",\"Rp/Rd\",'U-AVG-X','U-AVG-Y','U-AVG-Z','du/dx','du/dy','dv/dx','dv/dy',\n",
    "                          'P_AVG','1/Pr','local volume']]\n",
    "\n",
    "print(final_data.shape)\n",
    "final_data = final_data[final_data<1000]\n",
    "final_data = final_data.dropna(axis=0)\n",
    "print(final_data.shape)\n",
    "final_data = final_data.drop_duplicates(['X','Y'], keep='last')\n",
    "print(final_data.shape)\n",
    "\n",
    "# header : 변수 이름 포함   index 행 번호 포함\n",
    "final_data.to_csv(r'D:\\Desktop\\190305\\csvfile\\new\\ununiform_wedge_Re180_Pr0_7.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179927, 55)\n",
      "(179927, 55)\n",
      "(179927, 55)\n"
     ]
    }
   ],
   "source": [
    "#데이터 불러오기\n",
    "data=pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\wedge_Re180_Pr2_0.csv')\n",
    "data1=pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\1wedge_Re180_Pr2_0.csv')\n",
    "\n",
    "#X,Y 오름차순 정렬\n",
    "data.sort_values(by=['X','Y'],inplace=True)\n",
    "data1.sort_values(by=['X','Y'],inplace=True)\n",
    "\n",
    "#데이터프레임에 단일값을 가지는 컬럼 추가\n",
    "#data[\"Pr\"]=0.7\n",
    "#data[\"Re_tau\"]=0.18\n",
    "\n",
    "#데이터 필터링 과정 Y값이 0.8<Y<1.2 인부분 제외, y_plus가 >3 인 데이터만 추출\n",
    "data=data.drop(data[(data.Y<1.2)&(data.Y>0.8)].index)\n",
    "data=data[data.y_plus>=3]\n",
    "\n",
    "data.shape\n",
    "\n",
    "data1=data1.drop(data1[(data1.Y<1.2)&(data1.Y>0.8)].index)\n",
    "data1=data1[data1.y_plus>=3]\n",
    "\n",
    "data1.shape\n",
    "\n",
    "data[\"wedge_height\"] = 0.1\n",
    "data[\"1/Pr\"] = 1/data['Pr']\n",
    "data[\"TV\"] = 2*data['PHI_3-tfe']\n",
    "data['local volume'] = 1\n",
    "data = data.rename(columns={'PHI_3-Alpha_t_lsq': 'Alpha_t','dp_dx':'dp/dx','Mean_tke_pre_diff':'MKE_pre',\n",
    "                            'Mean_tfe_mol_diff':'MTV_mol_diff','Mean_tke_diss':'MKE_diss','dp_dx':'dp/dx',\n",
    "                            'U_AVG-Y':'U-AVG-Y','Mean_tfe_diss':'MTV_diss','PHI_3-Rp/Rd':'Rp/Rd',\n",
    "                            'PHI_3-Pr_t_new':'Pr_t','S_12':'S_12(=S_21)','Mean_tke_visc_diff':'MKE_visc_diff',\n",
    "                            'U_AVG-X':'U-AVG-X','dk_dx_i_abs':'dk/dx_i_abs','dp_dx_i_abs':'dp/dx_i_abs',\n",
    "                            'U_AVG-Z':'U-AVG-Z','dp_dy':'dp/dy','U_AVG-Y':'U-AVG-Y','U_AVG-X':'U-AVG-X',\n",
    "                            'PHI_3-Rp':'Rp','PHI_3-Rd':'Rd'\n",
    "                            })\n",
    "\n",
    "data1 = data1.rename(columns={'PHI_3-tfe_conv_tur':'TV_conv_turb','tke_prod':'tke_prod(nu_t_1_new)',\n",
    "                              'PHI_3-tfe_diss':'TV_diss','PHI_3-tfe_prod':'TV_prod(al_t_1)',\n",
    "                              'PHI_3-tfe_diff':'TV_diff','PHI_3-tfe_sdm':'TV_sdm',\n",
    "                              'tke_conv_tur':'tke_conv_turb'})\n",
    "\n",
    "\n",
    "\n",
    "#full parameter \n",
    "\n",
    "full_parameter_data1 = data1[['tke_conv_turb', 'TV_conv_turb', 'tke_pre', 'tke_prod(nu_t_1_new)',\n",
    "                              'TV_diss', 'TV_prod(al_t_1)', 'TV_diff', 'tke_diff',\n",
    "                              'TV_sdm', 'tke_sdm'] ]\n",
    "\n",
    "full_parameter_data2 = data[['X','Y','y_plus','wedge_height','Nu_t_lsq','Alpha_t','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss','Rp',\n",
    "                          'Rd','TV',\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22','Re','Pr','Pr_t',\n",
    "                          \"dTvar/dx_i_abs\",\"Rp/Rd\",'U-AVG-X','U-AVG-Y','U-AVG-Z','du/dx','du/dy','dv/dx','dv/dy',\n",
    "                          'P_AVG','1/Pr','local volume']]\n",
    "full_parameter_data = pd.merge(full_parameter_data1,full_parameter_data2,\n",
    "                               left_on=None, right_on=None, left_index=True, right_index=True)\n",
    "\n",
    "final_data=full_parameter_data[['X','Y','y_plus','wedge_height','Nu_t_lsq','Alpha_t','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss','TV_prod(al_t_1)','tke_prod(nu_t_1_new)','Rp',\n",
    "                          'Rd','TV','tke_sdm',\"tke_conv_turb\",\"tke_pre\",\"tke_diff\",\"TV_sdm\",\n",
    "                          \"TV_conv_turb\",\"TV_diff\",\"TV_diss\",\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22','Re','Pr','Pr_t',\n",
    "                          \"dTvar/dx_i_abs\",\"Rp/Rd\",'U-AVG-X','U-AVG-Y','U-AVG-Z','du/dx','du/dy','dv/dx','dv/dy',\n",
    "                          'P_AVG','1/Pr','local volume']]\n",
    "\n",
    "print(final_data.shape)\n",
    "final_data = final_data[final_data<1000]\n",
    "final_data = final_data.dropna(axis=0)\n",
    "print(final_data.shape)\n",
    "final_data = final_data.drop_duplicates(['X','Y'], keep='last')\n",
    "print(final_data.shape)\n",
    "\n",
    "# header : 변수 이름 포함   index 행 번호 포함\n",
    "final_data.to_csv(r'D:\\Desktop\\190305\\csvfile\\new\\uniform_wedge_Re180_Pr2_0.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(95735, 55)\n",
      "(95735, 55)\n",
      "(90655, 55)\n"
     ]
    }
   ],
   "source": [
    "#데이터 불러오기\n",
    "data=pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\ununiformed_wedge_Re180_Pr2_0.csv')\n",
    "data1=pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\ununiformed_1wedge_Re180_Pr2_0.csv')\n",
    "\n",
    "#X,Y 오름차순 정렬\n",
    "data.sort_values(by=['X','Y'],inplace=True)\n",
    "data1.sort_values(by=['X','Y'],inplace=True)\n",
    "\n",
    "#데이터프레임에 단일값을 가지는 컬럼 추가\n",
    "#data[\"Pr\"]=0.7\n",
    "#data[\"Re_tau\"]=0.18\n",
    "\n",
    "#데이터 필터링 과정 Y값이 0.8<Y<1.2 인부분 제외, y_plus가 >3 인 데이터만 추출\n",
    "data=data.drop(data[(data.Y<1.2)&(data.Y>0.8)].index)\n",
    "data=data[data.y_plus>=3]\n",
    "\n",
    "data.shape\n",
    "\n",
    "data1=data1.drop(data1[(data1.Y<1.2)&(data1.Y>0.8)].index)\n",
    "data1=data1[data1.y_plus>=3]\n",
    "\n",
    "data1.shape\n",
    "\n",
    "data[\"wedge_height\"] = 0.1\n",
    "data[\"1/Pr\"] = 1/data['Pr']\n",
    "data[\"TV\"] = 2*data['PHI_3-tfe']\n",
    "data = data.rename(columns={'PHI_3-Alpha_t_lsq': 'Alpha_t','dp_dx':'dp/dx','Mean_tke_pre_diff':'MKE_pre',\n",
    "                            'Mean_tfe_mol_diff':'MTV_mol_diff','Mean_tke_diss':'MKE_diss','dp_dx':'dp/dx',\n",
    "                            'U_AVG-Y':'U-AVG-Y','Mean_tfe_diss':'MTV_diss','PHI_3-Rp/Rd':'Rp/Rd',\n",
    "                            'PHI_3-Pr_t_new':'Pr_t','S_12':'S_12(=S_21)','Mean_tke_visc_diff':'MKE_visc_diff',\n",
    "                            'U_AVG-X':'U-AVG-X','dk_dx_i_abs':'dk/dx_i_abs','dp_dx_i_abs':'dp/dx_i_abs',\n",
    "                            'U_AVG-Z':'U-AVG-Z','dp_dy':'dp/dy','U_AVG-Y':'U-AVG-Y','U_AVG-X':'U-AVG-X',\n",
    "                            'PHI_3-Rp':'Rp','PHI_3-Rd':'Rd','no_volume_cc':'local volume'\n",
    "                            })\n",
    "\n",
    "data1 = data1.rename(columns={'PHI_3-tfe_conv_tur':'TV_conv_turb','tke_prod':'tke_prod(nu_t_1_new)',\n",
    "                              'PHI_3-tfe_diss':'TV_diss','PHI_3-tfe_prod':'TV_prod(al_t_1)',\n",
    "                              'PHI_3-tfe_diff':'TV_diff','PHI_3-tfe_sdm':'TV_sdm',\n",
    "                              'tke_conv_tur':'tke_conv_turb'})\n",
    "\n",
    "\n",
    "\n",
    "#full parameter \n",
    "\n",
    "full_parameter_data1 = data1[['tke_conv_turb', 'TV_conv_turb', 'tke_pre', 'tke_prod(nu_t_1_new)',\n",
    "                              'TV_diss', 'TV_prod(al_t_1)', 'TV_diff', 'tke_diff',\n",
    "                              'TV_sdm', 'tke_sdm'] ]\n",
    "\n",
    "full_parameter_data2 = data[['X','Y','y_plus','wedge_height','Nu_t_lsq','Alpha_t','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss','Rp',\n",
    "                          'Rd','TV',\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22','Re','Pr','Pr_t',\n",
    "                          \"dTvar/dx_i_abs\",\"Rp/Rd\",'U-AVG-X','U-AVG-Y','U-AVG-Z','du/dx','du/dy','dv/dx','dv/dy',\n",
    "                          'P_AVG','1/Pr','local volume']]\n",
    "full_parameter_data = pd.merge(full_parameter_data1,full_parameter_data2,\n",
    "                               left_on=None, right_on=None, left_index=True, right_index=True)\n",
    "\n",
    "final_data=full_parameter_data[['X','Y','y_plus','wedge_height','Nu_t_lsq','Alpha_t','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss','TV_prod(al_t_1)','tke_prod(nu_t_1_new)','Rp',\n",
    "                          'Rd','TV','tke_sdm',\"tke_conv_turb\",\"tke_pre\",\"tke_diff\",\"TV_sdm\",\n",
    "                          \"TV_conv_turb\",\"TV_diff\",\"TV_diss\",\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22','Re','Pr','Pr_t',\n",
    "                          \"dTvar/dx_i_abs\",\"Rp/Rd\",'U-AVG-X','U-AVG-Y','U-AVG-Z','du/dx','du/dy','dv/dx','dv/dy',\n",
    "                          'P_AVG','1/Pr','local volume']]\n",
    "\n",
    "print(final_data.shape)\n",
    "final_data = final_data[final_data<1000]\n",
    "final_data = final_data.dropna(axis=0)\n",
    "print(final_data.shape)\n",
    "final_data = final_data.drop_duplicates(['X','Y'], keep='last')\n",
    "print(final_data.shape)\n",
    "\n",
    "# header : 변수 이름 포함   index 행 번호 포함\n",
    "final_data.to_csv(r'D:\\Desktop\\190305\\csvfile\\new\\origin_wedge_Re180_Pr2_0.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 불러오기\n",
    "data=pd.read_csv(r'D:\\Desktop\\uniform_pr_t_data\\case2.csv')\n",
    "\n",
    "#X,Y 오름차순 정렬\n",
    "data.sort_values(by=['X','Y'],inplace=True)\n",
    "\n",
    "#데이터프레임에 단일값을 가지는 컬럼 추가\n",
    "data[\"Pr\"]=0.7\n",
    "data[\"Re_tau\"]=0.4\n",
    "\n",
    "#데이터 필터링 과정 Y값이 0.8<Y<1.2 인부분 제외, y_plus가 >3 인 데이터만 추출\n",
    "data=data.drop(data[(data.Y<1.2)&(data.Y>0.8)].index)\n",
    "data=data[data.y_plus>3]\n",
    "\n",
    "data.shape\n",
    "\n",
    "#full parameter \n",
    "\n",
    "full_parameter_data=data[['Pr','Re_tau','Nu_t_lsq','tke','tke_diss','tke_diff','tke_pre','tke_conv_tur','tke_prod','tfe','tfe_diss','tfe_diff',\n",
    "             'tfe_conv_tur','tfe_prod','dk/dx','dk/dy','dk/dx_i',\"dT'T'/dx\",\"dT'T'/dy\",\n",
    "             \"dT'T'/dx_i\",\"dp_dx\",\"dp_dy\",\"dp_dx_i\",\"dT/dx\",\"dT/dy\",\"dT/dx_i\",\"S_11\",\"S_12\",\n",
    "             \"S_22\",\"S_ij_abs\",\"u_du/dx+v_dv/dx\",\"Mean_tke_mol_diff\",\"Mean_tke_pre_diff\",\n",
    "             \"Mean_tke_diss\",\"Mean_tfe_mol_diff\",\"Mean_tfe_diss\",\"Pr_t_ke\",\"Pr_t_new\",\n",
    "             \"X\",\"Y\"]]\n",
    "\n",
    "\n",
    "full_parameter_data.shape\n",
    "\n",
    "# header : 변수 이름 포함   index 행 번호 포함\n",
    "full_parameter_data.to_csv(r'D:\\Desktop\\uniform_pr_t_data\\case2_Total_parameters_36.csv', header=True, index=False)\n",
    "\n",
    "#modeling parameter Pr_t_new 랑 Pr_t랑 어떤거?\n",
    "\n",
    "modeling_parameter_data=data[['Pr','Re_tau',\"Nu_t_lsq\",'tke','tke_diss','dp_dx','dp_dy','dp_dx_i','dT/dx','dT/dy',\n",
    "                              'dT/dx_i','S_11','S_12','S_22','S_ij_abs','dk/dx','dk/dy','dk/dx_i',\n",
    "                              'u_du/dx+v_dv/dx','Mean_tke_mol_diff','Mean_tke_pre_diff','Mean_tke_diss',\n",
    "                              'Mean_tfe_mol_diff','Mean_tfe_diss','Pr_t_ke','Pr_t_new','X','Y']]\n",
    "\n",
    "\n",
    "\n",
    "modeling_parameter_data.shape\n",
    "\n",
    "\n",
    "modeling_parameter_data.to_csv(r'D:\\Desktop\\uniform_pr_t_data\\case2_Modeling_parameters_24.csv', header=True, index=False)\n",
    "\n",
    "#fuctuation parameter\n",
    "\n",
    "fluctuation_parameter_data=data[['Pr','Re_tau','tke_diff','tke_pre','tke_conv_tur','tke_prod','tfe','tfe_diss',\n",
    "                                 'tfe_diff','tfe_conv_tur','tfe_prod',\"dT'T'/dx\",\"dT'T'/dy\",\n",
    "                                 \"dT'T'/dx_i\",'Pr_t_ke','Pr_t_new','X','Y']]\n",
    "\n",
    "\n",
    "\n",
    "fluctuation_parameter_data.shape\n",
    "\n",
    "# header : 변수 이름 포함   index 행 번호 포함 \n",
    "fluctuation_parameter_data.to_csv(r'D:\\Desktop\\uniform_pr_t_data\\case2_Fluctuation_parameters_14.csv', header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 불러오기\n",
    "data=pd.read_csv(r'D:\\Desktop\\uniform_pr_t_data\\case5.csv')\n",
    "\n",
    "#X,Y 오름차순 정렬\n",
    "data.sort_values(by=['X','Y'],inplace=True)\n",
    "\n",
    "#데이터프레임에 단일값을 가지는 컬럼 추가\n",
    "data[\"Pr\"]=0.7\n",
    "data[\"Re_tau\"]=0.18\n",
    "\n",
    "#데이터 필터링 과정 Y값이 0.8<Y<1.2 인부분 제외, y_plus가 >3 인 데이터만 추출\n",
    "data=data.drop(data[(data.Y<1.2)&(data.Y>0.8)].index)\n",
    "data=data[data.y_plus>3]\n",
    "\n",
    "data.shape\n",
    "\n",
    "#full parameter \n",
    "\n",
    "full_parameter_data=data[['Pr','Re_tau','Nu_t_lsq','tke','tke_diss','tke_diff','tke_pre','tke_conv_tur','tke_prod','PHI_2-tfe','PHI_2-tfe_diss','PHI_2-tfe_diff',\n",
    "             'PHI_2-tfe_conv_tur','PHI_2-tfe_prod','dk/dx','dk/dy','dk/dx_i',\"dT'T'/dx\",\"dT'T'/dy\",\n",
    "             \"dT'T'/dx_i\",\"dp_dx\",\"dp_dy\",\"dp_dx_i\",\"dT/dx\",\"dT/dy\",\"dT/dx_i\",\"S_11\",\"S_12\",\n",
    "             \"S_22\",\"S_ij_abs\",\"u_du/dx+v_dv/dx\",\"Mean_tke_mol_diff\",\"Mean_tke_pre_diff\",\n",
    "             \"Mean_tke_diss\",\"Mean_tfe_mol_diff\",\"Mean_tfe_diss\",\"Pr_t_ke\",\"Pr_t_new\",\n",
    "             \"X\",\"Y\"]]\n",
    "\n",
    "\n",
    "full_parameter_data.shape\n",
    "\n",
    "# header : 변수 이름 포함   index 행 번호 포함\n",
    "full_parameter_data.to_csv(r'D:\\Desktop\\uniform_pr_t_data\\case5_Total_parameters_36.csv', header=True, index=False)\n",
    "\n",
    "#modeling parameter Pr_t_new 랑 Pr_t랑 어떤거?\n",
    "\n",
    "modeling_parameter_data=data[['Pr','Re_tau',\"Nu_t_lsq\",'tke','tke_diss','dp_dx','dp_dy','dp_dx_i','dT/dx','dT/dy',\n",
    "                              'dT/dx_i','S_11','S_12','S_22','S_ij_abs','dk/dx','dk/dy','dk/dx_i',\n",
    "                              'u_du/dx+v_dv/dx','Mean_tke_mol_diff','Mean_tke_pre_diff','Mean_tke_diss',\n",
    "                              'Mean_tfe_mol_diff','Mean_tfe_diss','Pr_t_ke','Pr_t_new','X','Y']]\n",
    "\n",
    "\n",
    "\n",
    "modeling_parameter_data.shape\n",
    "\n",
    "\n",
    "modeling_parameter_data.to_csv(r'D:\\Desktop\\uniform_pr_t_data\\case5_Modeling_parameters_24.csv', header=True, index=False)\n",
    "\n",
    "#fuctuation parameter\n",
    "\n",
    "fluctuation_parameter_data=data[['Pr','Re_tau','tke_diff','tke_pre','tke_conv_tur','tke_prod','PHI_2-tfe','PHI_2-tfe_diss',\n",
    "                                 'PHI_2-tfe_diff','PHI_2-tfe_conv_tur','PHI_2-tfe_prod',\"dT'T'/dx\",\"dT'T'/dy\",\n",
    "                                 \"dT'T'/dx_i\",'Pr_t_ke','Pr_t_new','X','Y']]\n",
    "\n",
    "\n",
    "\n",
    "fluctuation_parameter_data.shape\n",
    "\n",
    "# header : 변수 이름 포함   index 행 번호 포함 \n",
    "fluctuation_parameter_data.to_csv(r'D:\\Desktop\\uniform_pr_t_data\\case5_Fluctuation_parameters_14.csv', header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 불러오기\n",
    "data=pd.read_csv(r'D:\\Desktop\\uniform_pr_t_data\\case6.csv')\n",
    "\n",
    "#X,Y 오름차순 정렬\n",
    "data.sort_values(by=['X','Y'],inplace=True)\n",
    "\n",
    "#데이터프레임에 단일값을 가지는 컬럼 추가\n",
    "data[\"Pr\"]=0.7\n",
    "data[\"Re_tau\"]=0.4\n",
    "\n",
    "#데이터 필터링 과정 Y값이 0.8<Y<1.2 인부분 제외, y_plus가 >3 인 데이터만 추출\n",
    "data=data.drop(data[(data.Y<1.2)&(data.Y>0.8)].index)\n",
    "data=data[data.y_plus>3]\n",
    "\n",
    "data.shape\n",
    "\n",
    "#full parameter \n",
    "\n",
    "full_parameter_data=data[['Pr','Re_tau','Nu_t_lsq','tke','tke_diss','tke_diff','tke_pre','tke_conv_tur','tke_prod','tfe','tfe_diss','tfe_diff',\n",
    "             'tfe_conv_tur','tfe_prod','dk/dx','dk/dy','dk/dx_i',\"dT'T'/dx\",\"dT'T'/dy\",\n",
    "             \"dT'T'/dx_i\",\"dp_dx\",\"dp_dy\",\"dp_dx_i\",\"dT/dx\",\"dT/dy\",\"dT/dx_i\",\"S_11\",\"S_12\",\n",
    "             \"S_22\",\"S_ij_abs\",\"u_du/dx+v_dv/dx\",\"Mean_tke_mol_diff\",\"Mean_tke_pre_diff\",\n",
    "             \"Mean_tke_diss\",\"Mean_tfe_mol_diff\",\"Mean_tfe_diss\",\"Pr_t_ke\",\"Pr_t_new\",\n",
    "             \"X\",\"Y\"]]\n",
    "\n",
    "\n",
    "full_parameter_data.shape\n",
    "\n",
    "# header : 변수 이름 포함   index 행 번호 포함\n",
    "full_parameter_data.to_csv(r'D:\\Desktop\\uniform_pr_t_data\\case6_Total_parameters_36.csv', header=True, index=False)\n",
    "\n",
    "#modeling parameter Pr_t_new 랑 Pr_t랑 어떤거?\n",
    "\n",
    "modeling_parameter_data=data[['Pr','Re_tau',\"Nu_t_lsq\",'tke','tke_diss','dp_dx','dp_dy','dp_dx_i','dT/dx','dT/dy',\n",
    "                              'dT/dx_i','S_11','S_12','S_22','S_ij_abs','dk/dx','dk/dy','dk/dx_i',\n",
    "                              'u_du/dx+v_dv/dx','Mean_tke_mol_diff','Mean_tke_pre_diff','Mean_tke_diss',\n",
    "                              'Mean_tfe_mol_diff','Mean_tfe_diss','Pr_t_ke','Pr_t_new','X','Y']]\n",
    "\n",
    "\n",
    "\n",
    "modeling_parameter_data.shape\n",
    "\n",
    "\n",
    "modeling_parameter_data.to_csv(r'D:\\Desktop\\uniform_pr_t_data\\case6_Modeling_parameters_24.csv', header=True, index=False)\n",
    "\n",
    "#fuctuation parameter\n",
    "\n",
    "fluctuation_parameter_data=data[['Pr','Re_tau','tke_diff','tke_pre','tke_conv_tur','tke_prod','tfe','tfe_diss',\n",
    "                                 'tfe_diff','tfe_conv_tur','tfe_prod',\"dT'T'/dx\",\"dT'T'/dy\",\n",
    "                                 \"dT'T'/dx_i\",'Pr_t_ke','Pr_t_new','X','Y']]\n",
    "\n",
    "\n",
    "\n",
    "fluctuation_parameter_data.shape\n",
    "\n",
    "# header : 변수 이름 포함   index 행 번호 포함 \n",
    "fluctuation_parameter_data.to_csv(r'D:\\Desktop\\uniform_pr_t_data\\case6_Fluctuation_parameters_14.csv', header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 불러오기\n",
    "data=pd.read_csv(r'D:\\Desktop\\uniform_pr_t_data\\case9.csv')\n",
    "\n",
    "#X,Y 오름차순 정렬\n",
    "data.sort_values(by=['X','Y'],inplace=True)\n",
    "\n",
    "#데이터프레임에 단일값을 가지는 컬럼 추가\n",
    "data[\"Pr\"]=0.7\n",
    "data[\"Re_tau\"]=0.18\n",
    "\n",
    "#데이터 필터링 과정 Y값이 0.8<Y<1.2 인부분 제외, y_plus가 >3 인 데이터만 추출\n",
    "data=data.drop(data[(data.Y<1.2)&(data.Y>0.8)].index)\n",
    "#data=data[data.y_plus>3]\n",
    "\n",
    "data.shape\n",
    "\n",
    "#full parameter \n",
    "\n",
    "full_parameter_data=data[['Pr','Re_tau','Nu_t_lsq','tke','tke_diss','tke_diff','tke_pre','tke_conv_tur','tke_prod','tfe','tfe_diss','tfe_diff',\n",
    "             'tfe_conv_tur','tfe_prod','dk/dx','dk/dy','dk/dx_i',\"dT'T'/dx\",\"dT'T'/dy\",\n",
    "             \"dT'T'/dx_i\",\"dp_dx\",\"dp_dy\",\"dp_dx_i\",\"dT/dx\",\"dT/dy\",\"dT/dx_i\",\"S_11\",\"S_12\",\n",
    "             \"S_22\",\"S_ij_abs\",\"u_du/dx+v_dv/dx\",\"Mean_tke_mol_diff\",\"Mean_tke_pre_diff\",\n",
    "             \"Mean_tke_diss\",\"Mean_tfe_mol_diff\",\"Mean_tfe_diss\",\"Pr_t_ke\",\"Pr_t_new\",\n",
    "             \"X\",\"Y\"]]\n",
    "\n",
    "\n",
    "full_parameter_data.shape\n",
    "\n",
    "# header : 변수 이름 포함   index 행 번호 포함\n",
    "full_parameter_data.to_csv(r'D:\\Desktop\\uniform_pr_t_data\\case9_Total_parameters_36.csv', header=True, index=False)\n",
    "\n",
    "#modeling parameter Pr_t_new 랑 Pr_t랑 어떤거?\n",
    "\n",
    "modeling_parameter_data=data[['Pr','Re_tau',\"Nu_t_lsq\",'tke','tke_diss','dp_dx','dp_dy','dp_dx_i','dT/dx','dT/dy',\n",
    "                              'dT/dx_i','S_11','S_12','S_22','S_ij_abs','dk/dx','dk/dy','dk/dx_i',\n",
    "                              'u_du/dx+v_dv/dx','Mean_tke_mol_diff','Mean_tke_pre_diff','Mean_tke_diss',\n",
    "                              'Mean_tfe_mol_diff','Mean_tfe_diss','Pr_t_ke','Pr_t_new','X','Y']]\n",
    "\n",
    "\n",
    "\n",
    "modeling_parameter_data.shape\n",
    "\n",
    "\n",
    "modeling_parameter_data.to_csv(r'D:\\Desktop\\uniform_pr_t_data\\case9_Modeling_parameters_24.csv', header=True, index=False)\n",
    "\n",
    "#fuctuation parameter\n",
    "\n",
    "fluctuation_parameter_data=data[['Pr','Re_tau','tke_diff','tke_pre','tke_conv_tur','tke_prod','tfe','tfe_diss',\n",
    "                                 'tfe_diff','tfe_conv_tur','tfe_prod',\"dT'T'/dx\",\"dT'T'/dy\",\n",
    "                                 \"dT'T'/dx_i\",'Pr_t_ke','Pr_t_new','X','Y']]\n",
    "\n",
    "\n",
    "\n",
    "fluctuation_parameter_data.shape\n",
    "\n",
    "# header : 변수 이름 포함   index 행 번호 포함 \n",
    "fluctuation_parameter_data.to_csv(r'D:\\Desktop\\uniform_pr_t_data\\case9_Fluctuation_parameters_14.csv', header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\new\\새 폴더 (2)\\orig_channel_all_Re.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = Data[Data.Pr == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\new\\새 폴더 (2)\\uniform_channel_all_Re.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X', 'Y', 'y_plus', 'wedge_height', 'Nu_t_lsq_n', 'PHI-Alpha_t_lsq_n',\n",
       "       'tke_n', 'dk/dx', 'dk/dy', 'dk_dx_i_abs', 'tke_diss_n',\n",
       "       'PHI-tfe_prod_n', 'tke_prod_n', 'PHI-Rp', 'PHI-Rd', 'PHI-TV',\n",
       "       'tke_sdm_n', 'tke_conv_tur_n', 'tke_pre_n', 'tke_diff_n',\n",
       "       'PHI-tfe_sdm_n', 'PHI-tfe_conv_tur_n', 'PHI-tfe_diff_n',\n",
       "       'PHI-tfe_diss_n', 'dp_dx', 'dp_dy', 'dp_dx_i_abs', 'u_du/dx+v_dv/dx',\n",
       "       'Mean_tke_pre_diff', 'Mean_tke_diss', 'Mean_tke_visc_diff',\n",
       "       'Mean_tfe_diss', 'Mean_tfe_mol_diff', 'dT/dx', 'dT/dy', 'dT/dx_i_abs',\n",
       "       'S_ij_abs', 'S_11', 'S_12(=S_21)', 'S_22', 'Re', 'Pr', 'PHI-Pr_t_new',\n",
       "       'dTvar/dx_i_abs', 'PHI-Rp/Rd', 'Ui_AVG_n', 'Vi_AVG_n', 'Wi_AVG_n',\n",
       "       'du/dx', 'du/dy', 'dv/dx', 'dv/dy', 'P_AVG_n', '1/Pr', 'local_volume'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Pr_t', 'MKE_visc_diff', 'MKE_pre', 'MTV_diss', 'dp/dy', 'Nu_t_lsq', 'dp/dx_i_abs', 'dp/dx', 'dk/dx_i_abs', 'MTV_mol_diff', 'tke_diss', 'tke', 'MKE_diss'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-fbfa77aa246f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m               \u001b[1;34m'S_ij_abs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'S_22'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m              \u001b[1;34m'S_12(=S_21)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'S_11'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dTvar/dx_i_abs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dT/dy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dT/dx'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dp/dx_i_abs'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dp/dy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'dp/dx'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m              'dk/dx_i_abs','dk/dy','dk/dx','tke_diss','tke','Nu_t_lsq','Pr_t']]\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2922\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2923\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[1;32m-> 2924\u001b[1;33m                                                    raise_missing=True)\n\u001b[0m\u001b[0;32m   2925\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2926\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[0;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[0;32m   1353\u001b[0m                           raise_missing}\n\u001b[1;32m-> 1354\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1355\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[0;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1161\u001b[1;33m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[0;32m   1162\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1250\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'loc'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1252\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not in index\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnot_found\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1254\u001b[0m             \u001b[1;31m# we skip the warning on Categorical/Interval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Pr_t', 'MKE_visc_diff', 'MKE_pre', 'MTV_diss', 'dp/dy', 'Nu_t_lsq', 'dp/dx_i_abs', 'dp/dx', 'dk/dx_i_abs', 'MTV_mol_diff', 'tke_diss', 'tke', 'MKE_diss'] not in index\""
     ]
    }
   ],
   "source": [
    "Data1 = Data[['Re','Pr','MTV_diss','MTV_mol_diff','MKE_diss','MKE_pre','MKE_visc_diff','u_du/dx+v_dv/dx',\n",
    "              'S_ij_abs','S_22',\n",
    "             'S_12(=S_21)','S_11','dTvar/dx_i_abs','dT/dy','dT/dx','dp/dx_i_abs','dp/dy','dp/dx',\n",
    "             'dk/dx_i_abs','dk/dy','dk/dx','tke_diss','tke','Nu_t_lsq','Pr_t']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1 = Data[['Re','Pr','Mean_tfe_diss','Mean_tfe_mol_diff','Mean_tke_diss','Mean_tke_pre_diff','Mean_tke_visc_diff','u_du/dx+v_dv/dx',\n",
    "              'S_ij_abs','S_22',\n",
    "             'S_12(=S_21)','S_11','dTvar/dx_i_abs','dT/dy','dT/dx','dp_dx_i_abs','dp_dy','dp_dx',\n",
    "             'dk_dx_i_abs','dk/dy','dk/dx','tke_diss_n','tke_n','Nu_t_lsq_n','PHI-Pr_t_new']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682898, 25)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1.to_csv(r'D:\\Desktop\\190305\\csvfile\\new\\새 폴더 (2)\\ANN_uniform_channel_all_Re.csv',header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    Dir = '/home/ftmlab/다운로드/ANN_code/case%d_uniform_channel.csv' %(i+1)\n",
    "    Data = pd.read_csv(Dir)\n",
    "    Data1 = Data[['Re','Pr','Mean_tfe_diss','Mean_tfe_mol_diff','Mean_tke_diss','Mean_tke_pre_diff','Mean_tke_visc_diff','u_du/dx+v_dv/dx',\n",
    "              'S_ij_abs','S_22',\n",
    "             'S_12(=S_21)','S_11','dTvar/dx_i_abs','dT/dy','dT/dx','dp_dx_i_abs','dp_dy','dp_dx',\n",
    "             'dk_dx_i_abs','dk/dy','dk/dx','tke_diss_n','tke_n','Nu_t_lsq_n','PHI-Pr_t_new']]\n",
    "    print(Data1.shape)\n",
    "    Data1.to_csv(Dir, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    Dir = '/home/ftmlab/다운로드/ANN_code/case%d_uniform_channel.csv' %(i+1)\n",
    "    Data = pd.read_csv(Dir)\n",
    "    Data.columns = ['Re','Pr','MTV_diss','MTV_mol_diff','MKE_diss','MKE_pre','MKE_visc_diff','u_du/dx+v_dv/dx',\n",
    "              'S_ij_abs','S_22',\n",
    "             'S_12(=S_21)','S_11','dTvar/dx_i_abs','dT/dy','dT/dx','dp/dx_i_abs','dp/dy','dp/dx',\n",
    "             'dk/dx_i_abs','dk/dy','dk/dx','tke_diss','tke','Nu_t_lsq','Pr_t']\n",
    "    Data.to_csv(Dir, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(9):\n",
    "    Dir = '/home/ftmlab/다운로드/ANN_code/case%d_uniform_wedge.csv' %(i+1)\n",
    "    Data = pd.read_csv(Dir)\n",
    "    del Data['Re']\n",
    "    del Data['Pr']\n",
    "    print(Data.shape)\n",
    "    Data.to_csv(Dir, header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(242208, 190)\n",
      "(242208, 137)\n",
      "(179927, 39)\n",
      "(179927, 37)\n",
      "(179927, 26)\n",
      "(179927, 24)\n",
      "(179927, 39)\n",
      "(179927, 37)\n",
      "(179927, 26)\n",
      "(179927, 24)\n",
      "(179927, 39)\n",
      "(179927, 26)\n"
     ]
    }
   ],
   "source": [
    "#영재킴 데이터 추출 \n",
    "############################\n",
    "\n",
    "# \"dT'T'/dx\",\"dT'T'/dy\",\"dTvar/dx_i_abs\"\n",
    "\n",
    "#판다스 모듈 임포트\n",
    "import pandas as pd\n",
    "\n",
    "#데이터 불러오기\n",
    "data=pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\wedge_Re180_Pr0_2.csv')\n",
    "data1=pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\1wedge_Re180_Pr0_2.csv')\n",
    "\n",
    "#데이터 사이즈 확인\n",
    "print(data.shape)\n",
    "print(data1.shape)\n",
    "\n",
    "#X,Y 오름차순 정렬\n",
    "data.sort_values(by=['X','Y'],inplace=True)\n",
    "data1.sort_values(by=['X','Y'],inplace=True)\n",
    "\n",
    "#데이터프레임에 단일값을 가지는 컬럼 추가\n",
    "#data[\"Pr\"]=0.7\n",
    "data[\"Re_tau\"]=0.18\n",
    "\n",
    "#데이터 필터링 과정 Y값이 0.8<Y<1.2 인부분 제외, y_plus가 >3 인 데이터만 추출\n",
    "data=data.drop(data[(data.Y<1.2)&(data.Y>0.8)].index)\n",
    "data=data[data.y_plus>=3]\n",
    "\n",
    "data1=data1.drop(data1[(data1.Y<1.2)&(data1.Y>0.8)].index)\n",
    "data1=data1[data1.y_plus>=3]\n",
    "\n",
    "#데이터에 컬럼 추가\n",
    "data[\"wedge_height\"] = 0.1\n",
    "data[\"1/Pr\"] = 1/data['Pr']\n",
    "data[\"TV\"] = 2*data['PHI-tfe']\n",
    "data['local volume'] = 1\n",
    "\n",
    "#컬럼명을 변경합니다.\n",
    "data = data.rename(columns={'PHI-Alpha_t_lsq': 'Alpha_t','dp_dx':'dp/dx','Mean_tke_pre_diff':'MKE_pre',\n",
    "                            'Mean_tfe_mol_diff':'MTV_mol_diff','Mean_tke_diss':'MKE_diss',\n",
    "                            'Mean_tfe_diss':'MTV_diss','PHI-Rp/Rd':'Rp/Rd',\n",
    "                            'PHI-Pr_t_new':'Pr_t','S_12':'S_12(=S_21)','Mean_tke_visc_diff':'MKE_visc_diff',\n",
    "                            'U_AVG-X':'U-AVG-X','dk_dx_i_abs':'dk/dx_i_abs','dp_dx_i_abs':'dp/dx_i_abs',\n",
    "                            'U_AVG-Z':'U-AVG-Z','dp_dy':'dp/dy','U_AVG-Y':'U-AVG-Y','U_AVG-X':'U-AVG-X',\n",
    "                            'PHI-Rp':'Rp','PHI-Rd':'Rd'\n",
    "                            })\n",
    "\n",
    "data1 = data1.rename(columns={'PHI-tfe_conv_tur':'TV_conv_turb','tke_prod':'tke_prod(nu_t_1_new)',\n",
    "                              'PHI-tfe_diss':'TV_diss','PHI-tfe_prod':'TV_prod(al_t_1)',\n",
    "                              'PHI-tfe_diff':'TV_diff','PHI-tfe_sdm':'TV_sdm',\n",
    "                              'tke_conv_tur':'tke_conv_turb'})\n",
    "\n",
    "\n",
    "\n",
    "#필요한 컬럼만 뽑아냅니다.\n",
    "full_parameter_data1 = data1[['tke_conv_turb', 'TV_conv_turb', 'tke_pre', 'tke_prod(nu_t_1_new)',\n",
    "                              'TV_diss', 'TV_prod(al_t_1)', 'TV_diff', 'tke_diff',\n",
    "                              'TV_sdm', 'tke_sdm'] ]\n",
    "\n",
    "full_parameter_data2 = data[['X','Y','Nu_t_lsq','Alpha_t','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss',\n",
    "                          'TV',\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22',\"Re_tau\",'Pr','Pr_t',\n",
    "                          \"dTvar/dx_i_abs\",\"dT'T'/dx\",\"dT'T'/dy\"]]\n",
    "\n",
    "#각기 두개의 데이터를 합칩니다.\n",
    "full_parameter_data = pd.merge(full_parameter_data1,full_parameter_data2,\n",
    "                               left_on=None, right_on=None, left_index=True, right_index=True)\n",
    "\n",
    "#컬럼을 원하는 순서대로 정렬합니다.\n",
    "final_data=full_parameter_data[['X','Y',\"Re_tau\",'Pr','Nu_t_lsq','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss','TV_prod(al_t_1)','tke_prod(nu_t_1_new)',\n",
    "                          'TV',\"tke_conv_turb\",\"tke_pre\",\"tke_diff\",\n",
    "                          \"TV_conv_turb\",\"TV_diff\",\"TV_diss\",\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22',\n",
    "                          \"dTvar/dx_i_abs\",\"dT'T'/dx\",\"dT'T'/dy\",'Pr_t']]\n",
    "\n",
    "notXY_final_data = full_parameter_data[[\"Re_tau\",'Pr','Nu_t_lsq','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss','+)','tke_prod(nu_t_1_new)',\n",
    "                          'TV',\"tke_conv_turb\",\"tke_pre\",\"tke_diff\",\n",
    "                          \"TV_conv_turb\",\"TV_diff\",\"TV_diss\",\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22',\n",
    "                          \"dTvar/dx_i_abs\",\"dT'T'/dx\",\"dT'T'/dy\",'Pr_t']]\n",
    "\n",
    "reduced_final_data = full_parameter_data[['X','Y','Pr','Nu_t_lsq','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss',\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22','Pr_t']]\n",
    "\n",
    "notXY_reduced_final_data = full_parameter_data[['Pr','Nu_t_lsq','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss',\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22','Pr_t']]\n",
    "\n",
    "#데이터가 잘 뽑혔는지 확인\n",
    "print(final_data.shape)\n",
    "print(notXY_final_data.shape)\n",
    "print(reduced_final_data.shape)\n",
    "print(notXY_reduced_final_data.shape)\n",
    "\n",
    "#데이터값들중에 1000보다 큰값은 제외합니다.\n",
    "final_data = final_data[final_data<1000]\n",
    "final_data = final_data.dropna(axis=0)\n",
    "print(final_data.shape)\n",
    "\n",
    "notXY_final_data = notXY_final_data[notXY_final_data<1000]\n",
    "notXY_final_data = notXY_final_data.dropna(axis=0)\n",
    "print(notXY_final_data.shape)\n",
    "\n",
    "reduced_final_data = reduced_final_data[reduced_final_data<1000]\n",
    "reduced_final_data = reduced_final_data.dropna(axis=0)\n",
    "print(reduced_final_data.shape)\n",
    "\n",
    "notXY_reduced_final_data = notXY_reduced_final_data[notXY_reduced_final_data<1000]\n",
    "notXY_reduced_final_data = notXY_reduced_final_data.dropna(axis=0)\n",
    "print(notXY_reduced_final_data.shape)\n",
    "\n",
    "#X , Y 값들 중복값을 제거합니다.\n",
    "final_data = final_data.drop_duplicates(['X','Y'], keep='last')\n",
    "print(final_data.shape)\n",
    "\n",
    "reduced_final_data = reduced_final_data.drop_duplicates(['X','Y'], keep='last')\n",
    "print(reduced_final_data.shape)\n",
    "\n",
    "\n",
    "# csv 파일을 저장합니다.   header : 컬럼 명 포함   index 행 번호 포함\n",
    "final_data.to_csv(r'D:\\Desktop\\190305\\csvfile\\new\\youngjae_csv\\includeXY_Full_wedge_Re180_Pr0_2.csv', header=True, index=False)\n",
    "notXY_final_data.to_csv(r'D:\\Desktop\\190305\\csvfile\\new\\youngjae_csv\\Full_wedge_Re180_Pr0_2.csv', header=True, index=False)\n",
    "reduced_final_data.to_csv(r'D:\\Desktop\\190305\\csvfile\\new\\youngjae_csv\\includeXY_Reduced_wedge_Re180_Pr0_2.csv', header=True, index=False)\n",
    "notXY_reduced_final_data.to_csv(r'D:\\Desktop\\190305\\csvfile\\new\\youngjae_csv\\Reduced_wedge_Re180_Pr0_2.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179927, 39)\n",
      "(179927, 37)\n",
      "(179927, 26)\n",
      "(179927, 24)\n",
      "(179927, 39)\n",
      "(179927, 37)\n",
      "(179927, 26)\n",
      "(179927, 24)\n",
      "(179927, 39)\n",
      "(179927, 26)\n"
     ]
    }
   ],
   "source": [
    "#데이터 불러오기\n",
    "data=pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\wedge_Re180_Pr0_7.csv')\n",
    "data1=pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\1wedge_Re180_Pr0_7.csv')\n",
    "\n",
    "#X,Y 오름차순 정렬\n",
    "data.sort_values(by=['X','Y'],inplace=True)\n",
    "data1.sort_values(by=['X','Y'],inplace=True)\n",
    "\n",
    "#데이터프레임에 단일값을 가지는 컬럼 추가\n",
    "#data[\"Pr\"]=0.7\n",
    "data[\"Re_tau\"]=0.18\n",
    "\n",
    "#데이터 필터링 과정 Y값이 0.8<Y<1.2 인부분 제외, y_plus가 >3 인 데이터만 추출\n",
    "data=data.drop(data[(data.Y<1.2)&(data.Y>0.8)].index)\n",
    "data=data[data.y_plus>=3]\n",
    "\n",
    "data.shape\n",
    "\n",
    "data1=data1.drop(data1[(data1.Y<1.2)&(data1.Y>0.8)].index)\n",
    "data1=data1[data1.y_plus>=3]\n",
    "\n",
    "data1.shape\n",
    "\n",
    "data[\"wedge_height\"] = 0.1\n",
    "data[\"1/Pr\"] = 1/data['Pr']\n",
    "data[\"TV\"] = 2*data['PHI_2-tfe']\n",
    "data['local volume'] = 1\n",
    "data = data.rename(columns={'PHI_2-Alpha_t_lsq': 'Alpha_t','dp_dx':'dp/dx','Mean_tke_pre_diff':'MKE_pre',\n",
    "                            'Mean_tfe_mol_diff':'MTV_mol_diff','Mean_tke_diss':'MKE_diss',\n",
    "                            'U_AVG-Y':'U-AVG-Y','Mean_tfe_diss':'MTV_diss','PHI_2-Rp/Rd':'Rp/Rd',\n",
    "                            'PHI_2-Pr_t_new':'Pr_t','S_12':'S_12(=S_21)','Mean_tke_visc_diff':'MKE_visc_diff',\n",
    "                            'U_AVG-X':'U-AVG-X','dk_dx_i_abs':'dk/dx_i_abs','dp_dx_i_abs':'dp/dx_i_abs',\n",
    "                            'U_AVG-Z':'U-AVG-Z','dp_dy':'dp/dy',\n",
    "                            'PHI_2-Rp':'Rp','PHI_2-Rd':'Rd'\n",
    "                            })\n",
    "\n",
    "data1 = data1.rename(columns={'PHI_2-tfe_conv_tur':'TV_conv_turb','tke_prod':'tke_prod(nu_t_1_new)',\n",
    "                              'PHI_2-tfe_diss':'TV_diss','PHI_2-tfe_prod':'TV_prod(al_t_1)',\n",
    "                              'PHI_2-tfe_diff':'TV_diff','PHI_2-tfe_sdm':'TV_sdm',\n",
    "                              'tke_conv_tur':'tke_conv_turb'})\n",
    "\n",
    "\n",
    "\n",
    "#full parameter \n",
    "\n",
    "full_parameter_data1 = data1[['tke_conv_turb', 'TV_conv_turb', 'tke_pre', 'tke_prod(nu_t_1_new)',\n",
    "                              'TV_diss', 'TV_prod(al_t_1)', 'TV_diff', 'tke_diff',\n",
    "                              'TV_sdm', 'tke_sdm'] ]\n",
    "\n",
    "full_parameter_data2 = data[['X','Y','Nu_t_lsq','tke','dk/dx','dk/dy','dk/dx_i_abs','tke_diss',\n",
    "                          'TV',\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22',\"Re_tau\",'Pr','Pr_t',\n",
    "                          \"dTvar/dx_i_abs\",\"dT'T'/dx\",\"dT'T'/dy\"]]\n",
    "full_parameter_data = pd.merge(full_parameter_data1,full_parameter_data2,\n",
    "                               left_on=None, right_on=None, left_index=True, right_index=True)\n",
    "\n",
    "#컬럼을 원하는 순서대로 정렬합니다.\n",
    "final_data=full_parameter_data[['X','Y',\"Re_tau\",'Pr','Nu_t_lsq','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss','TV_prod(al_t_1)','tke_prod(nu_t_1_new)',\n",
    "                          'TV',\"tke_conv_turb\",\"tke_pre\",\"tke_diff\",\n",
    "                          \"TV_conv_turb\",\"TV_diff\",\"TV_diss\",\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22',\n",
    "                          \"dTvar/dx_i_abs\",\"dT'T'/dx\",\"dT'T'/dy\",'Pr_t']]\n",
    "\n",
    "notXY_final_data = full_parameter_data[[\"Re_tau\",'Pr','Nu_t_lsq','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss','TV_prod(al_t_1)','tke_prod(nu_t_1_new)',\n",
    "                          'TV',\"tke_conv_turb\",\"tke_pre\",\"tke_diff\",\n",
    "                          \"TV_conv_turb\",\"TV_diff\",\"TV_diss\",\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22',\n",
    "                          \"dTvar/dx_i_abs\",\"dT'T'/dx\",\"dT'T'/dy\",'Pr_t']]\n",
    "\n",
    "reduced_final_data = full_parameter_data[['X','Y','Pr','Nu_t_lsq','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss',\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22','Pr_t']]\n",
    "\n",
    "notXY_reduced_final_data = full_parameter_data[['Pr','Nu_t_lsq','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss',\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22','Pr_t']]\n",
    "\n",
    "#데이터가 잘 뽑혔는지 확인\n",
    "print(final_data.shape)\n",
    "print(notXY_final_data.shape)\n",
    "print(reduced_final_data.shape)\n",
    "print(notXY_reduced_final_data.shape)\n",
    "\n",
    "#데이터값들중에 1000보다 큰값은 제외합니다.\n",
    "final_data = final_data[final_data<1000]\n",
    "final_data = final_data.dropna(axis=0)\n",
    "print(final_data.shape)\n",
    "\n",
    "notXY_final_data = notXY_final_data[notXY_final_data<1000]\n",
    "notXY_final_data = notXY_final_data.dropna(axis=0)\n",
    "print(notXY_final_data.shape)\n",
    "\n",
    "reduced_final_data = reduced_final_data[reduced_final_data<1000]\n",
    "reduced_final_data = reduced_final_data.dropna(axis=0)\n",
    "print(reduced_final_data.shape)\n",
    "\n",
    "notXY_reduced_final_data = notXY_reduced_final_data[notXY_reduced_final_data<1000]\n",
    "notXY_reduced_final_data = notXY_reduced_final_data.dropna(axis=0)\n",
    "print(notXY_reduced_final_data.shape)\n",
    "\n",
    "#X , Y 값들 중복값을 제거합니다.\n",
    "final_data = final_data.drop_duplicates(['X','Y'], keep='last')\n",
    "print(final_data.shape)\n",
    "\n",
    "reduced_final_data = reduced_final_data.drop_duplicates(['X','Y'], keep='last')\n",
    "print(reduced_final_data.shape)\n",
    "\n",
    "\n",
    "# csv 파일을 저장합니다.   header : 컬럼 명 포함   index 행 번호 포함\n",
    "final_data.to_csv(r'D:\\Desktop\\190305\\csvfile\\new\\youngjae_csv\\includeXY_Full_wedge_Re1800_Pr0_7.csv', header=True, index=False)\n",
    "notXY_final_data.to_csv(r'D:\\Desktop\\190305\\csvfile\\new\\youngjae_csv\\Full_wedge_Re180_Pr0_7.csv', header=True, index=False)\n",
    "reduced_final_data.to_csv(r'D:\\Desktop\\190305\\csvfile\\new\\youngjae_csv\\includeXY_Reduced_wedge_Re180_Pr0_7.csv', header=True, index=False)\n",
    "notXY_reduced_final_data.to_csv(r'D:\\Desktop\\190305\\csvfile\\new\\youngjae_csv\\Reduced_wedge_Re180_Pr0_7.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(179927, 39)\n",
      "(179927, 37)\n",
      "(179927, 26)\n",
      "(179927, 24)\n",
      "(179927, 39)\n",
      "(179927, 37)\n",
      "(179927, 26)\n",
      "(179927, 24)\n",
      "(179927, 39)\n",
      "(179927, 26)\n"
     ]
    }
   ],
   "source": [
    "#데이터 불러오기\n",
    "data=pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\wedge_Re180_Pr2_0.csv')\n",
    "data1=pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\1wedge_Re180_Pr2_0.csv')\n",
    "\n",
    "#X,Y 오름차순 정렬\n",
    "data.sort_values(by=['X','Y'],inplace=True)\n",
    "data1.sort_values(by=['X','Y'],inplace=True)\n",
    "\n",
    "#데이터프레임에 단일값을 가지는 컬럼 추가\n",
    "#data[\"Pr\"]=0.7\n",
    "data[\"Re_tau\"]=0.18\n",
    "\n",
    "#데이터 필터링 과정 Y값이 0.8<Y<1.2 인부분 제외, y_plus가 >3 인 데이터만 추출\n",
    "data=data.drop(data[(data.Y<1.2)&(data.Y>0.8)].index)\n",
    "data=data[data.y_plus>=3]\n",
    "\n",
    "data.shape\n",
    "\n",
    "data1=data1.drop(data1[(data1.Y<1.2)&(data1.Y>0.8)].index)\n",
    "data1=data1[data1.y_plus>=3]\n",
    "\n",
    "data1.shape\n",
    "\n",
    "data[\"wedge_height\"] = 0.1\n",
    "data[\"1/Pr\"] = 1/data['Pr']\n",
    "data[\"TV\"] = 2*data['PHI_3-tfe']\n",
    "data['local volume'] = 1\n",
    "data = data.rename(columns={'PHI_3-Alpha_t_lsq': 'Alpha_t','dp_dx':'dp/dx','Mean_tke_pre_diff':'MKE_pre',\n",
    "                            'Mean_tfe_mol_diff':'MTV_mol_diff','Mean_tke_diss':'MKE_diss','dp_dx':'dp/dx',\n",
    "                            'U_AVG-Y':'U-AVG-Y','Mean_tfe_diss':'MTV_diss','PHI_3-Rp/Rd':'Rp/Rd',\n",
    "                            'PHI_3-Pr_t_new':'Pr_t','S_12':'S_12(=S_21)','Mean_tke_visc_diff':'MKE_visc_diff',\n",
    "                            'U_AVG-X':'U-AVG-X','dk_dx_i_abs':'dk/dx_i_abs','dp_dx_i_abs':'dp/dx_i_abs',\n",
    "                            'U_AVG-Z':'U-AVG-Z','dp_dy':'dp/dy','U_AVG-Y':'U-AVG-Y','U_AVG-X':'U-AVG-X',\n",
    "                            'PHI_3-Rp':'Rp','PHI_3-Rd':'Rd'\n",
    "                            })\n",
    "\n",
    "data1 = data1.rename(columns={'PHI_3-tfe_conv_tur':'TV_conv_turb','tke_prod':'tke_prod(nu_t_1_new)',\n",
    "                              'PHI_3-tfe_diss':'TV_diss','PHI_3-tfe_prod':'TV_prod(al_t_1)',\n",
    "                              'PHI_3-tfe_diff':'TV_diff','PHI_3-tfe_sdm':'TV_sdm',\n",
    "                              'tke_conv_tur':'tke_conv_turb'})\n",
    "\n",
    "\n",
    "\n",
    "#full parameter \n",
    "\n",
    "full_parameter_data1 = data1[['tke_conv_turb', 'TV_conv_turb', 'tke_pre', 'tke_prod(nu_t_1_new)',\n",
    "                              'TV_diss', 'TV_prod(al_t_1)', 'TV_diff', 'tke_diff',\n",
    "                              'TV_sdm', 'tke_sdm'] ]\n",
    "\n",
    "full_parameter_data2 = data[['X','Y','Nu_t_lsq','tke','dk/dx','dk/dy','dk/dx_i_abs','tke_diss',\n",
    "                          'TV',\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22',\"Re_tau\",'Pr','Pr_t',\n",
    "                          \"dTvar/dx_i_abs\",\"dT'T'/dx\",\"dT'T'/dy\"]]\n",
    "full_parameter_data = pd.merge(full_parameter_data1,full_parameter_data2,\n",
    "                               left_on=None, right_on=None, left_index=True, right_index=True)\n",
    "\n",
    "#컬럼을 원하는 순서대로 정렬합니다.\n",
    "final_data=full_parameter_data[['X','Y',\"Re_tau\",'Pr','Nu_t_lsq','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss','TV_prod(al_t_1)','tke_prod(nu_t_1_new)',\n",
    "                          'TV',\"tke_conv_turb\",\"tke_pre\",\"tke_diff\",\n",
    "                          \"TV_conv_turb\",\"TV_diff\",\"TV_diss\",\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22',\n",
    "                          \"dTvar/dx_i_abs\",\"dT'T'/dx\",\"dT'T'/dy\",'Pr_t']]\n",
    "\n",
    "notXY_final_data = full_parameter_data[[\"Re_tau\",'Pr','Nu_t_lsq','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss','TV_prod(al_t_1)','tke_prod(nu_t_1_new)',\n",
    "                          'TV',\"tke_conv_turb\",\"tke_pre\",\"tke_diff\",\n",
    "                          \"TV_conv_turb\",\"TV_diff\",\"TV_diss\",\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22',\n",
    "                          \"dTvar/dx_i_abs\",\"dT'T'/dx\",\"dT'T'/dy\",'Pr_t']]\n",
    "\n",
    "reduced_final_data = full_parameter_data[['X','Y','Pr','Nu_t_lsq','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss',\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22','Pr_t']]\n",
    "\n",
    "notXY_reduced_final_data = full_parameter_data[['Pr','Nu_t_lsq','tke','dk/dx','dk/dy',\n",
    "                          'dk/dx_i_abs','tke_diss',\"dp/dx\",\"dp/dy\",\"dp/dx_i_abs\",\"u_du/dx+v_dv/dx\",\n",
    "                          \"MKE_pre\",\"MKE_diss\",\"MKE_visc_diff\",\"MTV_diss\",\"MTV_mol_diff\",\n",
    "                          \"dT/dx\",\"dT/dy\",\"dT/dx_i_abs\",\"S_ij_abs\",\"S_11\",'S_12(=S_21)','S_22','Pr_t']]\n",
    "\n",
    "#데이터가 잘 뽑혔는지 확인\n",
    "print(final_data.shape)\n",
    "print(notXY_final_data.shape)\n",
    "print(reduced_final_data.shape)\n",
    "print(notXY_reduced_final_data.shape)\n",
    "\n",
    "#데이터값들중에 1000보다 큰값은 제외합니다.\n",
    "final_data = final_data[final_data<1000]\n",
    "final_data = final_data.dropna(axis=0)\n",
    "print(final_data.shape)\n",
    "\n",
    "notXY_final_data = notXY_final_data[notXY_final_data<1000]\n",
    "notXY_final_data = notXY_final_data.dropna(axis=0)\n",
    "print(notXY_final_data.shape)\n",
    "\n",
    "reduced_final_data = reduced_final_data[reduced_final_data<1000]\n",
    "reduced_final_data = reduced_final_data.dropna(axis=0)\n",
    "print(reduced_final_data.shape)\n",
    "\n",
    "notXY_reduced_final_data = notXY_reduced_final_data[notXY_reduced_final_data<1000]\n",
    "notXY_reduced_final_data = notXY_reduced_final_data.dropna(axis=0)\n",
    "print(notXY_reduced_final_data.shape)\n",
    "\n",
    "#X , Y 값들 중복값을 제거합니다.\n",
    "final_data = final_data.drop_duplicates(['X','Y'], keep='last')\n",
    "print(final_data.shape)\n",
    "\n",
    "reduced_final_data = reduced_final_data.drop_duplicates(['X','Y'], keep='last')\n",
    "print(reduced_final_data.shape)\n",
    "\n",
    "\n",
    "# csv 파일을 저장합니다.   header : 컬럼 명 포함   index 행 번호 포함\n",
    "final_data.to_csv(r'D:\\Desktop\\190305\\csvfile\\new\\youngjae_csv\\includeXY_Full_wedge_Re180_Pr2_0.csv', header=True, index=False)\n",
    "notXY_final_data.to_csv(r'D:\\Desktop\\190305\\csvfile\\new\\youngjae_csv\\Full_wedge_Re180_Pr2_0.csv', header=True, index=False)\n",
    "reduced_final_data.to_csv(r'D:\\Desktop\\190305\\csvfile\\new\\youngjae_csv\\includeXY_Reduced_wedge_Re180_Pr2_0.csv', header=True, index=False)\n",
    "notXY_reduced_final_data.to_csv(r'D:\\Desktop\\190305\\csvfile\\new\\youngjae_csv\\Reduced_wedge_Re180_Pr2_0.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X', 'Y', 'Z', 'Nu_t_lsq', 'PHI-Alpha_t_lsq', 'PHI-Pr_t', 'nu_t_1',\n",
       "       'nu_t_2', 'u_tau', 'y_plus',\n",
       "       ...\n",
       "       'dv/dx', 'dv/dy', 'd2T/dy2', 'dT/dn', 'dT'T'/dx', 'dT'T'/dy',\n",
       "       'dT'T'/dx_i', 'u_du/dx', 'u_du/dx+v_dv/dy', 'Unnamed: 189'],\n",
       "      dtype='object', length=190)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Nu_t_lsq</th>\n",
       "      <th>PHI_2-Alpha_t_lsq</th>\n",
       "      <th>PHI_2-Pr_t</th>\n",
       "      <th>nu_t_1</th>\n",
       "      <th>nu_t_2</th>\n",
       "      <th>u_tau</th>\n",
       "      <th>y_plus</th>\n",
       "      <th>...</th>\n",
       "      <th>U'T'_AVG</th>\n",
       "      <th>V'T'_AVG</th>\n",
       "      <th>Mean_tfe_mol_diff</th>\n",
       "      <th>Mean_tfe_diss</th>\n",
       "      <th>tfe_prod</th>\n",
       "      <th>Nu_t_ke</th>\n",
       "      <th>Pr_t_ke</th>\n",
       "      <th>Rp</th>\n",
       "      <th>Rd</th>\n",
       "      <th>Unnamed: 177</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.64025</td>\n",
       "      <td>0.639543</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>0.004269</td>\n",
       "      <td>0.005290</td>\n",
       "      <td>0.806991</td>\n",
       "      <td>0.000606</td>\n",
       "      <td>0.141913</td>\n",
       "      <td>0.064603</td>\n",
       "      <td>118.606</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002624</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.715946</td>\n",
       "      <td>-0.619547</td>\n",
       "      <td>0.795028</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.61103</td>\n",
       "      <td>0.638884</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>0.004260</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.805154</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.143142</td>\n",
       "      <td>0.064651</td>\n",
       "      <td>119.529</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002625</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>-0.622896</td>\n",
       "      <td>0.801355</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.61103</td>\n",
       "      <td>0.650170</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>0.004215</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.805495</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.136506</td>\n",
       "      <td>0.065064</td>\n",
       "      <td>122.291</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002580</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.003737</td>\n",
       "      <td>0.714078</td>\n",
       "      <td>-0.590424</td>\n",
       "      <td>0.761443</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.64025</td>\n",
       "      <td>0.650824</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>0.004224</td>\n",
       "      <td>0.005231</td>\n",
       "      <td>0.807487</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.135337</td>\n",
       "      <td>0.065405</td>\n",
       "      <td>123.783</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002580</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.003736</td>\n",
       "      <td>0.714195</td>\n",
       "      <td>-0.587205</td>\n",
       "      <td>0.755269</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.61103</td>\n",
       "      <td>0.627708</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>0.004302</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.804463</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.149835</td>\n",
       "      <td>0.064481</td>\n",
       "      <td>116.602</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002668</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>0.717321</td>\n",
       "      <td>-0.656530</td>\n",
       "      <td>0.843661</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 178 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X         Y         Z  Nu_t_lsq  PHI_2-Alpha_t_lsq  PHI_2-Pr_t  \\\n",
       "0  5.64025  0.639543  0.008181  0.004269           0.005290    0.806991   \n",
       "1  5.61103  0.638884  0.008181  0.004260           0.005291    0.805154   \n",
       "2  5.61103  0.650170  0.008181  0.004215           0.005233    0.805495   \n",
       "3  5.64025  0.650824  0.008181  0.004224           0.005231    0.807487   \n",
       "4  5.61103  0.627708  0.008181  0.004302           0.005348    0.804463   \n",
       "\n",
       "     nu_t_1    nu_t_2     u_tau   y_plus  ...  U'T'_AVG  V'T'_AVG  \\\n",
       "0  0.000606  0.141913  0.064603  118.606  ... -0.002624  0.001296   \n",
       "1  0.000610  0.143142  0.064651  119.529  ... -0.002625  0.001296   \n",
       "2  0.000575  0.136506  0.065064  122.291  ... -0.002580  0.001290   \n",
       "3  0.000572  0.135337  0.065405  123.783  ... -0.002580  0.001290   \n",
       "4  0.000645  0.149835  0.064481  116.602  ... -0.002668  0.001301   \n",
       "\n",
       "   Mean_tfe_mol_diff  Mean_tfe_diss  tfe_prod   Nu_t_ke   Pr_t_ke        Rp  \\\n",
       "0          -0.000010      -0.000028  0.000339  0.003787  0.715946 -0.619547   \n",
       "1          -0.000009      -0.000028  0.000339  0.003788  0.715909 -0.622896   \n",
       "2          -0.000007      -0.000028  0.000339  0.003737  0.714078 -0.590424   \n",
       "3          -0.000007      -0.000028  0.000339  0.003736  0.714195 -0.587205   \n",
       "4          -0.000009      -0.000027  0.000339  0.003836  0.717321 -0.656530   \n",
       "\n",
       "         Rd  Unnamed: 177  \n",
       "0  0.795028           NaN  \n",
       "1  0.801355           NaN  \n",
       "2  0.761443           NaN  \n",
       "3  0.755269           NaN  \n",
       "4  0.843661           NaN  \n",
       "\n",
       "[5 rows x 178 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = pd.read_csv(r'D:\\Desktop\\190925\\wedge_pr_t\\csv_file\\full_orig_wedge_Re180_Pr07.csv')\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X', 'Y', 'Z', 'Nu_t_lsq', 'PHI_2-Alpha_t_lsq', 'PHI_2-Pr_t', 'nu_t_1',\n",
       "       'nu_t_2', 'u_tau', 'y_plus',\n",
       "       ...\n",
       "       'U'T'_AVG', 'V'T'_AVG', 'Mean_tfe_mol_diff', 'Mean_tfe_diss',\n",
       "       'tfe_prod', 'Nu_t_ke', 'Pr_t_ke', 'Rp', 'Rd', 'Unnamed: 177'],\n",
       "      dtype='object', length=178)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116802, 178)\n",
      "(110767, 180)\n",
      "(90655, 180)\n"
     ]
    }
   ],
   "source": [
    "Data.sort_values(by=['X','Y'], ascending=True, inplace=True)\n",
    "print(Data.shape)\n",
    "Data = Data.drop_duplicates(['X','Y'], keep='last')\n",
    "Data['Re'] = 0.18\n",
    "Data['Pr'] = 0.7\n",
    "print(Data.shape)\n",
    "\n",
    "Data.drop(Data[(Data.Y<1.2) & (Data.Y>0.8)].index, inplace=True)\n",
    "Data = Data[Data.y_plus >= 3]\n",
    "Data = Data[Data['Pr_t_new'] < 5]\n",
    "print(Data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X', 'Y', 'Z', 'Nu_t_lsq', 'PHI_2-Alpha_t_lsq', 'PHI_2-Pr_t', 'nu_t_1',\n",
       "       'nu_t_2', 'u_tau', 'y_plus',\n",
       "       ...\n",
       "       'Mean_tfe_mol_diff', 'Mean_tfe_diss', 'tfe_prod', 'Nu_t_ke', 'Pr_t_ke',\n",
       "       'Rp', 'Rd', 'Unnamed: 177', 'Re', 'Pr'],\n",
       "      dtype='object', length=180)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90655, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data1 = pd.DataFrame()\n",
    "Data1['Nu_t_lsq'] = Data['Nu_t_lsq']\n",
    "Data1['tke'] = Data['tke']\n",
    "Data1['tke_diss'] = Data['tke_diss']\n",
    "Data1['dk/dx'] = Data['dk/dx']\n",
    "Data1['dk/dy'] = Data['dk/dy']\n",
    "Data1['dk/dx_i'] = Data['dk/dx_i']\n",
    "Data1['dp_dx'] = Data['dp_dx']\n",
    "Data1['dp_dy'] = Data['dp_dy']\n",
    "Data1['dp_dx_i'] = Data['dp_dx_i']\n",
    "Data1['dT/dx'] = Data['dT/dx']\n",
    "Data1['dT/dy'] = Data['dT/dy']\n",
    "Data1['dT/dx_i'] = Data['dT/dx_i']\n",
    "Data1['S_11'] = Data['S_11']\n",
    "Data1['S_12'] = Data['S_12']\n",
    "Data1['S_22'] = Data['S_22']\n",
    "Data1['S_ij_abs'] = Data['S_ij_abs']\n",
    "Data1['u_du/dx+v_dv/dx'] = Data['u_du/dx+v_dv/dx']\n",
    "Data1['MKE_diff'] = Data['Mean_tke_mol_diff']\n",
    "Data1['MKE_pre'] = Data['Mean_tke_pre_diff']\n",
    "Data1['MKE_diss'] = Data['Mean_tke_diss']\n",
    "Data1['MTV_diff'] = Data['Mean_tfe_mol_diff']\n",
    "Data1['MTV_diss'] = Data['Mean_tfe_diss']\n",
    "Data1['Re_tau'] = Data['Re']\n",
    "Data1['Pr'] = Data['Pr']\n",
    "Data1['Pr_t'] = Data['Pr_t_new']\n",
    "Data1['X'] = Data['X']\n",
    "Data1['Y'] = Data['Y']\n",
    "Data1['Alpha_t_lsq'] = Data['PHI_2-Alpha_t_lsq']\n",
    "Data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1.to_csv(r'D:\\Desktop\\190925\\wedge_pr_t\\csv_file\\RANS_wedge_Re180_Pr07.csv',header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "      <th>Nu_t_lsq</th>\n",
       "      <th>PHI-Alpha_t_lsq</th>\n",
       "      <th>PHI-Pr_t</th>\n",
       "      <th>nu_t_1</th>\n",
       "      <th>nu_t_2</th>\n",
       "      <th>u_tau</th>\n",
       "      <th>y_plus</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean_tfe_mol_diff</th>\n",
       "      <th>Mean_tfe_diss</th>\n",
       "      <th>tfe_prod</th>\n",
       "      <th>Nu_t_ke</th>\n",
       "      <th>Pr_t_ke</th>\n",
       "      <th>Rp</th>\n",
       "      <th>Rd</th>\n",
       "      <th>Unnamed: 177</th>\n",
       "      <th>Re</th>\n",
       "      <th>Pr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 180 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [X, Y, Z, Nu_t_lsq, PHI-Alpha_t_lsq, PHI-Pr_t, nu_t_1, nu_t_2, u_tau, y_plus, no_volume_cc, PHI-tfe, PHI-tfe_prod, PHI-tfe_diss, PHI-al_t_1, PHI-al_t_2, tke, tke_prod, tke_diss, P_AVG, P_RMS, PHI_AVG, PHI_RMS, PHI_2_AVG, PHI_2_RMS, PHI_3_AVG, PHI_3_RMS, UV_AVG, UV_RMS, UW_AVG, UW_RMS, VW_AVG, VW_RMS, PU_AVG, PU_RMS, PV_AVG, PV_RMS, PW_AVG, PW_RMS, UUU1_AVG, UUU1_RMS, UUU2_AVG, UUU2_RMS, UUU3_AVG, UUU3_RMS, dU1dx1_AVG, dU1dx1_RMS, dU1dx2_AVG, dU1dx2_RMS, dU1dx3_AVG, dU1dx3_RMS, dU2dx1_AVG, dU2dx1_RMS, dU2dx2_AVG, dU2dx2_RMS, dU2dx3_AVG, dU2dx3_RMS, dU3dx1_AVG, dU3dx1_RMS, dU3dx2_AVG, dU3dx2_RMS, dU3dx3_AVG, dU3dx3_RMS, S_11_bud_AVG, S_11_bud_RMS, S_22_bud_AVG, S_22_bud_RMS, S_33_bud_AVG, S_33_bud_RMS, S_12_bud_AVG, S_12_bud_RMS, S_13_bud_AVG, S_13_bud_RMS, S_23_bud_AVG, S_23_bud_RMS, PHI-TU_AVG, PHI-TU_RMS, PHI-TV_AVG, PHI-TV_RMS, PHI-TW_AVG, PHI-TW_RMS, PHI-dTdx1_AVG, PHI-dTdx1_RMS, PHI-dTdx2_AVG, PHI-dTdx2_RMS, PHI-dTdx3_AVG, PHI-dTdx3_RMS, PHI-TTU_AVG, PHI-TTU_RMS, PHI-TTV_AVG, PHI-TTV_RMS, PHI-TTW_AVG, PHI-TTW_RMS, PHI_2-TU_AVG, PHI_2-TU_RMS, PHI_2-TV_AVG, PHI_2-TV_RMS, PHI_2-TW_AVG, PHI_2-TW_RMS, PHI_2-dTdx1_AVG, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 180 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1 = Data[Data['PHI-Pr_t']<0.1]\n",
    "data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
