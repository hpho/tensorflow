{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048 train samples\n",
      "262 validation samples\n",
      "328 test samples\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'D:\\Desktop\\190305\\csvfile\\new\\새 폴더 (3)\\0D_mean_orig_channel.csv')\n",
    "# x = data[data.columns[:-1]]\n",
    "# y = data[data.columns[-1:]]\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train),'train samples')\n",
    "print(len(val),'validation samples')\n",
    "print(len(test),'test samples')\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      X         Y     y_plus  wedge_height  Nu_t_lsq   Alpha_t       tke  \\\n",
      "480   0  0.109657   19.73830             0  0.000854  0.000788  0.011838   \n",
      "669   0  0.175166   70.06630             0  0.002836  0.002662  0.006715   \n",
      "382   0  0.082853   33.14130             0  0.001106  0.001138  0.008983   \n",
      "797   0  0.224752   40.45530             0  0.003154  0.003111  0.008225   \n",
      "758   0  0.208387  122.94800             0  0.002899  0.003342  0.005850   \n",
      "157   0  0.033877   13.55100             0  0.000172  0.000178  0.010383   \n",
      "1543  0  0.718146  287.25900             0  0.003269  0.004157  0.002524   \n",
      "1186  0  0.441538   79.47690             0  0.004791  0.004985  0.005143   \n",
      "1424  0  0.618699  365.03300             0  0.003684  0.004416  0.002995   \n",
      "392   0  0.084843   15.27180             0  0.000484  0.000500  0.012198   \n",
      "905   0  0.278109  111.24400             0  0.003621  0.004065  0.005582   \n",
      "1358  0  0.565705  333.76600             0  0.003761  0.004484  0.003319   \n",
      "43    0  0.014945    8.81779             0  0.000044  0.000043  0.007740   \n",
      "331   0  0.069991   12.59840             0  0.000311  0.000317  0.011796   \n",
      "772   0  0.214806   85.92260             0  0.003231  0.003573  0.006209   \n",
      "1403  0  0.600781  354.46100             0  0.003721  0.004464  0.003103   \n",
      "497   0  0.114107   20.53930             0  0.000930  0.000964  0.011706   \n",
      "1046  0  0.356265  142.50600             0  0.003942  0.004531  0.004956   \n",
      "664   0  0.172316  101.66600             0  0.002589  0.002604  0.006189   \n",
      "1454  0  0.642966  379.35000             0  0.003627  0.004346  0.002851   \n",
      "423   0  0.094733   37.89330             0  0.001385  0.001243  0.008519   \n",
      "614   0  0.153131   90.34750             0  0.002387  0.002623  0.006398   \n",
      "1408  0  0.606727  242.69100             0  0.003643  0.004554  0.003204   \n",
      "1094  0  0.383448  226.23400             0  0.003676  0.004468  0.004519   \n",
      "955   0  0.305515  180.25400             0  0.003428  0.003736  0.005079   \n",
      "1353  0  0.565705  226.28200             0  0.003779  0.004160  0.003478   \n",
      "100   0  0.024636   14.53520             0  0.000139  0.000133  0.009632   \n",
      "1040  0  0.351852  140.74100             0  0.003930  0.004514  0.004989   \n",
      "463   0  0.105231   42.09240             0  0.001626  0.001657  0.008169   \n",
      "63    0  0.018475    7.38993             0  0.000040  0.000039  0.007043   \n",
      "...  ..       ...        ...           ...       ...       ...       ...   \n",
      "1056  0  0.360711  212.82000             0  0.003620  0.004279  0.004677   \n",
      "230   0  0.048422   19.36880             0  0.000380  0.000389  0.010521   \n",
      "516   0  0.120887   71.32330             0  0.001963  0.002049  0.006824   \n",
      "939   0  0.297522  119.00900             0  0.003720  0.003849  0.005418   \n",
      "951   0  0.301502  177.88600             0  0.003412  0.003993  0.005109   \n",
      "1099  0  0.388097  228.97700             0  0.003683  0.004063  0.004487   \n",
      "380   0  0.082853   33.14130             0  0.001106  0.001107  0.008983   \n",
      "445   0  0.100965   59.56940             0  0.001640  0.001530  0.007179   \n",
      "1034  0  0.347473  205.00900             0  0.003576  0.004325  0.004771   \n",
      "1419  0  0.618699  247.48000             0  0.003593  0.004028  0.003125   \n",
      "1254  0  0.493405  197.36200             0  0.003914  0.004298  0.003974   \n",
      "565   0  0.137719   81.25440             0  0.002200  0.002135  0.006586   \n",
      "1196  0  0.451571  180.62800             0  0.003969  0.004735  0.004267   \n",
      "831   0  0.241694  142.59900             0  0.003118  0.003569  0.005566   \n",
      "1448  0  0.636860  375.74800             0  0.003643  0.004365  0.002887   \n",
      "1368  0  0.577282  230.91300             0  0.003748  0.004133  0.003400   \n",
      "1393  0  0.594864  237.94600             0  0.003690  0.004594  0.003283   \n",
      "1175  0  0.436423  174.56900             0  0.003984  0.004731  0.004374   \n",
      "1431  0  0.624726  368.58900             0  0.003671  0.004319  0.002959   \n",
      "1039  0  0.351852  207.59300             0  0.003591  0.003943  0.004739   \n",
      "932   0  0.289757   52.15620             0  0.004088  0.004037  0.006983   \n",
      "1545  0  0.718210  129.27800             0  0.004186  0.004292  0.002999   \n",
      "897   0  0.274324  161.85100             0  0.003301  0.003814  0.005313   \n",
      "1510  0  0.692713  408.70100             0  0.003464  0.003824  0.002563   \n",
      "1294  0  0.520594  307.15100             0  0.003732  0.004167  0.003608   \n",
      "1214  0  0.461834  272.48200             0  0.003734  0.004533  0.003996   \n",
      "109   0  0.025911   15.28760             0  0.000155  0.000148  0.009691   \n",
      "1590  0  0.756981  136.25700             0  0.004096  0.004212  0.002777   \n",
      "1421  0  0.618699  247.48000             0  0.003593  0.004395  0.003125   \n",
      "45    0  0.014945    8.81779             0  0.000044  0.000045  0.007740   \n",
      "\n",
      "             dk/dx     dk/dy  dk/dx_i_abs  ...  dTvar/dx_i_abs     Rp/Rd  \\\n",
      "480  -3.350000e-08  0.000245     0.027819  ...        0.018880  1.077800   \n",
      "669   2.130000e-10 -0.000439     0.014542  ...        0.002768  1.065414   \n",
      "382  -6.480000e-10 -0.000109     0.042275  ...        0.020562  0.971734   \n",
      "797   1.250000e-09 -0.000188     0.023411  ...        0.006890  1.012778   \n",
      "758   3.880000e-10  0.000358     0.008865  ...        0.000075  0.867687   \n",
      "157  -2.260000e-08 -0.000339     0.072903  ...        0.036061  0.965515   \n",
      "1543 -1.280000e-09  0.000154     0.005482  ...        0.003883  0.785583   \n",
      "1186 -1.160000e-09  0.000228     0.009816  ...        0.002318  0.960814   \n",
      "1424  3.050000e-09 -0.000358     0.005991  ...        0.003702  0.831744   \n",
      "392  -5.320000e-08 -0.001181     0.006669  ...        0.019320  0.969311   \n",
      "905  -5.930000e-11  0.000026     0.008714  ...        0.000613  0.890841   \n",
      "1358  1.630000e-09 -0.000233     0.006258  ...        0.003456  0.836625   \n",
      "43   -2.160000e-08  0.002361     0.393076  ...        0.053641  1.037995   \n",
      "331  -5.440000e-08 -0.002408     0.053436  ...        0.033476  0.978413   \n",
      "772   1.700000e-10 -0.000133     0.011384  ...        0.001379  0.904656   \n",
      "1403 -5.310000e-09 -0.000403     0.006074  ...        0.003604  0.831982   \n",
      "497  -2.990000e-08  0.000361     0.030527  ...        0.020798  0.965597   \n",
      "1046 -4.720000e-10  0.000357     0.007558  ...        0.002126  0.869855   \n",
      "664  -1.890000e-10  0.000216     0.010296  ...        0.002617  0.994396   \n",
      "1454 -6.700000e-09 -0.000307     0.005881  ...        0.003842  0.829270   \n",
      "423   3.210000e-10 -0.000671     0.035913  ...        0.010036  1.113469   \n",
      "614   3.040000e-10 -0.000276     0.011561  ...        0.001633  0.910195   \n",
      "1408 -7.410000e-09 -0.000041     0.006612  ...        0.003379  0.800906   \n",
      "1094  4.250000e-11  0.000435     0.006847  ...        0.001984  0.822681   \n",
      "955  -1.480000e-10  0.000645     0.007497  ...        0.004145  0.917772   \n",
      "1353  3.620000e-09 -0.000076     0.006780  ...        0.007401  0.909554   \n",
      "100  -3.910000e-08 -0.000187     0.059077  ...        0.053201  1.041546   \n",
      "1040 -9.050000e-11  0.000348     0.007586  ...        0.002072  0.870457   \n",
      "463   8.330000e-10 -0.001034     0.030864  ...        0.012347  0.981081   \n",
      "63    1.640000e-08  0.000079     0.401346  ...        0.034763  1.018053   \n",
      "...            ...       ...          ...  ...             ...       ...   \n",
      "1056  4.790000e-10  0.000540     0.007026  ...        0.003234  0.846053   \n",
      "230  -1.200000e-08  0.000532     0.029203  ...        0.006137  0.977692   \n",
      "516   4.650000e-10 -0.000573     0.015548  ...        0.003479  0.957737   \n",
      "939   1.710000e-10  0.000112     0.008256  ...        0.003050  0.966561   \n",
      "951  -1.110000e-10  0.000637     0.007501  ...        0.002257  0.854609   \n",
      "1099 -2.160000e-10  0.000412     0.006826  ...        0.005568  0.906533   \n",
      "380  -6.480000e-10 -0.000109     0.042275  ...        0.010702  0.998530   \n",
      "445   6.910000e-10 -0.000602     0.020390  ...        0.005370  1.072219   \n",
      "1034 -1.860000e-10  0.000582     0.007169  ...        0.001609  0.826565   \n",
      "1419 -3.370000e-09 -0.000013     0.006561  ...        0.007906  0.893185   \n",
      "1254  1.430000e-09 -0.000128     0.006934  ...        0.006259  0.910552   \n",
      "565   6.790000e-10 -0.000598     0.012979  ...        0.003183  1.030376   \n",
      "1196 -1.650000e-09 -0.000160     0.007046  ...        0.003850  0.838390   \n",
      "831  -8.650000e-11  0.000546     0.008065  ...        0.001241  0.873868   \n",
      "1448 -1.280000e-09 -0.000303     0.005905  ...        0.003795  0.830073   \n",
      "1368  1.190000e-09 -0.000059     0.006728  ...        0.007535  0.908058   \n",
      "1393 -3.750000e-10 -0.000048     0.006654  ...        0.003329  0.803964   \n",
      "1175 -8.000000e-11 -0.000076     0.007036  ...        0.003503  0.842425   \n",
      "1431  4.400000e-09 -0.000332     0.005961  ...        0.006807  0.846734   \n",
      "1039  2.900000e-10  0.000570     0.007123  ...        0.004909  0.910700   \n",
      "932   1.960000e-09  0.000123     0.015669  ...        0.002994  1.012236   \n",
      "1545  4.990000e-09 -0.000024     0.006000  ...        0.007531  0.976621   \n",
      "897  -1.140000e-10  0.000563     0.007539  ...        0.001893  0.865443   \n",
      "1510 -4.990000e-09 -0.000421     0.005647  ...        0.011136  0.895789   \n",
      "1294  1.150000e-10  0.000171     0.006572  ...        0.008321  0.894961   \n",
      "1214 -5.950000e-09  0.000096     0.006577  ...        0.002623  0.823242   \n",
      "109  -3.550000e-08 -0.000281     0.037537  ...        0.051969  1.044222   \n",
      "1590 -8.370000e-09 -0.000074     0.005448  ...        0.007462  0.974004   \n",
      "1421 -3.370000e-09 -0.000013     0.006561  ...        0.006020  0.818496   \n",
      "45   -2.160000e-08  0.002361     0.393076  ...        0.131013  0.987242   \n",
      "\n",
      "       U-AVG-X       U-AVG-Y   U-AVG-Z         du/dx     du/dy         dv/dx  \\\n",
      "480   0.666971  4.450000e-10  0.000383 -6.030000e-07 -0.013490  5.000000e-14   \n",
      "669   0.765725 -2.800000e-10  0.001792 -9.670000e-09 -0.002739 -1.650000e-13   \n",
      "382   0.673057 -4.200000e-10  0.001683 -9.460000e-08  0.007600  5.700000e-14   \n",
      "797   0.805618  4.600000e-10  0.001072 -1.050000e-07  0.006889 -2.860000e-13   \n",
      "758   0.785292 -9.000000e-11  0.000846 -4.910000e-09 -0.002399  2.050000e-13   \n",
      "157   0.491190  5.000000e-11  0.000678 -3.010000e-07 -0.010380 -2.870000e-14   \n",
      "1543  0.953674 -2.500000e-11 -0.000788  6.550000e-08 -0.000963 -1.510000e-13   \n",
      "1186  0.900982  3.400000e-10  0.000402 -2.180000e-09 -0.002783  7.380000e-15   \n",
      "1424  0.928239  5.900000e-11 -0.000608 -4.110000e-08 -0.001962 -1.440000e-13   \n",
      "392   0.597029  5.100000e-10  0.000195 -6.710000e-07 -0.022240 -1.110000e-13   \n",
      "905   0.821130 -4.800000e-10  0.000846 -1.010000e-09 -0.002235  6.630000e-14   \n",
      "1358  0.916135  5.450000e-11 -0.000493 -9.920000e-08 -0.000571  1.530000e-13   \n",
      "43    0.352312  2.900000e-11 -0.000302 -3.050000e-07  0.072050  2.500000e-17   \n",
      "331   0.538331  4.800000e-10  0.000102 -5.740000e-07 -0.023285 -6.240000e-14   \n",
      "772   0.789517 -4.500000e-10  0.001376 -2.570000e-09 -0.003521  3.930000e-13   \n",
      "1403  0.924290  5.350000e-11 -0.000586  9.380000e-08 -0.001492 -1.980000e-13   \n",
      "497   0.676799  4.150000e-10  0.000419 -5.790000e-07 -0.011755 -7.070000e-14   \n",
      "1046  0.853274 -6.300000e-10  0.000357 -5.450000e-09 -0.006645  6.800000e-14   \n",
      "664   0.763271 -5.500000e-11  0.000539 -5.440000e-09 -0.003749 -4.750000e-14   \n",
      "1454  0.933362  6.550000e-11 -0.000615  1.650000e-08 -0.003684 -2.110000e-14   \n",
      "423   0.691779 -3.900000e-10  0.001883 -6.890000e-08  0.009780  2.960000e-13   \n",
      "614   0.749942 -2.500000e-11  0.000347 -1.170000e-08 -0.004056 -6.500000e-16   \n",
      "1408  0.929040 -8.000000e-11 -0.000788  4.990000e-08  0.005745 -1.500000e-13   \n",
      "1094  0.862453 -8.500000e-11  0.000823  1.210000e-08  0.000447 -9.090000e-14   \n",
      "955   0.832509 -1.650000e-10  0.001062 -8.790000e-10  0.005247 -1.350000e-15   \n",
      "1353  0.918693 -1.000000e-10 -0.000629 -4.120000e-08  0.008375  4.550000e-13   \n",
      "100   0.477660  2.800000e-11 -0.000391 -6.050000e-07  0.033535 -1.550000e-16   \n",
      "1040  0.851618 -6.500000e-10  0.000384 -4.630000e-09 -0.006796 -1.870000e-14   \n",
      "463   0.705479 -3.300000e-10  0.001999 -5.290000e-08  0.009485 -1.300000e-14   \n",
      "63    0.325793  6.550000e-11  0.000470  3.960000e-08  0.015500 -1.410000e-14   \n",
      "...        ...           ...       ...           ...       ...           ...   \n",
      "1056  0.854293 -1.150000e-10  0.000911 -9.500000e-09  0.001610 -3.070000e-14   \n",
      "230   0.577093  2.500000e-11  0.000916 -2.460000e-07 -0.010105  1.490000e-13   \n",
      "516   0.723668 -4.500000e-11  0.000078 -2.050000e-08 -0.006224  4.950000e-14   \n",
      "939   0.829729 -6.950000e-10  0.000723 -1.250000e-09 -0.003720 -2.630000e-14   \n",
      "951   0.830805 -1.550000e-10  0.001066 -3.950000e-10  0.005466  1.180000e-15   \n",
      "1099  0.864073 -8.000000e-11  0.000802  8.370000e-09  0.000308  1.580000e-13   \n",
      "380   0.673057 -4.200000e-10  0.001683 -9.460000e-08  0.007600  5.700000e-14   \n",
      "445   0.703596 -1.350000e-10 -0.000038 -3.570000e-08 -0.002745  6.030000e-14   \n",
      "1034  0.849335 -1.300000e-10  0.000957 -1.320000e-09  0.002295  7.850000e-15   \n",
      "1419  0.931939 -6.500000e-11 -0.000818  7.010000e-08  0.005281 -4.480000e-13   \n",
      "1254  0.898617 -2.200000e-10 -0.000385 -2.160000e-08  0.012575 -2.500000e-15   \n",
      "565   0.738119 -2.000000e-11  0.000203 -1.460000e-08 -0.006421 -2.770000e-14   \n",
      "1196  0.885841 -3.250000e-10 -0.000204 -1.380000e-08  0.010531  7.880000e-13   \n",
      "831   0.803108 -9.500000e-11  0.001055 -2.200000e-09  0.000659 -2.320000e-14   \n",
      "1448  0.932097  6.350000e-11 -0.000616 -7.900000e-09 -0.003093  4.540000e-14   \n",
      "1368  0.921683 -1.000000e-10 -0.000680 -2.820000e-08  0.007542  9.750000e-14   \n",
      "1393  0.926116 -9.500000e-11 -0.000750  1.950000e-09  0.006341  1.060000e-12   \n",
      "1175  0.881004 -3.750000e-10 -0.000115  7.800000e-09  0.008192  3.690000e-13   \n",
      "1431  0.929536  6.050000e-11 -0.000613 -1.460000e-08 -0.002225  1.350000e-13   \n",
      "1039  0.850993 -1.250000e-10  0.000942 -1.720000e-09  0.002055 -6.360000e-15   \n",
      "932   0.841957  6.750000e-10  0.000976 -4.390000e-08  0.004410 -5.240000e-14   \n",
      "1545  0.971362  2.550000e-10 -0.000586  3.750000e-08  0.000548  9.790000e-13   \n",
      "897   0.818798 -7.000000e-11  0.001083 -1.520000e-09  0.004815  3.930000e-14   \n",
      "1510  0.943093  6.650000e-11 -0.000604  1.270000e-07 -0.007402 -1.780000e-13   \n",
      "1294  0.904636  3.000000e-11 -0.000208  2.100000e-08 -0.002614  1.600000e-14   \n",
      "1214  0.887875 -5.000000e-12  0.000328  7.380000e-09 -0.001481  1.950000e-13   \n",
      "109   0.489400  2.900000e-11 -0.000396 -5.870000e-07  0.030080  1.010000e-14   \n",
      "1590  0.978153  2.450000e-10 -0.000738 -7.290000e-08  0.001215 -1.800000e-13   \n",
      "1421  0.931939 -6.500000e-11 -0.000818  7.010000e-08  0.005281 -4.480000e-13   \n",
      "45    0.352312  2.900000e-11 -0.000302 -3.050000e-07  0.072050  2.500000e-17   \n",
      "\n",
      "             dv/dy     P_AVG  \n",
      "480  -1.540000e-08  0.000320  \n",
      "669  -2.150000e-09 -0.000837  \n",
      "382  -8.790000e-08 -0.000250  \n",
      "797  -1.600000e-08 -0.000687  \n",
      "758   2.320000e-09 -0.000727  \n",
      "157  -4.000000e-08  0.000976  \n",
      "1543  4.560000e-09  0.000285  \n",
      "1186  4.120000e-09 -0.000627  \n",
      "1424  2.660000e-09  0.000144  \n",
      "392  -1.880000e-08  0.000657  \n",
      "905   8.180000e-09 -0.000695  \n",
      "1358  2.640000e-09  0.000035  \n",
      "43   -1.490000e-08  0.001226  \n",
      "331  -2.590000e-08  0.000851  \n",
      "772   3.030000e-09 -0.000814  \n",
      "1403  2.980000e-09  0.000109  \n",
      "497  -1.610000e-08  0.000262  \n",
      "1046  8.610000e-09 -0.000509  \n",
      "664   6.970000e-10 -0.000771  \n",
      "1454  2.600000e-09  0.000190  \n",
      "423  -5.860000e-08 -0.000426  \n",
      "614   4.330000e-09 -0.000782  \n",
      "1408  8.720000e-09  0.000067  \n",
      "1094  1.150000e-10 -0.000368  \n",
      "955   6.580000e-09 -0.000542  \n",
      "1353  8.010000e-09 -0.000022  \n",
      "100  -1.370000e-08  0.000875  \n",
      "1040  9.390000e-09 -0.000520  \n",
      "463  -2.470000e-08 -0.000547  \n",
      "63   -3.650000e-08  0.001352  \n",
      "...            ...       ...  \n",
      "1056  2.530000e-09 -0.000419  \n",
      "230  -4.610000e-08  0.000548  \n",
      "516   1.060000e-08 -0.000762  \n",
      "939   2.110000e-08 -0.000650  \n",
      "951   6.980000e-09 -0.000551  \n",
      "1099 -5.000000e-12 -0.000358  \n",
      "380  -8.790000e-08 -0.000250  \n",
      "445  -1.260000e-08 -0.000701  \n",
      "1034  3.350000e-09 -0.000448  \n",
      "1419  8.070000e-09  0.000092  \n",
      "1254  1.470000e-08 -0.000186  \n",
      "565   6.080000e-09 -0.000781  \n",
      "1196  1.940000e-08 -0.000286  \n",
      "831  -6.790000e-09 -0.000672  \n",
      "1448  2.570000e-09  0.000179  \n",
      "1368  8.210000e-09  0.000003  \n",
      "1393  9.140000e-09  0.000041  \n",
      "1175  1.360000e-08 -0.000322  \n",
      "1431  2.590000e-09  0.000156  \n",
      "1039  3.140000e-09 -0.000439  \n",
      "932   1.730000e-08 -0.000820  \n",
      "1545  7.910000e-09 -0.000069  \n",
      "897   1.420000e-09 -0.000609  \n",
      "1510  1.710000e-09  0.000279  \n",
      "1294  3.910000e-09 -0.000066  \n",
      "1214  6.850000e-09 -0.000196  \n",
      "109  -1.350000e-08  0.000824  \n",
      "1590  6.030000e-09 -0.000014  \n",
      "1421  8.070000e-09  0.000092  \n",
      "45   -1.490000e-08  0.001226  \n",
      "\n",
      "[262 rows x 52 columns]\n",
      "480     1.083570\n",
      "669     1.065285\n",
      "382     0.971806\n",
      "797     1.013565\n",
      "758     0.867546\n",
      "157     0.963231\n",
      "1543    0.787530\n",
      "1186    0.961117\n",
      "1424    0.836117\n",
      "392     0.967274\n",
      "905     0.890577\n",
      "1358    0.839978\n",
      "43      1.044785\n",
      "331     0.980775\n",
      "772     0.904201\n",
      "1403    0.834925\n",
      "497     0.964854\n",
      "1046    0.869939\n",
      "664     0.994028\n",
      "1454    0.837566\n",
      "423     1.114550\n",
      "614     0.909886\n",
      "1408    0.800666\n",
      "1094    0.822651\n",
      "955     0.917632\n",
      "1353    0.909058\n",
      "100     1.048630\n",
      "1040    0.870536\n",
      "463     0.981132\n",
      "63      1.020885\n",
      "          ...   \n",
      "1056    0.845995\n",
      "230     0.978666\n",
      "516     0.957595\n",
      "939     0.966391\n",
      "951     0.854607\n",
      "1099    0.906516\n",
      "380     0.998931\n",
      "445     1.072430\n",
      "1034    0.826731\n",
      "1419    0.892767\n",
      "1254    0.910433\n",
      "565     1.030280\n",
      "1196    0.838138\n",
      "831     0.873906\n",
      "1448    0.837198\n",
      "1368    0.907598\n",
      "1393    0.803760\n",
      "1175    0.842009\n",
      "1431    0.852303\n",
      "1039    0.910655\n",
      "932     1.012780\n",
      "1545    0.975222\n",
      "897     0.865525\n",
      "1510    0.910513\n",
      "1294    0.896730\n",
      "1214    0.823995\n",
      "109     1.051110\n",
      "1590    0.972554\n",
      "1421    0.818109\n",
      "45      0.989940\n",
      "Name: Pr_t, Length: 262, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_labels = train.pop('Pr_t')\n",
    "val_labels = val.pop('Pr_t')\n",
    "test_labels = test.pop('Pr_t')\n",
    "print(val)\n",
    "print(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "    return (x - x.mean())/x.std()\n",
    "\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop('Pr_t')\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test,shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 특성: ['Alpha_t', 'MKE_visc_diff', 'TV_conv_turb', 'dk/dy', 'dT/dx_i_abs', 'tke_diss', 'Y', 'tke_pre', 'dT/dy', 'Nu_t_lsq', 'dk/dx', 'X', 'S_12(=S_21)', 'MTV_diss', 'MTV_mol_diff', 'tke_sdm', 'dp/dx', 'S_22', 'Rp', 'U-AVG-Y', 'TV_prod(al_t_1)', 'Re', 'dv/dy', 'TV_sdm', 'MKE_pre', 'du/dy', 'S_ij_abs', 'dp/dx_i_abs', 'Rd', 'Pr', 'tke_conv_turb', 'TV_diff', 'S_11', 'Rp/Rd', 'du/dx', 'tke_diff', 'dk/dx_i_abs', 'dp/dy', 'U-AVG-Z', 'wedge_height', 'dTvar/dx_i_abs', 'tke_prod(nu_t_1_new)', 'TV', 'MKE_diss', 'U-AVG-X', 'TV_diss', 'dv/dx', 'dT/dx', 'P_AVG', 'tke', 'u_du/dx+v_dv/dx', 'y_plus']\n",
      "나이 특성의 배치: tf.Tensor([0.0096368  0.00205126 0.00607366 0.00429392 0.00331897], shape=(5,), dtype=float64)\n",
      "타깃의 배치: tf.Tensor([0.951553  0.857238  0.9837425 0.8376035 0.912633 ], shape=(5,), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in train_ds.take(1):\n",
    "    print('전체 특성:',list(feature_batch.keys()))\n",
    "    print('나이 특성의 배치:',feature_batch['tke'])\n",
    "    print('타깃의 배치:',label_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_batch = next(iter(train_ds))[0]\n",
    "\n",
    "def dump(feature_column):\n",
    "    feature_layer = layers.DenseFeature(feature_column)\n",
    "    print(feature_layer(example_batch).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "      1/Unknown - 0s 67ms/step"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'dense_6_input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-2b4a61106634>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m model.fit(train_ds,\n\u001b[0;32m     11\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m           epochs=5)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    501\u001b[0m       \u001b[1;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m       \u001b[0minitializer_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 503\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    504\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m       \u001b[1;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[1;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[0;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[1;32m--> 408\u001b[1;33m             *args, **kwds))\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2150\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2041\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2043\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    913\u001b[0m                                           converted_func)\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mdistributed_function\u001b[1;34m(input_iterator)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;34m\"\"\"A single step of the distributed execution across replicas.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     x, y, sample_weights = _prepare_feed_values(\n\u001b[1;32m---> 66\u001b[1;33m         model, input_iterator, mode)\n\u001b[0m\u001b[0;32m     67\u001b[0m     \u001b[1;31m# Call `Model.{train,test,predict}_on_batch` on every replica passing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# PerReplicas as arguments.  On every replica inside this call, each\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36m_prepare_feed_values\u001b[1;34m(model, inputs, mode)\u001b[0m\n\u001b[0;32m    116\u001b[0m   \u001b[1;31m# correct order.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelInputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    116\u001b[0m   \u001b[1;31m# correct order.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModelInputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'dense_6_input'"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation='relu',input_shape=[len(train.keys())]),\n",
    "    tf.keras.layers.Dense(25, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='mse',\n",
    "             metrics=['mse'])\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
