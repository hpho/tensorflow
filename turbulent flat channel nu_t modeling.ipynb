{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "mod = sys.modules[__name__]\n",
    "from sklearn import ensemble\n",
    "import numpy as np\n",
    "\n",
    "Data = pd.read_csv(r'D:\\Desktop\\SynologyDrive\\하강우\\bubble\\data\\bubble.csv')\n",
    "R_csv = pd.read_csv(r'D:\\Desktop\\SynologyDrive\\하강우\\bubble\\data\\R.csv')\n",
    "\n",
    "num_Fold = 3\n",
    "\n",
    "mean = Data.mean()[-1]\n",
    "std = Data.std()[-1]\n",
    "\n",
    "def stz(Data):\n",
    "    return (Data - Data.mean())/Data.std()\n",
    "\n",
    "def norm(Data, min_norm=-0.9, max_norm=0.9):\n",
    "    return (Data - Data.min())/(Data.max() - Data.min())*(max_norm - min_norm) + min_norm\n",
    "\n",
    "stz_Data = stz(Data)\n",
    "norm_Data = norm(Data)\n",
    "\n",
    "All_Data = pd.DataFrame()\n",
    "All_Data[Data.columns[0:3]] = norm_Data[Data.columns[0:3]]\n",
    "All_Data[Data.columns[3]] = stz_Data[Data.columns[3]]\n",
    "All_Data[Data.columns[4]] = norm_Data[Data.columns[4]]\n",
    "All_Data[Data.columns[5]] = stz_Data[Data.columns[5]]\n",
    "All_Data['R'] = R_csv[['R']].iloc[:len(Data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_list = [[0,5],[5,20],[20,35],[35,50],[50,65],[65,80],[80,95],[95,110],[110,125],[125,140],\n",
    "             [140,155],[155,162],[162,169],[169,176],[176,183],[183,198],[198,213],[213,228],\n",
    "             [228,243],[243,258],[258,273],[273,288],[288,302]]\n",
    "\n",
    "for j in range(5):\n",
    "    \n",
    "    for i in range(len(case_list)):\n",
    "        setattr(mod,'case{}_RF_Data_{}'.format(i+1,j+1),pd.read_csv(r'D:\\Desktop\\SynologyDrive\\하강우\\bubble\\RF_case_modeling\\RF_case{}_Data{}.csv'.format(i+1,j+1)))\n",
    "for i in range(len(case_list)):\n",
    "    \n",
    "    setattr(mod,'case{}_RF_Data_model'.format(i+1), pd.DataFrame())\n",
    "    getattr(mod,'case{}_RF_Data_model'.format(i+1))['model'] = [0 for i in range(case_list[i][1] - case_list[i][0])]\n",
    "    \n",
    "    setattr(mod,'case{}_RF_Data_y_data'.format(i+1), pd.DataFrame())\n",
    "    getattr(mod,'case{}_RF_Data_y_data'.format(i+1))['y_data'] = [0 for i in range(case_list[i][1] - case_list[i][0])]\n",
    "    \n",
    "    for j in range(5):\n",
    "        \n",
    "        getattr(mod,'case{}_RF_Data_model'.format(i+1))['model{}'.format(j+1)] = getattr(mod,'case{}_RF_Data_{}'.format(i+1,j+1))['model'].iloc[case_list[i][0]:case_list[i][1]].reset_index(drop=True)\n",
    "        \n",
    "        getattr(mod,'case{}_RF_Data_y_data'.format(i+1))['y_data{}'.format(j+1)] = getattr(mod,'case{}_RF_Data_{}'.format(i+1,j+1))['y_data'].iloc[case_list[i][0]:case_list[i][1]].reset_index(drop=True)\n",
    "        \n",
    "    del getattr(mod,'case{}_RF_Data_model'.format(i+1))['model']\n",
    "    del getattr(mod,'case{}_RF_Data_y_data'.format(i+1))['y_data']\n",
    "    \n",
    "    setattr(mod,'avg_case{}_RF_Data'.format(i+1), pd.DataFrame())\n",
    "    getattr(mod,'avg_case{}_RF_Data'.format(i+1))['model']  = getattr(mod,'case{}_RF_Data_model'.format(i+1)).mean(axis=1)\n",
    "    getattr(mod,'avg_case{}_RF_Data'.format(i+1))['y_data']  = getattr(mod,'case{}_RF_Data_y_data'.format(i+1)).mean(axis=1)\n",
    "    \n",
    "    setattr(mod,'std_case{}_RF_Data'.format(i+1), pd.DataFrame())\n",
    "    getattr(mod,'std_case{}_RF_Data'.format(i+1))['model']  = getattr(mod,'case{}_RF_Data_model'.format(i+1)).std(axis=1)\n",
    "    getattr(mod,'std_case{}_RF_Data'.format(i+1))['y_data']  = getattr(mod,'case{}_RF_Data_y_data'.format(i+1)).std(axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "x = np.linspace(0,12)\n",
    "y1 = x*1.3\n",
    "y2 = x*0.7\n",
    "\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "for i in 4,5,7,8,9,10,11,12,13,14,15,20,21,22,23:\n",
    "    plt.scatter(getattr(mod,'avg_case{}_RF_Data'.format(i))['model'],getattr(mod,'avg_case{}_RF_Data'.format(i))['y_data'],s=10,color='b')\n",
    "plt.plot([0,12],[0,12],color='k')\n",
    "plt.plot(x,y1,'--',color='k')\n",
    "plt.plot(x,y2,'--',color='k')\n",
    "plt.axis([0,12,0,12])\n",
    "plt.grid(True)\n",
    "plt.xlabel('$D_{sm}^{RF}$ (mm)')\n",
    "plt.ylabel('$D_{sm}^{EXP}$ (mm)')\n",
    "plt.title('Random Forest interpolation case avg scatter')\n",
    "plt.savefig(r'D:\\Desktop\\SynologyDrive\\하강우\\bubble\\wallcoresnu\\RF_inter_scatter.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(A,B):\n",
    "    return ((A - B)**2).mean()\n",
    "\n",
    "def ARE(A,T):\n",
    "    return (abs((A-T)/T)*100).mean()\n",
    "\n",
    "aa = []\n",
    "bb = []\n",
    "for i in 4,5,7,8,9,10,11,12,13,14,15,20,21,22,23:\n",
    "    aa.append(MSE(getattr(mod,'avg_case{}_RF_Data'.format(i))['model'],getattr(mod,'avg_case{}_RF_Data'.format(i))['y_data']))\n",
    "    bb.append(ARE(getattr(mod,'avg_case{}_RF_Data'.format(i))['model'],getattr(mod,'avg_case{}_RF_Data'.format(i))['y_data']))\n",
    "    \n",
    "print(np.sqrt(sum(aa)/len(aa)))\n",
    "print(sum(bb)/len(bb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_list = [[0,5],[5,20],[20,35],[35,50],[50,65],[65,80],[80,95],[95,110],[110,125],[125,140],\n",
    "             [140,155],[155,162],[162,169],[169,176],[176,183],[183,198],[198,213],[213,228],\n",
    "             [228,243],[243,258],[258,273],[273,288],[288,302]]\n",
    "n_Avg = 5\n",
    "n_Fold = 4\n",
    "\n",
    "for j in range(n_Avg):\n",
    "    for i in range(n_Fold):\n",
    "        setattr(mod,'inter_Data_{}_{}'.format(i+1,j+1), pd.read_csv(r'D:\\Desktop\\SynologyDrive\\하강우\\bubble\\K_Fold_Regular_ANN_1million_epoch\\regular_ANN_{}_4_inter_Fold_million_iter_Data_1{}.csv'.format(i+1,j+1)))\n",
    "        setattr(mod,'extra_Data_{}_{}'.format(i+1,j+1), pd.read_csv(r'D:\\Desktop\\SynologyDrive\\하강우\\bubble\\K_Fold_Regular_ANN_1million_epoch\\regular_ANN_{}_4_extra_Fold_million_iter_Data_1{}.csv'.format(i+1,j+1)))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolation scatter\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "for j in range(n_Avg):\n",
    "    for i in range(n_Fold):\n",
    "        plt.scatter(getattr(mod,'inter_Data_{}_{}'.format(i+1,j+1))['model'],getattr(mod,'inter_Data_{}_{}'.format(i+1,j+1))['y_data'],s=10,color='b')\n",
    "plt.plot([0,12],[0,12],color='k')\n",
    "plt.plot(x,y1,'--',color='k')\n",
    "plt.plot(x,y2,'--',color='k')\n",
    "plt.axis([0,12,0,12])\n",
    "plt.grid(True)\n",
    "plt.xlabel('$D_{sm}^{ANN}$ (mm)')\n",
    "plt.ylabel('$D_{sm}^{EXP}$ (mm)')\n",
    "plt.title('1/4 case Regular ANN interpolation full scatter')\n",
    "plt.savefig(r'D:\\Desktop\\SynologyDrive\\하강우\\bubble\\wallcoresnu\\Regular_ANN_4_Fold_inter_full_scatter.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolation scatter\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "for j in range(n_Avg):\n",
    "    for i in range(n_Fold):\n",
    "        plt.scatter(getattr(mod,'extra_Data_{}_{}'.format(i+1,j+1))['model'],getattr(mod,'extra_Data_{}_{}'.format(i+1,j+1))['y_data'],s=10,color='b')\n",
    "plt.plot([0,12],[0,12],color='k')\n",
    "plt.plot(x,y1,'--',color='k')\n",
    "plt.plot(x,y2,'--',color='k')\n",
    "plt.axis([0,12,0,12])\n",
    "plt.grid(True)\n",
    "plt.xlabel('$D_{sm}^{ANN}$ (mm)')\n",
    "plt.ylabel('$D_{sm}^{EXP}$ (mm)')\n",
    "plt.title('1/4 case Regular ANN extrapolation full scatter')\n",
    "plt.savefig(r'D:\\Desktop\\SynologyDrive\\하강우\\bubble\\wallcoresnu\\Regular_ANN_4_Fold_extra_full_scatter.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = []\n",
    "bb = []\n",
    "for j in range(n_Avg):\n",
    "    for i in range(n_Fold):\n",
    "        aa.append(MSE( getattr(mod,'inter_Data_{}_{}'.format(i+1,j+1))['model'],getattr(mod,'inter_Data_{}_{}'.format(i+1,j+1))['y_data'] ))\n",
    "        bb.append(ARE( getattr(mod,'inter_Data_{}_{}'.format(i+1,j+1))['model'],getattr(mod,'inter_Data_{}_{}'.format(i+1,j+1))['y_data'] ))\n",
    "        \n",
    "print(np.sqrt(sum(aa)/len(aa)))\n",
    "print(sum(bb)/len(bb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(n_Avg):\n",
    "    for i in range(n_Fold):\n",
    "        if i==0 and j==0:\n",
    "            avg_inter_Data = pd.DataFrame()\n",
    "            avg_inter_Data['model'] = [0 for i in range(len(B_Data))]\n",
    "            avg_inter_Data['y_data'] = [0 for i in range(len(B_Data))]\n",
    "            \n",
    "            avg_inter_Data += inter_Data_1_1.set_index(\"index\")\n",
    "            avg_inter_Data = avg_inter_Data.replace(np.nan, 0)\n",
    "            \n",
    "        avg_inter_Data += getattr(mod,'inter_Data_{}_{}'.format(i+1,j+1)).set_index(\"index\")\n",
    "\n",
    "avg_inter_Data = avg_inter_Data/(n_Avg*(n_Fold ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.scatter(avg_inter_Data['model'],(B_Data['Dsm/R']*R_csv['R']).iloc[avg_inter_Data.index],s=10,color='b')\n",
    "plt.plot([0,12],[0,12],color='k')\n",
    "plt.plot(x,y1,'--',color='k')\n",
    "plt.plot(x,y2,'--',color='k')\n",
    "plt.axis([0,12,0,12])\n",
    "plt.grid(True)\n",
    "plt.xlabel('$D_{sm}^{ANN}$ (mm)')\n",
    "plt.ylabel('$D_{sm}^{EXP}$ (mm)')\n",
    "plt.title('1/4 case Regular ANN interpolation avg scatter')\n",
    "plt.savefig(r'D:\\Desktop\\SynologyDrive\\하강우\\bubble\\wallcoresnu\\Regular_ANN_4_Fold_inter_avg_scatter.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(MSE(avg_inter_Data['model'],avg_inter_Data['y_data'])))\n",
    "print(ARE(avg_inter_Data['model'],avg_inter_Data['y_data']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_extra_Data = pd.DataFrame()\n",
    "avg_extra_Data['model'] = [0 for i in range(len(B_Data))]\n",
    "avg_extra_Data['y_data'] = [0 for i in range(len(B_Data))]\n",
    "\n",
    "for j in range(n_Avg):\n",
    "    for i in range(n_Fold):\n",
    "        if j==0:\n",
    "                       \n",
    "            avg_extra_Data += getattr(mod,'extra_Data_{}_{}'.format(i+1,j+1)).set_index(\"index\")\n",
    "            avg_extra_Data = avg_extra_Data.replace(np.nan, 0)\n",
    "            \n",
    "        avg_extra_Data += getattr(mod,'extra_Data_{}_{}'.format(i+1,j+1)).set_index(\"index\")\n",
    "\n",
    "avg_extra_Data = avg_extra_Data/(n_Avg*(n_Fold ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.scatter(avg_extra_Data['model'],B_Data['Dsm/R']*R_csv['R'],s=10,color='b')\n",
    "plt.plot([0,12],[0,12],color='k')\n",
    "plt.plot(x,y1,'--',color='k')\n",
    "plt.plot(x,y2,'--',color='k')\n",
    "plt.axis([0,12,0,12])\n",
    "plt.grid(True)\n",
    "plt.xlabel('$D_{sm}^{ANN}$ (mm)')\n",
    "plt.ylabel('$D_{sm}^{EXP}$ (mm)')\n",
    "plt.title('1/4 case Regular ANN extrapolation avg scatter')\n",
    "plt.savefig(r'D:\\Desktop\\SynologyDrive\\하강우\\bubble\\wallcoresnu\\Regular_ANN_4_Fold_extra_avg_scatter.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_extra_Data_model = pd.DataFrame()\n",
    "avg_extra_Data_model['model'] = [0 for i in range(len(B_Data))]\n",
    "\n",
    "for j in range(n_Avg):\n",
    "    for i in range(n_Fold):\n",
    "        avg_extra_Data_model['model{}{}'.format(i+1,j+1)] = getattr(mod,'extra_Data_{}_{}'.format(i+1,j+1)).set_index('index')['model']\n",
    "avg_extra_Data_model = avg_extra_Data_model.replace(np.nan, 0)\n",
    "del avg_extra_Data_model['model']\n",
    "\n",
    "avg_extra_Data = pd.DataFrame()\n",
    "avg_extra_Data['model'] = (avg_extra_Data_model.mean(axis=1))*20/5\n",
    "\n",
    "std_extra_Data = pd.DataFrame()\n",
    "std_extra_Data['model'] = np.sqrt((avg_extra_Data_model.var(axis=1))*20/5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_extra_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_inter_Data_model = pd.DataFrame()\n",
    "avg_inter_Data_model['model'] = [0 for i in range(len(B_Data))]\n",
    "\n",
    "for j in range(n_Avg):\n",
    "    for i in range(n_Fold):\n",
    "        avg_inter_Data_model['model{}{}'.format(i+1,j+1)] = getattr(mod,'inter_Data_{}_{}'.format(i+1,j+1)).set_index('index')['model']\n",
    "avg_inter_Data_model = avg_inter_Data_model.replace(np.nan, 0)\n",
    "del avg_inter_Data_model['model']\n",
    "\n",
    "avg_inter_Data = pd.DataFrame()\n",
    "avg_inter_Data['model'] = (avg_inter_Data_model.mean(axis=1))*20/20\n",
    "avg_inter_Data = avg_inter_Data[avg_inter_Data['model'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_inter_Data_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\orig_channel_all_Re.csv')\n",
    "for i in 180,400,590:\n",
    "    setattr(mod,'Data_{}'.format(i), Data[Data['Re'] == i])\n",
    "    setattr(mod,'Data_{}'.format(i), getattr(mod,'Data_{}'.format(i))[getattr(mod,'Data_{}'.format(i))['X'] == 0])\n",
    "    setattr(mod,'Data_{}'.format(i), getattr(mod,'Data_{}'.format(i))[getattr(mod,'Data_{}'.format(i))['Y'] < 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_180.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 180,400,590:\n",
    "    \n",
    "    plt.scatter(getattr(mod,'Data_{}'.format(i))['Y'],getattr(mod,'Data_{}'.format(i))['Nu_t_lsq_n'],label='Re : {}'.format(i))\n",
    "    plt.legend()\n",
    "    plt.axis([-.05,.85,-.001,.006])\n",
    "    plt.xticks([0,.1,.2,.3,.4,.5,.6,.7,.8])\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 180,400,590:\n",
    "    \n",
    "    plt.scatter(getattr(mod,'Data_{}'.format(i))['Y'],(-0.08)*(getattr(mod,'Data_{}'.format(i))['tke_n']**2)/getattr(mod,'Data_{}'.format(i))['tke_diss_n'],label='Re : {}'.format(i))\n",
    "    plt.legend()\n",
    "    plt.axis([-.05,.85,-.001,.006])\n",
    "    plt.xticks([0,.1,.2,.3,.4,.5,.6,.7,.8])\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 180,400,590:\n",
    "    setattr(mod,'channel_Data_{}'.format(i), pd.DataFrame())\n",
    "    getattr(mod,'channel_Data_{}'.format(i))['tke_n'] = getattr(mod,'Data_{}'.format(i))['tke_n']\n",
    "    getattr(mod,'channel_Data_{}'.format(i))['tke_diss_n'] = getattr(mod,'Data_{}'.format(i))['tke_diss_n']\n",
    "    getattr(mod,'channel_Data_{}'.format(i))['Nu_t_lsq_n'] = getattr(mod,'Data_{}'.format(i))['Nu_t_lsq_n']\n",
    "    getattr(mod,'channel_Data_{}'.format(i))['Y'] = getattr(mod,'Data_{}'.format(i))['Y']\n",
    "    getattr(mod,'channel_Data_{}'.format(i)).to_csv(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\channel_Data_{}.csv'.format(i),index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from functools import partial\n",
    "import sys\n",
    "mod = sys.modules[__name__]\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "num_output = 1\n",
    "num_layer = 4\n",
    "num_neuron = 30\n",
    "activation_function = 'tanh'\n",
    "# initializer = tf.keras.initializers.RandomUniform(minval=-1, maxval=1)\n",
    "initializer = tf.keras.initializers.he_normal()\n",
    "\n",
    "for i in 180,400,590:\n",
    "    setattr(mod,'Data_{}'.format(i), pd.read_csv(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\channel_Data_{}.csv'.format(i)))\n",
    "    \n",
    "def stz(Data):\n",
    "    return (Data - Data.mean())/Data.std()\n",
    "\n",
    "def norm(Data, min_norm=1, max_norm=2):\n",
    "    return (Data - Data.min())/(Data.max() - Data.min())*(max_norm - min_norm) + min_norm\n",
    "\n",
    "stz_Data_180 = stz(Data_180)\n",
    "# stz_Data_180 = norm(stz1_Data_180)\n",
    "stz_Data_180.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = stz_Data_180[stz_Data_180.columns[:-2]].sample(frac=0.7)\n",
    "train_Y = stz_Data_180[stz_Data_180.columns[-2:-1]].iloc[train_X.index]\n",
    "\n",
    "test_X = stz_Data_180[stz_Data_180.columns[:-2]].drop(train_X.index)\n",
    "test_Y = stz_Data_180[stz_Data_180.columns[-2:-1]].iloc[test_X.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "for i in range(5):\n",
    "    RFmodel = ensemble.RandomForestRegressor(n_estimators=2000, min_samples_split=2, min_samples_leaf=1, bootstrap=False, oob_score=False, \n",
    "                                                            max_depth=None, max_features='auto', random_state=None, n_jobs=2)\n",
    "\n",
    "    RFmodel.fit(train_X, train_Y)\n",
    "\n",
    "    RF_180 = pd.DataFrame()\n",
    "    RF_180['model'] = RFmodel.predict(test_X).flatten()\n",
    "    RF_180 = RF_180*Data_180.std()[-2] + Data_180.mean()[-2]\n",
    "    RF_180['y_data'] = Data_180['Nu_t_lsq_n'].loc[test_X.index]\n",
    "    RF_180['Y'] = Data_180['Y'].loc[test_X.index]\n",
    "    RF_180.to_csv(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\RF_model_180_{}.csv'.format(i+1),header=True,index=False)\n",
    "    \n",
    "    RF_400 = pd.DataFrame()\n",
    "    RF_400['model'] = RFmodel.predict(stz(Data_400[Data_400.columns[:-2]])).flatten()\n",
    "    RF_400 = RF_400*Data_180.std()[-2] + Data_180.mean()[-2]\n",
    "    RF_400.to_csv(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\RF_model_400_{}.csv'.format(i+1),header=True,index=False)\n",
    "    \n",
    "    RF_590 = pd.DataFrame()\n",
    "    RF_590['model'] = RFmodel.predict(stz(Data_590[Data_590.columns[:-2]])).flatten()\n",
    "    RF_590 = RF_590*Data_180.std()[-2] + Data_180.mean()[-2]\n",
    "    RF_590.to_csv(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\RF_model_590_{}.csv'.format(i+1),header=True,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "mod = sys.modules[__name__]\n",
    "import pandas as pd\n",
    "\n",
    "for k in range(5):\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    from functools import partial\n",
    "\n",
    "    num_output = 1\n",
    "    num_layer = 10\n",
    "    num_neuron = 20\n",
    "    activation_function = 'elu'\n",
    "    # initializer = tf.keras.initializers.RandomUniform(minval=-1, maxval=1)\n",
    "    initializer = tf.keras.initializers.he_normal()\n",
    "\n",
    "#     for i in 180,400,590:\n",
    "#         setattr(mod,'Data_{}'.format(i), pd.read_csv(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\channel_Data_{}.csv'.format(i)))\n",
    "\n",
    "#     def stz(Data):\n",
    "#         return (Data - Data.mean())/Data.std()\n",
    "\n",
    "#     def norm(Data, min_norm=1, max_norm=2):\n",
    "#         return (Data - Data.min())/(Data.max() - Data.min())*(max_norm - min_norm) + min_norm\n",
    "\n",
    "#     stz_Data_180 = stz(Data_180)\n",
    "#     stz_Data_180 = norm(stz_Data_180)\n",
    "#     stz_Data_180.boxplot()\n",
    "    \n",
    "    l2_reg = tf.contrib.layers.l2_regularizer(scale=0.01)    \n",
    "    dense_layer = partial(tf.layers.dense, activation=None, kernel_initializer=initializer, use_bias=True, bias_initializer=initializer, kernel_regularizer=l2_reg)\n",
    "\n",
    "    X = tf.placeholder(tf.float32, shape=[None, 2])\n",
    "    Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "    for i in range(num_layer):\n",
    "        if i == 0:\n",
    "            setattr(mod, 'hidden{}'.format(i+1),dense_layer(X,num_neuron))\n",
    "\n",
    "        else:\n",
    "            setattr(mod, 'hidden{}'.format(i+1),dense_layer(getattr(mod, 'hidden{}_act'.format(i)),num_neuron))\n",
    "\n",
    "        setattr(mod,'hidden{}_act'.format(i+1),getattr(tf.nn,activation_function)(getattr(mod,'hidden{}'.format(i+1))))\n",
    "\n",
    "    model = dense_layer(getattr(mod,'hidden{}'.format(num_layer)), num_output)\n",
    "\n",
    "    mse_loss = tf.reduce_mean(tf.square(model - Y))\n",
    "    kl_loss = tf.reduce_mean(tf.square(model/Y))\n",
    "    \n",
    "    loss_regularization = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    loss = tf.add_n([kl_loss] + loss_regularization)\n",
    "\n",
    "    train_op = tf.train.AdamOptimizer(0.00001).minimize(loss)\n",
    "\n",
    "    sess= tf.Session()\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "\n",
    "    train_mse_profile = []\n",
    "    test_mse_profile = []\n",
    "\n",
    "    for epoch in range(50000):\n",
    "\n",
    "#         batch_X = train_X.sample(n=2)\n",
    "#         batch_Y = train_Y.loc[batch_X.index]\n",
    "#         sess.run(train_op,feed_dict={X: batch_X, Y: batch_Y})\n",
    "        sess.run(train_op, feed_dict={X: train_X, Y: train_Y})\n",
    "\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            train_mse_profile.append(sess.run(mse_loss, feed_dict={X: train_X, Y: train_Y}))\n",
    "            test_mse_profile.append(sess.run(mse_loss, feed_dict={X: test_X, Y: test_Y}))\n",
    "            print('{} epochs mse train : {} , test : {}'.format(epoch+1,train_mse_profile[-1],test_mse_profile[-1]))\n",
    "\n",
    "\n",
    "    SGD_180 = pd.DataFrame()\n",
    "    SGD_180['model'] = sess.run(model,feed_dict={X: test_X}).flatten()\n",
    "    SGD_180 = SGD_180*Data_180.std()[-2] + Data_180.mean()[-2]\n",
    "    SGD_180['y_data'] = Data_180['Nu_t_lsq_n'].loc[test_X.index]\n",
    "    SGD_180['Y'] = Data_180['Y'].loc[test_X.index]\n",
    "    SGD_180.to_csv(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\kl_L10_L2_SGD_model_180_{}.csv'.format(k+1),header=True,index=False)\n",
    "    \n",
    "    \n",
    "    Data_400['tke_n'] = (Data_400['tke_n'] - Data_180['tke_n'].mean())/Data_180['tke_n'].std()\n",
    "    Data_400['tke_diss_n'] = (Data_400['tke_diss_n'] - Data_180['tke_diss_n'].mean())/Data_180['tke_diss_n'].std()\n",
    "    Data_400['Nu_t_lsq_n'] = (Data_400['Nu_t_lsq_n'] - Data_180['Nu_t_lsq_n'].mean())/Data_180['Nu_t_lsq_n'].std()\n",
    "\n",
    "    ttt = pd.DataFrame()\n",
    "    ttt['model'] = sess.run(model,feed_dict={X: Data_400[Data_400.columns[:-2]]}).flatten()\n",
    "    ttt['y_data'] = Data_400[Data_400.columns[-2:-1]]\n",
    "    ttt = ttt*Data_180.std()[-2] + Data_180.mean()[-2]\n",
    "    ttt.to_csv(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\kl_L10_L2_SGD_model_400_{}.csv'.format(k+1),header=True,index=False)\n",
    "    \n",
    "    Data_590['tke_n'] = (Data_590['tke_n'] - Data_180['tke_n'].mean())/Data_180['tke_n'].std()\n",
    "    Data_590['tke_diss_n'] = (Data_590['tke_diss_n'] - Data_180['tke_diss_n'].mean())/Data_180['tke_diss_n'].std()\n",
    "    Data_590['Nu_t_lsq_n'] = (Data_590['Nu_t_lsq_n'] - Data_180['Nu_t_lsq_n'].mean())/Data_180['Nu_t_lsq_n'].std()\n",
    "\n",
    "    ttt = pd.DataFrame()\n",
    "    ttt['model'] = sess.run(model,feed_dict={X: Data_590[Data_590.columns[:-2]]}).flatten()\n",
    "    ttt['y_data'] = Data_590[Data_590.columns[-2:-1]]\n",
    "    ttt = ttt*Data_180.std()[-2] + Data_180.mean()[-2]\n",
    "    ttt.to_csv(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\kl_L10_L2_SGD_model_590_{}.csv'.format(k+1),header=True,index=False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aa = [i*100 for i in range(len(train_mse_profile))]\n",
    "plt.plot(aa,train_mse_profile,label='train')\n",
    "plt.plot(aa,test_mse_profile,label='test')\n",
    "plt.axis([0,50000,0,0.01])\n",
    "plt.legend()\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.savefig(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\batch_train_epoch_profile.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(Data_180['Y'].loc[test_X.index],Data_180['Nu_t_lsq_n'].loc[test_X.index],s=10,label='DNS')\n",
    "plt.scatter(Data_180['Y'].loc[test_X.index],RF_180['model'],s=10,label='Random Forest')\n",
    "plt.axis([-.05,.85,-.001,.006])\n",
    "plt.xticks([0,.1,.2,.3,.4,.5,.6,.7,.8])\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\RF_Re180_interpolation.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in 180,400,590:\n",
    "        setattr(mod,'Data_{}'.format(i), pd.read_csv(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\channel_Data_{}.csv'.format(i)))\n",
    "\n",
    "ttt = pd.DataFrame()\n",
    "ttt['model'] = sess.run(model,feed_dict={X: Data_400[Data_400.columns[:-2]]}).flatten()\n",
    "ttt['y_data'] = Data_400[Data_400.columns[-2:-1]]\n",
    "ttt = ttt*Data_180.std()[-2] + Data_180.mean()[-2]\n",
    "\n",
    "plt.scatter(Data_400['Y'],Data_400['Nu_t_lsq_n'],s=10,label='DNS')\n",
    "plt.scatter(Data_400['Y'],ttt['model'],s=10,label='Random Forest')\n",
    "plt.axis([-.05,.85,-.001,.006])\n",
    "plt.xticks([0,.1,.2,.3,.4,.5,.6,.7,.8])\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "# plt.savefig(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\RF_Re400_interpolation.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tttt = pd.DataFrame()\n",
    "tttt['model'] = sess.run(model,feed_dict={X: stz(Data_400[Data_400.columns[:-2]])}).flatten()\n",
    "tttt = tttt*Data_180.std()[-2] + Data_180.mean()[-2]\n",
    "\n",
    "plt.scatter(Data_590['Y'],Data_590['Nu_t_lsq_n'],s=10,label='DNS')\n",
    "plt.scatter(Data_590['Y'],tttt['model'],s=10,label='Random Forest')\n",
    "plt.axis([-.05,.85,-.001,.006])\n",
    "plt.xticks([0,.1,.2,.3,.4,.5,.6,.7,.8])\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "# plt.savefig(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\RF_Re590_interpolation.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ARE(tt['model'],Data_180['Nu_t_lsq_n'].loc[test_X.index]))\n",
    "print(ARE(ttt['model'],Data_400['Nu_t_lsq_n']))\n",
    "print(ARE(tttt['model'],Data_590['Nu_t_lsq_n']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in 180,400,590:\n",
    "    for i in range(5):\n",
    "        setattr(mod,'L15_L2_SGD_{}_{}'.format(j,i+1), pd.read_csv(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\L15_L2_SGD_model_{}_{}.csv'.format(j,i+1)))\n",
    "              \n",
    "for j in 180,400,590:\n",
    "    setattr(mod,'avg_L15_L2_SGD_{}_model'.format(j), pd.DataFrame())\n",
    "    getattr(mod,'avg_L15_L2_SGD_{}_model'.format(j))['model'] = [0 for i in range(len(getattr(mod,'L15_L2_SGD_{}_1'.format(j))))]\n",
    "    for i in range(5):\n",
    "        getattr(mod,'avg_L15_L2_SGD_{}_model'.format(j))['model{}'.format(i+1)] = getattr(mod,'L15_L2_SGD_{}_{}'.format(j,i+1))['model']\n",
    "        \n",
    "    del getattr(mod,'avg_L15_L2_SGD_{}_model'.format(j))['model']\n",
    "    setattr(mod,'avg_L15_L2_SGD_{}'.format(j), getattr(mod,'avg_L15_L2_SGD_{}_model'.format(j)).mean(axis=1))\n",
    "    setattr(mod,'std_L15_L2_SGD_{}'.format(j), getattr(mod,'avg_L15_L2_SGD_{}_model'.format(j)).std(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in 180,400,590:\n",
    "    for i in range(5):\n",
    "        setattr(mod,'L10_L2_Regular_{}_{}'.format(j,i+1), pd.read_csv(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\L10_L2_Regular_model_{}_{}.csv'.format(j,i+1)))\n",
    "              \n",
    "for j in 180,400,590:\n",
    "    setattr(mod,'avg_L10_L2_Regular_{}_model'.format(j), pd.DataFrame())\n",
    "    getattr(mod,'avg_L10_L2_Regular_{}_model'.format(j))['model'] = [0 for i in range(len(getattr(mod,'L10_L2_Regular_{}_1'.format(j))))]\n",
    "    for i in range(5):\n",
    "        getattr(mod,'avg_L10_L2_Regular_{}_model'.format(j))['model{}'.format(i+1)] = getattr(mod,'L10_L2_Regular_{}_{}'.format(j,i+1))['model']\n",
    "        \n",
    "    del getattr(mod,'avg_L10_L2_Regular_{}_model'.format(j))['model']\n",
    "    setattr(mod,'avg_L10_L2_Regular_{}'.format(j), getattr(mod,'avg_L10_L2_Regular_{}_model'.format(j)).mean(axis=1))\n",
    "    setattr(mod,'std_L10_L2_Regular_{}'.format(j), getattr(mod,'avg_L10_L2_Regular_{}_model'.format(j)).std(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in 180,400,590:\n",
    "    for i in range(5):\n",
    "        setattr(mod,'L10_L2_SGD_{}_{}'.format(j,i+1), pd.read_csv(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\L10_L2_SGD_model_{}_{}.csv'.format(j,i+1)))\n",
    "              \n",
    "for j in 180,400,590:\n",
    "    setattr(mod,'avg_L10_L2_SGD_{}_model'.format(j), pd.DataFrame())\n",
    "    getattr(mod,'avg_L10_L2_SGD_{}_model'.format(j))['model'] = [0 for i in range(len(getattr(mod,'L10_L2_SGD_{}_1'.format(j))))]\n",
    "    for i in range(5):\n",
    "        getattr(mod,'avg_L10_L2_SGD_{}_model'.format(j))['model{}'.format(i+1)] = getattr(mod,'L10_L2_SGD_{}_{}'.format(j,i+1))['model']\n",
    "        \n",
    "    del getattr(mod,'avg_L10_L2_SGD_{}_model'.format(j))['model']\n",
    "    setattr(mod,'avg_L10_L2_SGD_{}'.format(j), getattr(mod,'avg_L10_L2_SGD_{}_model'.format(j)).mean(axis=1))\n",
    "    setattr(mod,'std_L10_L2_SGD_{}'.format(j), getattr(mod,'avg_L10_L2_SGD_{}_model'.format(j)).std(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in 180,400,590:\n",
    "    for i in range(5):\n",
    "        setattr(mod,'L2_SGD_{}_{}'.format(j,i+1), pd.read_csv(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\L2_SGD_model_{}_{}.csv'.format(j,i+1)))\n",
    "              \n",
    "for j in 180,400,590:\n",
    "    setattr(mod,'avg_L2_SGD_{}_model'.format(j), pd.DataFrame())\n",
    "    getattr(mod,'avg_L2_SGD_{}_model'.format(j))['model'] = [0 for i in range(len(getattr(mod,'L2_SGD_{}_1'.format(j))))]\n",
    "    for i in range(5):\n",
    "        getattr(mod,'avg_L2_SGD_{}_model'.format(j))['model{}'.format(i+1)] = getattr(mod,'L2_SGD_{}_{}'.format(j,i+1))['model']\n",
    "        \n",
    "    del getattr(mod,'avg_L2_SGD_{}_model'.format(j))['model']\n",
    "    setattr(mod,'avg_L2_SGD_{}'.format(j), getattr(mod,'avg_L2_SGD_{}_model'.format(j)).mean(axis=1))\n",
    "    setattr(mod,'std_L2_SGD_{}'.format(j), getattr(mod,'avg_L2_SGD_{}_model'.format(j)).std(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "mod = sys.modules[__name__]\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "for j in 180,400,590:\n",
    "    for i in range(20):\n",
    "        setattr(mod,'SGD_{}_{}'.format(j,i+1), pd.read_csv(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\SGD_model_{}_{}.csv'.format(j,i+1)))\n",
    "              \n",
    "for j in 180,400,590:\n",
    "    setattr(mod,'avg_SGD_{}_model'.format(j), pd.DataFrame())\n",
    "    getattr(mod,'avg_SGD_{}_model'.format(j))['model'] = [0 for i in range(len(getattr(mod,'SGD_{}_1'.format(j))))]\n",
    "    for i in range(5):\n",
    "        getattr(mod,'avg_SGD_{}_model'.format(j))['model{}'.format(i+1)] = getattr(mod,'SGD_{}_{}'.format(j,i+1))['model']\n",
    "        \n",
    "    del getattr(mod,'avg_SGD_{}_model'.format(j))['model']\n",
    "    setattr(mod,'avg_SGD_{}'.format(j), getattr(mod,'avg_SGD_{}_model'.format(j)).mean(axis=1))\n",
    "    setattr(mod,'std_SGD_{}'.format(j), getattr(mod,'avg_SGD_{}_model'.format(j)).std(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in 180,400,590:\n",
    "    for i in range(5):\n",
    "        setattr(mod,'RA_{}_{}'.format(j,i+1), pd.read_csv(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\RA_model_{}_{}.csv'.format(j,i+1)))\n",
    "              \n",
    "for j in 180,400,590:\n",
    "    setattr(mod,'avg_RA_{}_model'.format(j), pd.DataFrame())\n",
    "    getattr(mod,'avg_RA_{}_model'.format(j))['model'] = [0 for i in range(len(getattr(mod,'RA_{}_1'.format(j))))]\n",
    "    for i in range(5):\n",
    "        getattr(mod,'avg_RA_{}_model'.format(j))['model{}'.format(i+1)] = getattr(mod,'RA_{}_{}'.format(j,i+1))['model']\n",
    "        \n",
    "    del getattr(mod,'avg_RA_{}_model'.format(j))['model']\n",
    "    setattr(mod,'avg_RA_{}'.format(j), getattr(mod,'avg_RA_{}_model'.format(j)).mean(axis=1))\n",
    "    setattr(mod,'std_RA_{}'.format(j), getattr(mod,'avg_RA_{}_model'.format(j)).std(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in 180,400,590:\n",
    "    for i in range(5):\n",
    "        setattr(mod,'RF_{}_{}'.format(j,i+1), pd.read_csv(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\RF_model_{}_{}.csv'.format(j,i+1)))\n",
    "              \n",
    "for j in 180,400,590:\n",
    "    setattr(mod,'avg_RF_{}_model'.format(j), pd.DataFrame())\n",
    "    getattr(mod,'avg_RF_{}_model'.format(j))['model'] = [0 for i in range(len(getattr(mod,'RF_{}_1'.format(j))))]\n",
    "    for i in range(5):\n",
    "        getattr(mod,'avg_RF_{}_model'.format(j))['model{}'.format(i+1)] = getattr(mod,'RF_{}_{}'.format(j,i+1))['model']\n",
    "        \n",
    "    del getattr(mod,'avg_RF_{}_model'.format(j))['model']\n",
    "    setattr(mod,'avg_RF_{}'.format(j), getattr(mod,'avg_RF_{}_model'.format(j)).mean(axis=1))\n",
    "    setattr(mod,'std_RF_{}'.format(j), getattr(mod,'avg_RF_{}_model'.format(j)).std(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re 180 interpolation\n",
    "plt.scatter(Data_180['Y'].loc[test_X.index]*180,Data_180['Nu_t_lsq_n'].loc[test_X.index],s=40,color='b',label='DNS (in 2019 S.Kang et al)')\n",
    "plt.scatter(Data_180['Y'].loc[test_X.index]*180,(-0.11*((Data['tke_n']**2)/Data['tke_diss_n'])).loc[test_X.index],s=20,color='purple',label='k-$\\epsilon$ model')\n",
    "plt.errorbar(Data_180['Y'].loc[test_X.index], avg_L2_SGD_180,yerr=1.96*std_L2_SGD_180,fmt='rs',ms=4,linewidth=1,capsize=2,label='L8 L2 reg SGD ANN')\n",
    "plt.errorbar(Data_180['Y'].loc[test_X.index], avg_L10_L2_SGD_180,yerr=1.96*std_L10_L2_SGD_180,fmt='ys',ms=4,linewidth=1,capsize=2,label='L10 L2 reg SGD ANN')\n",
    "plt.errorbar(Data_180['Y'].loc[test_X.index], avg_L15_L2_SGD_180,yerr=1.96*std_L15_L2_SGD_180,fmt='gs',ms=4,linewidth=1,capsize=2,label='L15 L2 reg SGD ANN')\n",
    "# plt.errorbar(Data_180['Y'].loc[test_X.index], avg_SGD_180,yerr=1.96*std_SGD_180,fmt='rs',ms=4,linewidth=1,capsize=2,label='SGD ANN')\n",
    "# plt.errorbar(Data_180['Y'].loc[test_X.index]*180, avg_L10_L2_Regular_180,yerr=1.96*std_L10_L2_Regular_180,fmt='ys',ms=2,linewidth=1,capsize=2,label='L10 L2reg Regular ANN')\n",
    "# plt.errorbar(Data_180['Y'].loc[test_X.index]*180, avg_RF_180,yerr=1.96*std_RF_180,fmt='gs',ms=3,linewidth=1,capsize=2,label='Random Forest')\n",
    "plt.axis([-.05,0.9,-.001,.006])\n",
    "# plt.xticks([0,.1,.2,.3,.4,.5,.6,.7,.8])\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "# plt.savefig(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\y_plus_Re_180_profile.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.scatter(Data_180['Nu_t_lsq_n'].loc[test_X.index],avg_RF_180,s=10,color='b')\n",
    "plt.plot([0,0.005],[0,0.005],color='k')\n",
    "plt.axis([0,0.005,0,0.005])\n",
    "plt.grid(True)\n",
    "plt.title('Random Forest interpolation')\n",
    "plt.savefig(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\RF_Re_180_scatter.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sqrt(MSE(Data_180['Nu_t_lsq_n'].loc[test_X.index],avg_RF_180)))\n",
    "print(ARE(Data_180['Nu_t_lsq_n'].loc[test_X.index],avg_RF_180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re 400 extrapolation\n",
    "X = Data_400['Y'].sample(n=50)*400\n",
    "plt.scatter(X,L2_SGD_400_1['y_data'].loc[X.index],s=20,color='b',label='DNS (in 2019 S.Kang et al)')\n",
    "# plt.errorbar(X, avg_L15_L2_SGD_400.loc[X.index],yerr=1.96*std_L15_L2_SGD_400.loc[X.index],fmt='rs',ms=3,linewidth=1,capsize=2,label='L15 L2reg SGD ANN')\n",
    "# plt.errorbar(X, avg_L10_L2_SGD_400.loc[X.index],yerr=1.96*std_L10_L2_SGD_400.loc[X.index],fmt='rs',ms=3,linewidth=1,capsize=2,label='L10 L2reg SGD ANN')\n",
    "plt.scatter(X,(-0.09*((Data1['tke_n']**2)/Data1['tke_diss_n'])).loc[X.index],s=20,color='purple',label='k-$\\epsilon$ model')\n",
    "plt.errorbar(X, avg_L10_L2_Regular_400.loc[X.index],yerr=1.96*std_L10_L2_Regular_400.loc[X.index],fmt='ys',ms=3,linewidth=1,capsize=2,label='L10 L2 Regular ANN')\n",
    "# plt.errorbar(X, avg_L2_SGD_400.loc[X.index],yerr=1.96*std_L2_SGD_400.loc[X.index],fmt='rs',ms=2,linewidth=1,capsize=2,label='L8 L2reg SGD ANN')\n",
    "# plt.errorbar(X, avg_SGD_400.loc[X.index],yerr=1.96*std_SGD_400.loc[X.index],fmt='ys',ms=2,linewidth=1,capsize=2,label='L8 SGD ANN')\n",
    "# plt.errorbar(X, avg_RA_400.loc[X.index],yerr=1.96*std_RA_400.loc[X.index],fmt='ys',ms=3,linewidth=1,capsize=2,label='Regular ANN')\n",
    "plt.errorbar(X, avg_RF_400.loc[X.index],yerr=1.96*std_RF_400.loc[X.index],fmt='gs',ms=3,linewidth=1,capsize=2,label='Random Forest')\n",
    "plt.axis([-.05,320,-.001,.006])\n",
    "# plt.xticks([0,.1,.2,.3,.4,.5,.6,.7,.8])\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.title('Re_tau 400 extrapolation case')\n",
    "# plt.savefig(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\y_plus_Re_400_profile.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.scatter(SGD_400_1['y_data'].loc[X.index],avg_SGD_400.loc[X.index],s=10,color='b')\n",
    "plt.plot([0,0.005],[0,0.005],color='k')\n",
    "plt.axis([0,0.005,0,0.005])\n",
    "plt.grid(True)\n",
    "plt.title('400 SGD ANN extrapolation')\n",
    "plt.savefig(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\SGD_Re_400_scatter.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re 590 extrapolation\n",
    "# Re 400 extrapolation\n",
    "X = Data_590['Y'].sample(n=50)*590\n",
    "plt.scatter(X,L2_SGD_590_1['y_data'].loc[X.index],s=20,color='b',label='DNS (in 2019 S.Kang et al)')\n",
    "plt.scatter(X,(-0.09*((Data1['tke_n']**2)/Data1['tke_diss_n'])).loc[X.index],s=20,color='purple',label='k-$\\epsilon$ model')\n",
    "# plt.errorbar(X, avg_L15_L2_SGD_590.loc[X.index],yerr=1.96*std_L15_L2_SGD_590.loc[X.index],fmt='rs',ms=2,linewidth=1,capsize=2,label='L15 L2reg SGD ANN')\n",
    "# plt.errorbar(X, avg_L10_L2_SGD_590.loc[X.index],yerr=1.96*std_L10_L2_SGD_590.loc[X.index],fmt='rs',ms=3,linewidth=2,capsize=2,label='L10 L2reg SGD ANN')\n",
    "plt.errorbar(X, avg_L10_L2_Regular_590.loc[X.index],yerr=1.96*std_L10_L2_Regular_590.loc[X.index],fmt='ys',ms=3,linewidth=1,capsize=2,label='L10 L2reg Regular ANN')\n",
    "# plt.errorbar(X, avg_L2_SGD_590.loc[X.index],yerr=1.96*std_L2_SGD_590.loc[X.index],fmt='rs',ms=2,linewidth=0.5,capsize=2,label='L8 L2reg SGD ANN')\n",
    "# plt.scatter(X,SGD_590_1['y_data'].loc[X.index],s=20,color='b',label='DNS (in 2019 S.Kang et al)')\n",
    "# plt.scatter(X,(-0.117*((Data2['tke_n']**2)/Data2['tke_diss_n'])).loc[X.index],s=20,color='purple',label='k-$\\epsilon$ model')\n",
    "# plt.errorbar(X, avg_SGD_590.loc[X.index],yerr=1.96*std_SGD_590.loc[X.index],fmt='ys',ms=2,linewidth=1,capsize=2,label='L8 SGD ANN')\n",
    "# plt.errorbar(X, avg_RA_590.loc[X.index],yerr=1.96*std_RA_590.loc[X.index],fmt='gs',ms=3,linewidth=1,capsize=2,label='Regular ANN')\n",
    "plt.errorbar(X, avg_RF_590.loc[X.index],yerr=1.96*std_RF_590.loc[X.index],fmt='gs',ms=2,linewidth=1,capsize=2,label='Random Forest')\n",
    "plt.axis([-.05,500,-.001,.006])\n",
    "# plt.xticks([0,.1,.2,.3,.4,.5,.6,.7,.8])\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.title('Re_tau 590 extrapolation case')\n",
    "# plt.savefig(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\y_plus_Re_590_profile.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.scatter(SGD_590_1['y_data'].loc[X.index],avg_RF_590.loc[X.index],s=10,color='b')\n",
    "plt.plot([0,0.005],[0,0.005],color='k')\n",
    "plt.axis([0,0.005,0,0.005])\n",
    "plt.grid(True)\n",
    "plt.title('590 Random Forest extrapolation')\n",
    "plt.savefig(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\RF_Re_590_scatter.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_400['tke_n'] = (Data_400['tke_n'] - Data_180['tke_n'].mean())/Data_180['tke_n'].std()\n",
    "Data_400['tke_diss_n'] = (Data_400['tke_diss_n'] - Data_180['tke_diss_n'].mean())/Data_180['tke_diss_n'].std()\n",
    "Data_400['Nu_t_lsq_n'] = (Data_400['Nu_t_lsq_n'] - Data_180['Nu_t_lsq_n'].mean())/Data_180['Nu_t_lsq_n'].std()\n",
    "\n",
    "ttt = pd.DataFrame()\n",
    "ttt['model'] = sess.run(model,feed_dict={X: Data_400[Data_400.columns[:-2]]}).flatten()\n",
    "ttt['y_data'] = Data_400[Data_400.columns[-2:-1]]\n",
    "# tttt['model'] = RFmodel.predict(stz(Data_590[Data_590.columns[:-2]]))\n",
    "ttt = ttt*Data_180.std()[-2] + Data_180.mean()[-2]\n",
    "\n",
    "plt.scatter(Data_400['Y'],Data_400['Nu_t_lsq_n'],s=10,label='DNS')\n",
    "plt.scatter(Data_400['Y'],ttt['model'],s=10,label='Random Forest')\n",
    "# plt.axis([-.05,.85,-.001,.006])\n",
    "plt.xticks([0,.1,.2,.3,.4,.5,.6,.7,.8])\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\RF_Re400_interpolation.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_400.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_590['tke_n'] = (Data_590['tke_n'] - Data_180['tke_n'].mean())/Data_180['tke_n'].std()\n",
    "Data_590['tke_diss_n'] = (Data_590['tke_diss_n'] - Data_180['tke_diss_n'].mean())/Data_180['tke_diss_n'].std()\n",
    "Data_590['Nu_t_lsq_n'] = (Data_590['Nu_t_lsq_n'] - Data_180['Nu_t_lsq_n'].mean())/Data_180['Nu_t_lsq_n'].std()\n",
    "\n",
    "Data_590.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = pd.DataFrame()\n",
    "ttt['model'] = sess.run(model,feed_dict={X: Data_590[Data_590.columns[:-2]]}).flatten()\n",
    "ttt['y_data'] = Data_590[Data_590.columns[-2:-1]]\n",
    "# tttt['model'] = RFmodel.predict(stz(Data_590[Data_590.columns[:-2]]))\n",
    "ttt = ttt*Data_180.std()[-2] + Data_180.mean()[-2]\n",
    "\n",
    "plt.scatter(Data_590['Y'],ttt['y_data'],s=10,label='DNS')\n",
    "plt.scatter(Data_590['Y'],ttt['model'],s=10,label='SGD ANN')\n",
    "plt.axis([-.05,.85,-.001,.006])\n",
    "plt.xticks([0,.1,.2,.3,.4,.5,.6,.7,.8])\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.savefig(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\RF_Re590_interpolation.png',dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_400.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\channel_Data_180.csv')\n",
    "Data1 = pd.read_csv(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\channel_Data_400.csv')\n",
    "Data2 = pd.read_csv(r'D:\\Desktop\\190925\\channel_pr_t\\Prt_data\\channel_Data_590.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
